I would like to request all the attendees of the panel discussion starting from 2:30 p.m. please take your seats. >> [music] [music] [music] [music] >> It's it's been a complete uh like what what should I say I mean I think basically because of the change in location the last moment and traffic jam and everything that the people still coming of fact couple of panelists also yet to come and uh but I thought we'll start waiting for them and in fact audience also like they on the way that they're supposed to come right so uh Gabila was there it's a sequel to the AI safety summit conclave what we did in December at Kerala it was an international event we had uh Dr. G I mean Gabila Ramos giving a keynote address along with others and uh and we also came with a safety report uh which we shared which are well received by industry and academia as well and public sectors. So we thought we will have a sequel to that and we'll discuss some of the points which is being discussed and take it forward from there and so that we can shape up this AI safety in particular agentic a safety discussions forward so that it can form input to the policy makers the academia and the industry in general. The important aspect we must consider here the AIC aspect report we covered the sectoral aspects of AI safety when it comes to agentic AI we covered BFSI we have covered defense we have covered healthcare we have covered retail and we have covered education and I'm happy to share this uh report with you and all of you and after this and it's also published on the LinkedIn right and you're also going to come out another another two days we are going to release uh our a sovereignity for India and global south uh it's it's been we have gone through a very extensive interview process and survey questionary process and we're coming out with the report so that with uh that background I would start with Dr. Krishna Shri because uh she's going to give a five minutes highlights of the safety report what we published with and we can take it forward. Is it okay? Uh good afternoon everybody and thank you very much for being here. Um we've seen in these uh past couple of days a very broad uh spectrum of uh various different dimensions that AI can take course in science in technology in the social sciences humanities um aspects and we've had many many experts from all around the world with us uh these past couple of days and I think we are seeing more and more um how every aspect of AI is going to really touch our lives, our businesses, our economic growth uh and probably also our peace of mind I would say at some point of time. Um but uh just addressing what uh Dr. Shivarama Krishna just mentioned um we actually are from south of India Amitita University um built on a three core pillar um which is um looking at compassiondriven research education for life and global impact. Now two of these three pillars actually intersect the discussion today. One is compassiondriven research. What does it really mean when we really look at these emerging technology frontiers in terms of how it touches um the lives and links um of in terms of the applications in terms of also [snorts] the frontiers in terms of safety and security as well. Uh the second is really global impact. So as we are seeing AI is just not the first but definitely the the current uh technology that has and and and has largely impacted in probably the fastest wave so far. Um not only the technology companies but also organizations even civil society organizations for that respect in terms of how we really deal with day-to-day activities and communicate. uh with that the work that we did in December actually touched on six different dimensions. It included life cycle monitoring, looked at emergent um safety or deviant behavior safeguards, what is really ethical autonomy, looked at u recursive uh governance, uh looked at also regional adaptive governance and also human oversight. So these were the six pillars that we looked at um from the perspective of various different corporate verticals like uh Dr. Shivramman said um looked at BFSI, looked at healthcare, looked at education etc. So what we really found is that there is a significant maturity gap. We see that BFSI in fact has the highest level of you could say compliance and also maybe 100% human oversight mechanisms inbuilt. Um, of course RBI has the free AI framework to be able to deal with transactions and AI applications and perhaps that could have been the reason. If you talk about education, it was kind of like the biggest sleeping giant in the room, you could say. Even though there was significant excitement about AI tutors and whatnot, um the level of safeguards against uh deviant behavior was almost nil in any of the educational applications that we looked at and and the people we spoke to. If you looked at the healthcare on the other side, it has the highest amount of variability um in terms of some institutions being uh well oriented in terms of the AI impact in their own institutions but also highest risk because of the lack of governance maturity across the uh healthare systems due to lack of also escalation protocols and procedures and also automated safeguards. So all of these were what we found as significantly missing from the healthcare industry. And we looked at public services, it was like kind of a blinded sector when it came to uh context awareness. So you looked at applications that were available in in in in urban communities and you just took that and put it in rural communities where it totally didn't make sense uh and people couldn't really embrace those technologies. So, so we found these specific aspects as different verticals from these different industries. >> Thank you. Now, thanks. With that background, I would go with I start with the lady first. Um, you oversaw school's 2021 recommendations on the ethics of AI, right? Given the India's diversity, you know, like even our currency prints 15 languages here, right? So given the India's uh all possible diversities right which unus principle like justice inclusivity or accountability governance are the most critical for guiding agentic safe agent your opinion develop >> me. >> Yes you're having me which is great. Uh well thanks so much for the invitation. I'm glad to be here with all friends and new friends. >> Um the the fact is that first congratulations for that report. I really feel and India has shown the way with all of the infrastructure the DPI the financial services the applications applications of AI that this should not be only a very sophisticated technological discussion. It has to be grounded on concrete ways in which systems can be improved. Uh and I understand why the educational system is lagging behind too high risk. Uh I know that many countries are not using AI because they don't have the legal basis or the accountability frameworks and therefore people don't feel that they have the basis to do it. Um so there there would be two parts. I feel that um the principles that UNESCO developed but I have to confess that I was also at the OECD when the OECD produced their principles in 2019 and they are the same. It's about transparency. It's about accountability. It's about proportionality. You we don't need AI for everything and for everything and for every uh single issue we do. uh it's about the rule of law and I would say that for me all of them are so important but all of them are only contributors to ensure that the rule of law is preserved meaning we do everything we can to steer the incentives for these technologies to behave and we're talking about agents >> and we're talking about safety and loss of control and catastrophic risk and autonomy that will just get around humans and I feel that we need to find the way to build not only the most important principle but as uh Krishna said bring it to very concrete ways of doing it. For example, if you want to make sure that the deployments are accountable, one thing is very important that we did also and and with the support of member states uh was to eliminate the notion ban the notion that you can give legal personality to AI developments. And you might say, well, this sounds very crazy. No, but at the end I spent hours hours listening to member states with such different views. Japan was fully supportive to give legal personality thinking about care economy, the elderly, having robots that will be there and who knows like corporations also have legal responsibilities. uh and then you have the other group European countries who are more based on human rights saying no way we can do that because then you will be delinking the responsibility and the outcomes and there should always be human determination and I think this is another very important principle >> thank you governor now with that a follow-up question I will go to Abdul Raman right lot of countries from mena including especially Saudi are drafting ethical AI guidance and you were you were leading some of this initiative still there right so now like uh with this like for example the excited you were part of it and you were you were one of the thought leaders one of the thought leaders there right I mean um should should countries like India Saudi and all the global south countries should collaborate on establishing a common ground where we have a centralized kind of guidelines but with regional flavors and do you think organization like UNESCO and UN should play a role on this? The public question. What do you think? >> Thank you. She sh I think uh to your point yes it is timely right to do this right now. Um Mina region today today morning I had a round table with the Indian counterparts. >> Okay. Um we are talking about expanding relationship but not only that but also the businesses the trades between different countries and what that trade with AI will look like and how these agents will help or how these agents will u will come with some challenges. Um maybe Gabriella mentioned the legal the legal side of it but I I'll focus on the economical part of it. >> Okay. Um now we want to to have more business with different countries. Uh these opportunities will create new new businesses. Uh but those all or the majority of those businesses today is digital. How are we going to do that if if the ethical concern is not embedded by design if it's not localized and in some cases it need to be also sovereign in in some places. So while we work together we need to make sure uh sovereignty is there. I think today morning um some of our Indian colleagues mentioned that especially with what happened in the past year or so from uh major countries that open our eyes that sovereignty is very important and we cannot just um deal with it especially with agentic now um without thinking of the consequences of not having the agents in your country and the those agents are not having the the right understanding. Um I think also that um looking at those agents now and working with with different counterparts auditing and looking at the um the compliance that will will come either voluntary today in case of Saudi Arabia there is no required law but there is voluntary compliance >> and in may maybe other countries as well at the same time build that compliance within the products build it from the ground up in order to make sure that these uh these products are um culturally accepted and also will provide the right value that for for those uh for those uh programs. I think at the end also preserving languages and preserving uh culture is an important deal for many of us. Therefore, building those applications and those program with the cultural preservation either uh language or religions and many others are critical important point for so many uh customers today. Thank you. >> So that's a very important point you need to take into account the cultural aspects of the entire thing. That is a great point. Now Dr. like one um uh your if you look at it our India AI guidelines are principle based right quote unquote um uh like trustworthy AI and humanentric and all the stuff like unlike Europe's more detailed draft regulation so from your perspective India is at risk of too many gray areas should I stakes like finance healthare BFSA have stricter mandates what's your opinion on Thank you. I think this is it's an important thing to reflect on if we're looking at the upcoming uh importance of AI systems be they agentic or otherwise and their impact on the way in which companies and people and public sector interact with each other to figure out what is the good baseline against which we're going to be operating on these. Now certain jurisdictions like the EU have a tradition of approaching these kinds of new technologies with a an an approach of saying we will set new regulations, we will set a sort of a new legal frameworks around this. There are certain reasons for this. One of them being that the EU is trying to coordinate across 27 different jurisdictions and if the EU doesn't put something in place then you you run the risk of getting 27 different pieces of legislation which is not going to be beneficial for anybody really. Um but just because one one culture of jurisdiction has one way of approaching this doesn't mean that that is the best way for everybody else. for India, for many other jurisdictions, you have a different um culture of how to approach uh regulation in a space and it makes more sense to also approach AI regulation in a way that fits in with the way in which everything else is being done. So it may make more sense to say instead of trying to put in place a new piece of AI legislation, let us make sure that the existing pieces of safeguards that exist for the society that they are maintained correctly when dealing with AI. So for instance, just asking existing regulators to pay attention that AI doesn't generate a um accountability gap where people will say well it wasn't our choice. the AI agent went off and did a thing and therefore it's not my fault and maybe we'll try to blame it on the technology providers from whom we imported something but the technology provider will say well we never knew you were going to go to this context which comes to the the the sectoral dependency so we couldn't take accountability for it accountab we must never allow accountability to suddenly evaporate just because there was an agentic system in the space but the way in which to approach it needs to fit within in the cultural and legal context of a jurisdiction. So it's not the case that you can say these were the first movers everybody needs to follow this way or or any it's important to look at what works in your context. >> Great. So I'm going back to that throughout your uh tenure in UNESCO you always uh evangelize um uh basically mean I mean inclusivity inclusivity and security and governance right what kind of uh concrete steps you suggest from India's perspective or global so perspective to ensure that the systems we are building agentric system are safe and secure Sure. >> That's um that's a question that has several levels because first as we have heard of course we need to make sure that the way we develop the technologies is safe and the good news is that technologically that is becoming more feasible. before I I mean I have been in all these summits uh for many years even before the AI summits arrived on the G20 and we were always listening we don't understand the models we don't know how to control them they come with certain results and then we don't I'm I'm hearing that less it's not that it's gone because it's true that there are very complex models and sometimes the outcomes are not aligned with what the developer want to do but so so I feel that we should ensure that we don't discriminate. We are in a context in which there are lots of inequalities. There are lots of communities that are not represented in the data. Not only in terms of language and the work that I care is doing is in that sense have more representativeness in the in the development of the tools. Uh but at the end when you apply those technologies we need to make sure that we understand the context and we understand which are the groups that are at risk of suffering in their rights in their opportunities in their because of the technology and I don't think that this is the mindset that we have now it it seems that the technology came from the sky and then we're discing in the technology. No, the we have some challenges. India has a lot of challenges as Mexico. The the the high inequalities, >> the need to provide with quality education to children, the need to ensure that there's universal health health coverage. I mean, all of our countries what they are aiming at is to improve the well-being of their people. And at the end, independently of the technology or not, that's our objective. So how do we ensure that these technologies are going to be helping us to provide more opportunities for those groups that were usually lagging behind of how are they going to be because of the bias algorithms or or data that is not representative are going to be just widening this gap. I feel this is the most important thing and again it's not going to be a technological discussion. It's going to be a political one. It's going to be a soci a societal discussion and it's going to be based in recognizing first and foremost what are our challenges and then how we solve them. One of of the issue that is very easy to do is to ensure that women are represented in the development. >> Yep. >> No, I'm happy that we have a very balanced panel. >> Very balanced panel. >> But usually it's not the case. The fact is that you have only 20% in the big developments of the of the AI in the world only 20% of the workforce are women and you see the top uh owners of these technologies are men. Nothing wrong with that [laughter] but no not taken uh but at the end this is one of the issues that we really need to to tackle and that is not so complicated. >> Do you see this u trend improving? A followup question that the the inclusivity of women in deep tech is do you see a trend which is improving? >> Not that much. I see more push I I see more women pushing >> but but no no it's not it's not yet there. I I I admire India because actually you have a share of women engineerings that is higher than in Belgium or in in some other uh European countries. Uh we need not only to break the mold and the glass ceiling. We need to create the pipeline >> and therefore it's it's a challenging task but at least the fact that many leaders are recognizing that this cannot go on without gender equality I think is a good step. >> What about LATAM makes it your own country >> in Latam. Uh we don't have AI. No, I'm kidding. I'm kidding. Of course. No, I I there there lots of very fantastic women. I have senators and I actually have the first the first female president >> which is a scientific and you have me. Thank you. [laughter] >> I'm going to Dr. people are human like um we have been going through a lot of discussions about AI life cycle accountability right in your view like if something goes wrong with agentic system and the life the life cycle chain actually who do you think should be held responsible either the developers or the the regulators or the government or or who else right right uh that's what anduh Are there any regulatory requirements or guidelines or frameworks are in place um which helps you to identify this is a life cycle activities and I have to pin the responsibility at this stage on this person is there anything uh are evolving in your opinion >> maybe before answering this question I'll follow up with Gabriela and woman empowerment I believe that um global south >> y >> have a unique opportunity for women empowerment more than global north. >> Completely agree with you. Completely agree. >> Looking at the the ratio of woman representation in engineering and and science in India and in Saudi is is very good and it is improving and improving organically even without looking or trying that hard to to engage as much. >> Yes. >> Um so this is an opportunity rather than it's a challenge. I understand it's a challenge for certain countries but it's a great opportunity for global south and that will bring more global south to south collaboration >> I think that's becoming more important now especially on on woman empowerment now going back to your question about the the accountability I think accountability >> I think will be the most important piece of agentic this is the trickiest part after risk and accountability will be the the biggest challenges with with agentic uh but it need to be layered. We can't say just developers are the one responsible especially if the agency is generative. We can't say also um multinational technology organization they are the one responsible and accountable for X and Y. I think there should be layers and that that layers will include the developers, will include the provider, will include also the deployer whomever that organization is deploying in either the government agency or whatever and also the international community where we are setting also standards and programs to help um improve that accountability and establish it in different ways. And then different countries will have it somewhat differently. As as you mentioned earlier jurisdictions are are thought and maybe systems are different therefore it will be implemented to the context of that country Dr. You have been u one of the evangelist thought leader when it comes to AI audits and evaluation in your even your current program right in your opinion like what do you think uh what the India is doing right or the private sector is doing right or not doing right when it comes to this I mean I mean the the I mean the the frontier system audits and I mean on the care assistance. >> Um let me start uh by reflecting on the question about the accountability point. I I think it's absolutely true the accountability um there will be certain accountability that lies with the engineers but it that is not where it will start. It starts with those who've decided that an AI system is going to be even be used in this kind of space. That means it starts with the decision makers. If you're in a company that means it starts at the sea level. There needs to be uh accountability there. That includes taking the re react the responsibility to put in place good governance frameworks including looking at things like standards that have arisen around this like the ISO 4201 AI management system standard which is providing a life cycle perspective on these questions. Um but then it needs to also be at the deployment side at whoever is deciding we are actually going to go with this. We can't have um the agentic system somehow being the one that does this. I think um and we had a very lively and and I think dynamic conversation on this topic of the assessments and validations of AI systems earlier uh during this conference. I think we heard some very valuable and and and um strong contributions from our Indian colleagues on on that panel including from uh Jibo Ilas from from Monzilla Foundation about the way in which India is looking at this not just from a top down but also from the bottom up kind of perspective of how can you make sure that uhmemes that smaller organizations if they are looking to use AI try to help help them scale and help them be able to be a a strong competitor in the space. Um, but that they can find ways of practically implementing against the principles that have been established. Principles are all great and good, but if you don't have a practical way of of looking into this, then there is a challenge and and I think um that is an area where there's still a lot that needs to be done, but we are seeing practical tools coming out. We've got standards. We've got also IE standards around AI ethics. Um we've also got tools like AI impact assessment um uh frameworks that are coming out including one that the Council of Europe is looking to to launch related to the convention on AI. So um I think it was for me what I see especially in in India and I think also broadly across the global south is because there is a dynamic mindset of look of many voices exploring best ways of approaching it that we have a an organic bottomup way of finding this is what's actually going to work and that thing maybe it looks nice on a on a p piece of paper but practically speaking there are gaps here that we need to fill and I think India can bring these up big be through this dynamic ecosystem >> that's a very good important point Dr. Christ you would like to add something on the playbook part what we are booking. So um basically listening to all of you uh I I really feel that uh what would be thinking about what would be an ideal AI agentic AI framework what could some pillars be from that perspective is kind of something that we had actually discussed about and and researched and uh if if you really look at um the approaches that we can take one is from the regulatory API perspective can to make these systems stop and think or stop and ask uh type of approaches. Um that would be one and the other would be how can you really have a second layer of say watcher agents that could really look at any gold drifts and and you know potential malicious performance of these types of things. So we came up kind of with with with a threeprong approach to how to really embrace these kind of agentic AI and and build a framework around it. And first included looking at uh providing more of a a dynamic compliance oracle you could say that could really sync up with the rules and regulations um as they're evolving and incorporate that um into an engine to be able to share with the world. Second, like I said, is more of a a federated um watcher agent that could actually uh again monitor and and ensure that there is u always an alarm when there is a potential drift of any sort or even violations. And and third is really what I feel most important which is really a very compassionate and a constitutional AI perspective. How do you really protect um secularism? How do you really provide equity? How do you really give justice uh when needed in spite of all the potential testing and frameworks and standards that it has gone through? How do you really ensure that this still really happens is kind of the evolvement of kind of the things that we are looking at and want to really propose as potential um pathways for everybody to be able to look at as well. Thank you. >> That's a very interesting point. So this is a cross panel pushing crosscutting panel pushing I thought I I'll I'll have critical sectors like BFSI healthcare defense retail and education and stuff like that. Uh when it comes to agentic safety a safe agentic systems what do you think should be regulated which sector should be regulated first? Um I mean I know that I mean immediately everybody would jump into BFSI which is very highly regulated industry but I would like to draw your brain like which should be in your opinion which sector should be regulated first. I >> I I don't think that's that's the way the policy uh cycle operates. >> Okay. >> Because at the end you have ministers in charge of sectors >> and they will tell you no way Jose my sector first. >> Okay. Uh no I think that what we need to look at and I'm learning a lot from this panel is how to ensure that the learnings from one sector can be also informing what happens in other sectors. >> Yeah. >> And for me the most important element here is to have it outcome based. >> I was talking to Krishna in the way coming uh here to education. Just think about education. You can say I want agents to help me grade the students and allow me to get rid of all the administrative tasks. >> It's the most complicated setting to deploy these things not because of the technologies but because of the organizational changes that need to be made in these systems. And I compare education with health. Health is a sector that is very absorptive of research of progress knowledge all the time. Doctors need to be upgrading themselves all the time. >> They have by by design because they dealing with with with human health safety procedures. And many times when we were working on neurochnology, we were thinking the neurochnology tools that are now in the markets would need to follow the neurochnology tools that are in the in the health system because they are very well codified. So, so it it depends of which sector but at the end it would need to be outcome based and what we have seen in the education field for example is that everybody wants the technology and the and the places or the countries that have introduced the tablets and all the programs and are not the ones that are improving the student outcomes because they did not take a look at the cultural content. They did not took a look at how to change the pedagogy. They did not train teachers and they don't didn't put the whole system behind to support the deployment and the and the knowledge of what the technology can contribute in the specific sector. So I feel it's more understanding how these things work and what kind of technology will help them do what agents replacing teachers. I hope not. >> Yep. I I absolutely agree that ultimately we are interested in the outcomes and so that is what we judge the system by. But it is important that the thought process around how do we make sure that the outcomes are going to be compliant with good uh good good behavior that that doesn't start start at the end of the process but that that is something that starts at the very beginning of the process when we are defining what are the requirements that we want for this agentic system. At that point already it is important to make sure that the conversation about what do appropriate societal comp uh legal compliant ethical outcomes what do those look like and how do we make sure that they are um achieved throughout the life cycle of the system. >> I think um before coming to this session I played with my agents And I actually threw this question for them to discuss. What you will notice that um over reliance is is a is a big issue and a human with over reliance in in so many areas create new problems. >> Yes. >> And look at previous technology not only AI. Therefore, we will go through a whole list of we want this to improve our efficiency, solve some problems to have new problems and then we need to solve them some in another way maybe not with that technology or maybe to your point professor before with an agent that follows the other agent and they're all valid uh but not in every case and as Gabriela mentioned I think healthcare and education will be critical areas and what's more critical is the outcome moving forward and how are we going to measure those outcomes then is this technology is beneficial or we will ban it or not use it because it is actually not as beneficial. So all these questions will come to surface when we adopt more these agents and maybe AI overall then we are not getting the benefits that we thought it will be. So we'll think about a different technology that will help us to solve it. >> So I I too agree with the thought that perhaps we should not be thinking sectoral only. Um and maybe the way to be to to unify uh you could say the cross- sectoral uh requirements would be to look at a hybrid approach. What could be the minimum common requirements um that should be common across all sectors while there could be some specific sectoral requirements that could be mandated depending on healthcare which is kind of the highest risk you could say sector compared to and followed by education. So in that common requirements can we at least define what are you know the risks what are you know some of the definitions that we are going to be able to use so that they are all commonly judged and commonly assessed that would be the first um uh suggestion followed by what are some specific sectoral requirements like clinical safety versus you know um age related uh requirements when it comes to education and what we what what kids can use and should not use and what types of like I mentioned emergent behavior controls that we can really bring into these applications. So I think a hybrid approach could actually be a more of a unifying uh way to be able to look at perhaps sectoral um uh s uh you could say regulations. >> Okay. Suppose if we if India as a country if we have to balance our ambition uh to be uh I mean AI superpower like or at least a forerunner of AI technologies when it comes to Bizav is playing it safe in some sectors. Do you think we need to pass this in some sectors and take the lessons and then move forward to other critical sectors? This is that approach would what what do you think about this approach? >> Well, I think that's exactly what you have done with the DPI. So, okay, you really and and I think that was very smart because because the financial sector is really serving everybody. Yep. and is also helping to educate and make make uh individuals bankable and get financial inclusion. And so I feel that's that was a very strategic thinking and in that sense I see where you're going. Uh that um some of the things that India has done are really like benchmarks. >> Yes. >> Uh I was private to a conversation a decade ago. >> Yep. uh on the on the uh digital registry. >> Yep. >> And and we thought it's crazy to think that you can do 100 million every month. >> Yeah. >> I said, "No way. That's just crazy." Well, it's done. >> And therefore, 10 years ago, now we're talking about the infrastructure, infrastructure, connectivity, the digital tools, and you have them. Then you go to services and then you go and so you're building it up and you are also building the the human capital which is super important because the skills are lagging and and are lacking not only in emerging economies but also in advanced economies and even you see how the big tech is just trying to capture the the talent everywhere. So I feel you're doing it in in a in in the right way. I I I take advantage to make an announcement because I'm gonna there is a book that I contributed of Springer >> where I'm what where what where these questions was posed no what would what would it take and I and I put four eyes which was incentives for more investments in safe secure and uh good AI uh infrastructure >> y >> investments massive investments not the trillions that the big tech is burning that's their own choice but but the governments the businesses the people need to invest in themselves to use these technologies and the last one is no incentives infrastructure institutions we need institutions to frame the thing >> you spoke about DPI I have my friend Dr. Aik who was who played a big role in that I thought a right over to you Dr. I believe um a lot of countries have done very interesting things that we can all learn from and having a forum like this today and and other forms on AI and especially on regulation um and on adoption will help all of us learn from what happened in in one country and what uh what can be learned from the other countries and that's one of the reason why why most of whilst we are here and why we want to have this exchange in order to learn from the good and bad and what happened in in each of the countries and I think that will um help us all transform and and get better as we go >> and sorry to chip in but I would love to ask Saudi Arabia how they have made to increase female participation which was hit amazing. Yeah. Yeah. >> Um I think um to the point earlier global south and especially Middle East, North African countries, women are seriously interested in um in STEM and that's not the cultural issues that we face elsewhere where um STEM is not for girls. Actually in my previous team at the international center for AI um the team is about 45% women organically. We are just hiring and women are are getting into those programs faster than men. I think the ratio somehow is very close to each other but men has other options also to look at while women like these type of jobs being in interesting point. It is interesting. It is interesting for them and but don't quote me on this. They're in many cases better than than uh than some of the guys in there. >> Yeah. Therefore, they are getting higher higher results, higher scores, high achievement and in Saudi we see them everywhere. We're very proud of so many women are across the board in Saudi uh in AI and also in other STEM STEM areas. And you can see just some of those um comp international competition and how they are they're working the majority of the teams are are are ladies in in there. >> So congratulations to them and happy to be to be in that situation. >> Yeah, I can say I can tell you like I've been going to Riyad and Jeda like for last three four years attending conferences the amount of women who are getting into the stage and talking about STEM areas is phenomenally increasing. That's very last word. You are the last word. So I think um events like this uh this week it's it's really great that the conference has come to India um because um as you you already said we we all need to be learning from each other and as all of the different uh jurisdictions and companies have been on this journey to try to find out not just uh what are cool proof of concepts that you play with within AI but rather what are the challenges that come when you try to integrate them into actual service provisions that need to that people need to be able to rely on and we've seen huge challenges in public sector deployment of AI as well in in many different jurisdictions. Um it is vital that there is a good exchange of knowledge especially on things like safety and trust um and safeguards and what are red lines that these systems should really never be deployed for because if they fail it has a broad systemic um impact and what are we actually learning through these different experiences including the things that didn't work or where where is like you can't move this fast you need to move at a certain speed because institutional knowledge needs to build up. Uh frameworks need to be in place. Um so it this conversation is very necessary and frank exchange of information. With that I also had a small announcement. So with the support from India AI mission um and the ministry of IT as well as the department of telecom Amita was also uh had an opportunity to actually build a system to be able to uh track actually the various uh biases truthfulness etc of elements for India specific applications. So with that maybe I just wanted to play a short video for those of you in the crowd that would like to test their applications with this specific uh outcome of the government of India's uh effort. Please do come meet with us and talk to us as well. I make one last announcement also like on Friday Amanda University we worked on a research report on AI sovereigntity for India and global south uh with I mean with NASCAM as a research partner we are releasing this research report on 3:00 at barat mand I'm not here so we like all the panelists and be here uh to please grace our and bless the report thank you very much >> thank you so much also I think one of our speakers uh Dr. Dr. [music] Ganesh Bharat Jan could not be here but we actually worked very closely with them in also looking at healthcare applications [music] from our school of aridabad and uh we have something also um specific to Harat [music] and related applications there as Heat. Heat. [music] [music] [music]