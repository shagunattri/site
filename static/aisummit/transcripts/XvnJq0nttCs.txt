Hallelujah. I should have kept so many Good morning. Uh good morning everyone. Good morning. Uh uh Shri Ashni Ashnav GI Honorable Minister for Electronics and Information Technology. Uh Sir Damis Hasabis, CEO of Google Deep Mind. Shri Jitin Prasad, Honorable Minister of State for Electronics and IT. Sir Shri Krishnan, Secretary Matei. Mrs. Kavita Bhya, COO India, Ministry of Electronics and IT. and distinguished guest, eminent researchers, ladies and gentlemen, it's a very warm welcome to all our dignities and participants. We welcome you to the research symposium on AI and its impact, the flagship event of the India AI impact summit 2026. Now we begin the opening ceremony. It is my privilege to invite Shrimiti Kavita Bharty, Chief Operating Officer India to deliver the welcome address. Honorable minister, honorable minister of state, secretary mighty sir deisabis, symposium chair and co-chair of the program committee of the research symposium, esteemed researchers, academia leaders, innovators, partners from India and across the world. A very warm welcome to all of you. It's my privilege to open the research symposium on AI and its impact, a flagship knowledge platform of the India AI impact summit. Over the past one year, as the preparation for the summit have unfolded, one conviction has guided our efforts that meaningful conversations on AI must be anchored in research, evidence, and interdisciplinary exchange. The research symposium has therefore been designed not as a ceremonial gathering but as a working platform one that brings together the build people building AI systems studying their implications and shaping the real world deployment. Today convening reflects months of institutional collaboration. We have worked closely with researchers and academia in in particular our knowledge partners triple IT Hyderabad to curate a program that is both globally representative and substantially rigorous. The diversity of the participation we see today across geographies and sector is a testament to the growing importance of such integrated research platform. Increasingly the meaningful progress is emerging at the intersection of communities computer scientists and social scientists engineers and ethics public institution and private laboratories startups and universities. By bringing these communities into a shared space we hope to enable conversation that are technically grounded, societal aware and implemented oriented. Another important dimension of this platform is its emphasis on emerging research voices alongside globally recognized scholars. The symposium has created dedicated space for early career researchers, doctoral scholars and student innovators because institution building in AI will require not only nurturing ideas but also building ecosystem of mentorship and visibility. From an institutional standpoint, convenings such as this play a catalyst role in surfacing frontier research questions, identifying partnership opportunities and aligning innovators pathways with real world needs. It's our hope that the conversation initiated here will extend well beyond today's session evolving into a sustained institutional partnership. As we begin the proceeding, I would like to express my sincere appreciation to all partner institutions, knowledge collaborators, speakers, program curators who have contributed in shaping the symposium. Your participation in is what transformed this platform for an event into a living research network. As we inaugurate this symposium, we do um at the moment when India's AI journey is accelerating, the insights and partnership that emerge from these discussions will play an important role. It's now my honor to invite the dignitaries to give their special address. Thank you. Thank you ma'am. Now to set the context of for the sessions ahead I invite professor PJ Narayan professor IIT Hyderabad and chair of the symposium to address the gathering. distinguished uh members who are sitting in the on the disinvitab is chairman secretary Mr. Krishnan and I would like to also recognize some special people sitting in the audience. Professor Raji is here uh touring award winner and uh and and so so this is an academic uh gathering. So when the the summit is was planned uh the mighty or the organizers also had it to have wanted to have a a academic symposium or research symposium in parallel with it and I was contacted to see if I could coordinate this. So I agreed to be the co-chair and I get to stand here and and represent a co-chair but there were so many people who helped me with this very critical decisions. One of them is Kalika Bali sitting there. I mean she's part of the India team. She did a lot more firefighting than I did and of course Abhishek Singh the additional secretary who guided us in multiple ways in ways see we think we are we are researchers we think only researchers way but this is not only a research event this entire summit so how to put these things together has been very uh very instrumental in doing that so AI has suddenly become so big even two years ago if somebody had suggested said people working in AI or machine learning will win Nobel prizes. Everybody would have laughed and we got two in the in the same year. And even even the touring awards, you know, the first initial pioneers, four or five pioneers of computer science got Turing awards, I mean of AI got Turing awards say back in 60s and 70s. After that about 20 years there was a gap in even touring awards being given to AI work and Raji and Professor Fenbomb were awarded Turing award in 94 for their work in AI. So even the computer science community was not recognizing it as much. Of course now it has changed you have many more Turing awards in the last year the recent years. So when we started planning this we didn't know where to go. There are so many things happening in AI. How do we how do we bring everything together? And we try to get as much of it together as possible and I'm very very pleased to have four stellar uh individuals doing keynotes. Deasabis himself who uses AI or ML techniques to advance science mostly where the humanity benefits unquestionably. And we will have after that Wendy Hall Dame Wendy Hall. She's been working in web sciences and looking at the progress of how web and this big connected world enable this whole thing in some way. AI wouldn't have been there without this data and this adoption. Then we have Yoshua Benjio who has been on the safety side on cautioning everybody of the potential dangers of AI and I think he's they are very real. we need to listen to him and we also have Yan Lakun who probably takes the other side who is very very gung-ho about AI's potential. So I think we need to listen to all the voices. I'm very glad that all four kind of voices are heard here in terms of plenaries. Then we have uh what we call research dialogues. One is on u on the you know how AI can be a catalyst in discovery of science and engineering progress and how can we can impact the increase the impact of that. The other one is on AI itself. What next? What is the you know what next frontier for AI research? Where is AI going? Then we have two international uh call international panels or global south with global south uh concentration. One of them is on global south itself. What is the impact on global south? The other one is on AI safety safe and trusted AI. These are the two panel parallel sessions that will happen. And then there are we have invited several top uh you know publishers from authors who published influential work in AI from across the world. People have come from all over the world to to present. These are they will be in posters during lunchtime and uh right after the the the session. So we have a fantastic program ahead and uh this should spur dialogue and discussion in topics related to AI and I was very pleased to see the large crowds for the last two days and I'm sure everybody or every one of us pleased to see a full hall like like this here. Everybody's eager to know about AI. Everybody's know eager to know how they will affect how it will affect them. So we'll have a fantastic session today. I'm thankful for this opportunity to to curate the session and bring it front of you. Enjoy the session. Thank you very much. Thank you sir. May I now invite our honorable minister for electronics and IT Shri Ashni Vashnavj to deliver the special address. Very good morning friends. Um this is a research symposium and uh I'm not at all qualified to be standing here. I wouldn't take too much of your time. Just want to thank you for coming out in such large numbers at 8:30 in the morning. Uh yesterday we had about 250,000 people uh mostly young. The average age was I think below 30 attending the AI expo and the entire exhibition area. It was phenomenal response when I interacted with the young minds. I was so surprised at the optimism that most of the young people expressed towards this uh opportunity which is coming for them. Initially I was bit apprehensive but looking at their optimism I'm feeling really hopeful for a totally new future for our country and for the world. Um we in India are very focused on AI in the edge AI for use cases. AI for solving real world problems. AI for improving the productivity in the enterprises. AI for population scale problems like healthcare, like agriculture, like climate change. These are the things that we are focused here in India and this AI summit brings that opportunity. And as we discuss various technical matters, I will request the topmost brains which are present here to please do bring some solid concrete suggestions on how to make AI safe. This is a great tool. It should be used for the benefit of humans. It shouldn't be something which really distorts that balance. I really look forward to the suggestions and ideas which will come out of the symposium. Thank you very much for coming to this symposium in such large numbers and I wish you all the best. Thank you. Thank you sir. With this we formally conclude the opening ceremony of the research symposium on AI and its impact. Thank you sir and thank you everyone. Yeah, you come here. My game Mike. Hello everyone. My name is Mossum. I'm a professor of computer science at IIT Delhi and also one of the co-organizers of the research symposium. I welcome everyone to the symposium and in fact we are all looking forward to it and the rain gods have also showered their blessings today. So we know that this is going to be a great symposium. It is my distinct honor to to welcome uh sir Deis Habis the fellow of Royal Society a Nobel laureate and the CEO and co-founder of Google deep mind for the keynote address and with him on the stage would be the moderator our own professor B Rainan who is himself a triple AI fellow and head department of data science and artificial intelligence at IIT Madras. So I request you to please join us on stage and deliver your keynote address. Thank you. Thank you ministers and uh government of India and uh our fellow professors for inviting me here to give this keynote. It's a huge honor uh to be here. uh very excited to see the incredible turnout um uh from the country and the interest in AI of course but also from many of my colleagues from around the world um in both industry and academia who've convened here. So I'm looking forward to a really amazing couple of days of discussions um about the way forward for AI. when we started uh DeepMind in 2010 um seems uh it's only 16 years ago now but it's almost a lifetime in terms of AI uh almost nobody was working on AI back then few people in academia but almost nobody in industry so it's been amazing to see the progress we've made in just over a decade um but at this point I think we're at a threshold moment um where AGI artificial general intelligence uh is on the horizon maybe in the next five uh five to eight years. So this summit uh comes at a critical moment um as we start seeing more autonomous agentic AI systems much more capable. I think we're seeing the beginnings uh of of um what those kinds of systems can do. And of course the opportunities are incredible in um for my my personal passion is using AI for science and to advance science and medicine uh with systems like Alphafold. I think we can revolutionize drug discovery and human health and also uh areas like material science and climate change uh with the help of AI. But of course it also comes uh with many risks too. AI is a dualpurpose technology. It's going to be the most one of the most if not the most transformative technology in human history. Um and that's just uh on the horizon now. And the thing about this technology is it's going to affect the whole world. everybody in the world. It's going to cross borders. Um so it's very important that we have uh summits like this, international summits to bring the international community together uh to discuss um how to uh uh make sure the opportunities benefit the whole world. Um and also how do we mitigate the risks? Uh and I think in order to mitigate uh some of the risks, it's going to need international cooperation. And um the first step for that is to have um international dialogue. And I think uh that's what these summits um starting in the UK and then in Paris and then in Korea and now here in India are for and have been really helpful in convening um uh many of uh the important heads of state and many of the important uh leaders in this technology together to discuss um what is on the horizon. So uh with that um thank you for having me and I look forward to the discussions here in the next couple of days. Thank you. >> Yeah. So good morning everyone and so you you started talking about how amazed you are at the progress that AI has made and you started deep mind in 2010 with a vision to solve intelligence. So are we there yet? Um no I don't think we're there yet. Uh I I have quite a high bar for if we talk about solve intelligence meaning building artificial general intelligence. Um then you know my measure for that is having a system that can exhibit all the cognitive capabilities humans can including in creativity, long-term planning, things like that. And today's systems are very impressive but um as we know they still have many flaws uh and things they can't do uh including consistency across different tasks that you would um want from a general system. >> So you did mention a AGI, right? So what do you think really that we can do to take where we are right now and move it towards artificial general intelligence as you define it? >> Well, when I look at the um current systems and uh what's missing from uh them being a kind of general intelligence, I would say things like continual learning. So learning after they've been trained and put out into the world. The today's systems, we train them. um we do various different types of training on them and then uh they're kind of frozen and then put out into the world. Um but what you'd like is uh for those systems to continually learn online from experience uh to learn from the context they're in. Maybe get maybe personalized to the situation that uh and the and the task that you have for them. And today's systems don't do that. Um also they have difficulty in things like doing long-term coherent plans. they can plan over the short term but over the longer term like the way that we plan can plan over years um they don't really have that capability at the moment. Um but I think probably the one of the biggest issues is uh what I would call consistency. So um today's systems they're kind of like jagged intelligences. They're very good at certain things um but they're very uh uh uh you know very poor at other things including sometimes the same thing. So for example, today's systems can get gold medals in the international maths olympiad, really hard problems, but sometimes can still make mistakes on elementary maths if you pose it uh the question in a certain way. Um a true general intelligent system shouldn't shouldn't have that kind of jaggedness. >> But but aren't humans jagged as well? >> Uh no, not in that way. I don't think so. So um I think if you're an expert in maths and many of you in the room are and or in physics or something like that um you're not going to uh sort of make a mistake on a strictly easier more trivial problem right you would have some way to work through that problem um similarly you know uh let's take the example of games which is very close to my heart and we've used in the early days of deep mind to train our AI systems uh you know today's general uh uh foundation models are very poor at for example playing chess um you know below kind of weak amateur level uh and that is not what you would expect from an AGI system. Um there are other tests too that I would have is uh true creativity. So AI is very useful as a scientific tool an assistant um or for solving specialized areas like Alphafold does with protein structures. But really what separates great scientists from good scientists is their creativity and their sort of maybe you could call it taste for what's the right question um what's the right hypothesis and it's much harder to come up with the right question and the right hypothesis than it is to solve a conjecture and um you know I would call that the highest level of sort of creativity and so far today's systems you know they don't have that capability um you know one way we maybe would test that is you could imagine training a foundation model with a knowledge cutoff of something like 1911 uh and then see if it could come up with general relativity like Einstein did in 1915. Um but that would be a good test I think for AGI and I think today's systems clearly would not be capable of doing that but I think this will be solved in time. >> Okay that's that's great. So you talked about u scientific tool this is a tool for scientific discovery right and so we see a lot of you know headlines about AI you know making great breakthroughs in science sometimes but uh uh you know how would this become the norm right I mean so do you see AI becoming the scientific tool for discovery soon >> yeah the reason I spent my whole life um and career working on AI is um I saw quite early on as um if we could build these kind of general models that were good at uh pattern recognition um they would be incredibly useful uh scientific tools maybe the ultimate tool for science um that's what I was thinking a you know a lot of science is about finding insights and structure in vast amounts of data that's perfect for AI and uh so I think we're going to enter in the next probably 10 years this new a new golden era for scientific discovery almost a new renaissance using these tools incredible tools um like Alphafold but I hope that will be the first of many uh that can massively speed up our research and accelerate scientific discovery across almost uh any subject area. So I think that's going to be uh the next period is is using these systems as tools and then after that we'll see as they become more autonomous can they be kind of like co-scientists with you like a PhD student something like that I think we're still quite away from that but maybe in 10 plus years that will be possible >> so just to reassure a good fraction of the audience you still see a role for humans in that future right >> yes I think um you know the next phase is going to be uh incredible I think for uh human experts and scientists the amount of work they'll be able to do and I'm actually really excited about cross-disciplinary science which is quite hard because you have to understand you know more than one subject area maybe two three four subject areas and then find some interesting connections between that I actually think that's where a lot of the really valuable advances are going to happen in the next few years these combinations of subject areas and I think having a tool like AI will really help um scientists uh learn about and be able to understand and process uh all of that information from you know multiple different uh domains. So so in some sense science is is is a well definfined field if you will I mean you can recognize success and so on so forth. So what do you think would be the role of AI in more abstract domains like policy and other kinds of public decision- making? I think we're uh I think things like um science but especially if you take coding and maths um are more amunable to the current systems we have today mostly because especially coding and mathematics but also things like games like chess um they are verifiable so the answer that the AI system outputs uh can be checked for correctness and so um it's very uh useful when you're training these systems you can have uh uh uh databases of questions and check to see if um 100% if it's right or not right. Um I think of course when you get into the arts and the humanities things like decision-m policy, you know, I'm not sure what you necessarily had in mind, but they're much more subjective. Uh they're hard to run the same experiment twice. So it's um it's difficult to get data about what is a good decision in those cases. So I think they'll be um those areas will be a lot harder for AI to um to sort of um model. >> So as a neuroscientist, so what do you think we have learned about human intelligence itself with all these advances in AI that we're seeing? Well, I think when you're in the early days of of of this uh I guess modern AI phase, which maybe you could say is the last 20 years um with the advent of uh of you know things like deep learning from from Jeff Hinton. Um a lot in the when we started at Deep Mind too, we took a lot of inspiration from the brain. Uh high level systems inspiration, not not the direct mechanics of the brain, but things like episodic memory, what does the hippocampus do, which is what I studied. um how uh obviously neural networks, reinforcement learning, your area um which we know the brain dopamine system in the brain implements. So we kind of took inspiration from the brain which is the only general in example of a general intelligence that we have know of maybe in the universe um as as a starting point and so we sort of knew that it was possible in the limit right and uh and I think that's why neural networks and reinforcement learning have been so successful because um uh uh uh uh I think learning is the key to the these modern AI systems working not being programmed with the answer like experts systems were in the '9s um like deep blue but actually allowing the systems to learn directly from data and I think now what I what I've I view looking back at at neuroscience is you know how efficient the brain is um sample efficient uh it doesn't need you know to ingest the whole of the internet to understand things so it's a it's a different what we've built now today it uses some of the same principles but it's been uh manifest in a in a very different type of um system than probably the way the brain works. >> Okay, thank you. So, uh, so one of the things that people always talk about is the safety risk, security risk from AI and so on so forth, right? And so, what does GDMs stand on this and how do you approach making sure that AI is safe? Well, we've been um when we again when we started Deep Mind, we we actually, you know, were planning for success. Our mission statement was uh solve intelligence step one and then step two, use it to solve everything else, which at the time, you know, was sounded like science fiction, but I think now is becoming clearer how that might be possible. Um and and uh applying AI to almost every subject area, but we planned for success. So um even though we were just starting out and the field was mostly uh just building um building up ahead of steam um we understood also the implications of that if that did turn out to be the case and we thought about it as a 20-year mission and I think we're basically on track for that you know around 2030 um then it would come with these attendant risks as well as the enormous benefits to science and medicine and all these things that I think we need as a society um to help with our other challenges, many other challenges that we have uh around the world. Um but also as these systems become more powerful, I think there's, you know, at least two risks that we've always worried about. One is um bad actors um human actors, but individuals, but could be also nation states using these systems uh and repurposing them for harmful ends um because they're dual purpose. Um but then also as we get closer to AGI and I think we're entering maybe a kind of agentic era should we call it where systems are more autonomous I think we'll see a lot of that happening this year and next year um then we have to make sure as well that the guard rails uh are in place that these systems do what we expect them to do and don't veer off um into uh areas that uh we didn't we hadn't planned for um and that could also be uh problematic. So I think those are the two challenges. There's a very sort of societal one which I think also is going to require international dialogue and maybe ideally a minimum set of standards um that is agreed internationally. Um and then the second one is more of a technical risk of how can we make sure these systems are robust and reliable. >> So I I mean setting aside all existential risk questions. So what do you think is the top two risks that we should address with with AI systems today? >> Well, I mean I I I I think I mentioned the two classes of problems. I think we need to worry about um things like bio and cyber risk um uh very soon. I think that the current systems are getting pretty good at um cyber and I think we need to make sure cyber defenses are more powerful than the attack vectors and it's something that you know we work on quite a lot at at Google and at DeepMind is um sort of using AI for cyber security um to make sure that of course it's very useful tool for cyber defense too but you need to make sure that the defenses are stronger than the offenses. So um you know I think those are kind of near-term risks. Uh but there there are many that we need to think about and and do a lot more research on and some of them are to do with uh um agreeing a sort of set of standards which you know I know many people including yourself are trying to work on. >> Great. Thank you. So again talking about international collaborations right? So you you said that we really have to worry on that work on that. So an audience like this or or or or a gathering like this right where we are trying to involve uh the global south very much in the dialogue right so what do you think would be the impact of such gatherings on the overall direction of AI do you think and are these going to make a big change going forward >> I think so and I and I think that's why um it's important we convene this summit around the world because it's going to affect this technology is going to affect everyone. It's um it's a digital technology so it can't really be contained by borders. Um there's things like open source so which is generally very good but also one has to think about if you found a vulnerability or or some issue with an open-source piece of software how do you recall it? How do you patch it? There's no recall. So we need to think about that. These are new issues with something like AI where it's hard ahead of time to fully understand if there are any vulnerabilities and um I think for the global south and and countries like India I think there's huge opportunity for the youth of today you you all have access to pretty much the most cutting edge tools in the world right I don't think that's ever sort of happened before maybe only 3 to 6 months after they've been invented in the frontier labs and I think and I can say as someone working on the coldface of this um we barely have time to understand what are the amazing uh capabilities that could be supported by these models you know in products and applied research so I think there's so much um uh potential there uh to be explored and I think we'll see a lot of that um and hopefully many of you in the audience too entrepreneurs here uh uh you can do incredible things maybe 10x of what you could do before because these tools are so capable and they're available almost instantly around the world. >> So I I have a question. It's more specific because you are right now in India, right? So So the Indian population like as we one of the things that a lot of people have been remarking is that the crowd at this summit is extraordinarily young, right? So this youthful energy, right? So you think what what what would be the role that India can play effectively in the future given the resource constraints of India and but also the availability of this talent pool. Well, look, I've been incredibly impressed already about the energy that's here and we heard from the minister that, you know, the youth of today and in India especially. I think when you see the polls on this are very positive about AI, which I think is great and um what I'd recommend to the students of today is to really lean into becoming incredibly uh proficient with these new AI tools. And I think over the next 10 years that will almost kind of make them superpowered in terms of what they're able to do, you know, whether that's business or science. Uh and it's a little bit um like the dawn of the computer age or uh maybe mobile or internet that we went through. Those um the the the the generation that grows up native with that technology will end up doing sort of incredible things that we can only dream of right now. And I think that's going to happen with AI. And I think India and and the youth here can be at the vanguard of that. >> Uh since this is a research symposium, can I can I ask you to get a little technical on the next? Sure. Great. So uh uh so we we we saw the evolution of how alpha fold right started off by you know building on top of existing work from the Baker lab and and then moving on to evolving all on its own right. So what do you think is the next stage technically in the evolution of these kinds of co-scientist models? >> Yeah. So well with AlphaFold what we what we we actually built a new completely new system but it would it required the PDB the protein database. So it needed the 150,000 structures that um humanity had painstakingly uh found over the last 50 years through experimental work. Right? And that turned out to be only just enough data to actually you know build a uh solve the problem and build a system like alpha fold. The interesting thing is in the debate we have uh at deep mind and and other places is what's the difference between the general system which you can think of like the brain and the tools that it uses. So um for us as as humans there's no debate about what's our minds and what are our tools because obviously it's physically separated. But if both things are digital and in some cases both things are AI the tool and the and the orchestrating system uh then what do you put in the main system and what do you leave as a specialized tool now in my opinion I think you'll end up with in in our case with foundation models like Gemini will use alpha things like alphafold as a tool so if you if you if Gemini wanted to or needed to fold a protein understand the structure of a protein I think it would be better for it to call alpha fold as a tool then put all of that protein information into the main um system and I think the the if you want to talk about it technically I think the choice comes down to if you put that data into the main system does it help with other tasks does it transfer to other tasks or does it actually degrade the performance on those other tasks so it's actually an empirical question so that's why for example coding and maths we put that in the general foundation models because Um, it turns out if you get good at coding or maths, you're actually better at planning uh and reasoning in general. So, it's a it's it's a useful t skill, but it also generalizes and uh but something like you know the the folding proteins probably is a is a very specialized skill that that wouldn't necessarily transfer to other domains. So, I would be of the opinion that we should leave that as a specialized tool. Oh, that's interesting because a lot of learnings from robot path planning was used for trying to robot path planning was try used to try to solve protein folding. So you think protein knowing how to protein fold will not transfer back to other domains. It might do but but we would um I I think it's we in fact we do these experiments all the time on smaller scale models where we ablate different data sets and we try and mix in certain data sets and see if they help or if they regress some benchmarks like it would be no use if you put all the protein data in and then it got worse at language for example um which is uh probably currently what would happen. So maybe over time with an AGI system you just have everything in in the one system. But uh I think for the foreseeable maybe you know future I think it'll be more efficient to still have um uh separate tools. Also those tools by the way might be hybrid systems in that they might just not they might not be just learning systems. They might also have uh built-in structures like Alphafold did actually about physics and chemistry and chemical bonds that you could learn but would be more efficient to just tell the system or or program that indirectly. >> So now that I mentioned the word robots, so I'd like to ask you what's next in physical AI? >> Uh well look, I think I'm getting increasingly excited by robotics. um you know I probably wasn't so interested in that 10 years ago because I I felt that the issue was the algorithms not the physical uh construction of the bodies. I thought the algorithms were the thing that was um behind. Now I think algorithmically and actually we're very excited about Gemini robotics because we built our foundation model to be really good multimodally so it could understand vision image the world around us. So it has a very good understanding of the physical world and that's exactly what you'd want for robotics um is a kind of general system that understands the physical context the robots in. So I think uh we're probably in the next two three years we're going to see some very interesting new breakout moments for robotics. I think there's still quite a bit more research to be done. I don't think we're there yet like some robotics companies are claiming. Um and I think we'll have humanoid robots and also non-humanoid. I think both will be useful. Um but uh I think in the next couple of years there'll be some really breakthrough uh moments. So I I think it's a very exciting space to watch and a good area to get into right now. So a little tricky question. So a lot of people are you know I mean that is a lot of fear-mongering around AI. We we know that most of it is unnecessary. Uh but um if you start getting humanoids that are running off foundation models do you think the the fear factor would go up? >> Um potentially. I mean it depends how we design those humanoids but I think um some risks go up too right. again depends on what you deploy them for and I think increasingly especially if the humanoids are pretty capable um and they're heavy you know that there are uh dangers and risks with that so I think we need to um have those guardrails that we were discussing earlier in place by the time uh there's uh a lot of robots roaming around >> great thank you so um we we talked enough about risk so let's talk a little bit more about the positive positivity of things. So you know a lot of the benefits of of all this cutting edge AI right now is still seems to acrue to you know the countries that have more resources right that can that have GPUs that can run their models there and so on so forth. So what do you think would take for AI to reach the global south benefit much more larger fraction of the population? So what kind of initiatives that we should be looking at? Well, look, I think we kind of touched on it earlier, but um these the leading foundation models, maybe there's three or four of them uh and and perhaps five or six uh if we include the Chinese models too, then um they're pretty much available uh very uh cost- effectively for um you know a few months behind. also open source I mean we work on um our own open source models Gemma which uh uh we'll be releasing a new version of soon which are very powerful for edge devices so I think that's very interesting areas really efficient models uh for you know computing on the edge whether that's um you know your phone uh or a lap single laptop or you know eventually robotics I think uh there's huge opportunities there for optimizing uh what those kinds of uh models do and the types of products or applications you can build on top of that. So I think there's um you know a lot of uh potential there for for for those types of um work to happen. >> The entire audience the auditorium went dark for a bit. So no no that's that is not signaling any kind of ominous uh thing. So don't worry about that. >> So I mean it's amazing. So I was actually there when you did the first uh uh game playing demo at one of the new side events and that was this tiny room even then it was packed >> and and this large auditorium is packed. >> So what's the largest size hall you think you can pack if you are talking nowadays Madison Square Garden? >> I don't know this is um pretty big one and I I hear it's streaming to many many people online. So um but yes I remember that that uh that Europe's event very well. It was a it was a hall maybe maybe a third of this size but it was I think it was standing room only and it was packed outside the door and that was really the first success that we had with um these deep reinforcement learning systems that we sort of pioneered that could play Atari games very simple games now but um but just directly from the pixels not giving any other information just maximize the score here the pixels on the screen and it was the first demonstration I would say maybe of the modern AI era of an agentic system doing something kind of challenging and interesting that um you know in this case a task that was designed for humans to find interesting and and enjoyable and somewhat challenging and uh I think it was kind of a watershed moment uh of course for us but also for maybe for the industry. This is back in 2013 I think and um that actually this thesis of uh learning systems learning algorithms this idea of generality that you don't special case uh uh the information or give give it um privilege prior information to the system that maybe was the way traditional AI had been done or old good old-fashioned AI had been done until then expert systems that actually that could scale to something interesting in this case an Atari screen with 20,000 pixels on the screen. You know, trivally small by today's standards, but very uh you know, very large uh action space and uh data space for the types of systems we had then. >> Yeah. Now they've become like the hello world of reinforcement learning now. >> Yes. Yes. And then of course that encouraged us to then do uh go on with Alph Go which was I think really the the big watershed moment that made the field and the industry set up a notice in 2016. and and I think started a lot of the commercial interest in in these technologies that we could scale this kind of deep reinforcement learning and learning systems to actually you know beat the world champion and the legendary you know Lisa doll in in our South Korea match. >> So and one thing I really have to say that I mean you wrote up everything about the Atari game player and also later AlphaGo that allowed the rest of the reinforcement learning community to catch up. So thank you for that. And of course my first success was I was actually in the room and not outside clamoring to get into the room to watch the demo. But so that was that's that's that's great. So again, so let's forget AI for a minute. Let me ask about reinforcement learning. So you know that Rich Chutton has been talking a lot about how how and and and David and Rich wrote this amazing amazing article on how reinforcement learning is going to drive AI forward. So what's your take on that? Well, yeah, obviously we've we've had many um debates over the years and I think it's uh for me if I was to say and maybe we can take this question more generally like um what do I think about today's foundation models and reinforcement learning of course reinforcement learning is an integral part of the post-training of these um uh these models and I think the inference time compute the thinking part of the the models uh could actually benefit a lot more from the ideas we pioneered in alpho the monte Carlo research and other things. So in actually many respects we need to combine the ideas we had with Alph Go with today's foundation models. Of course it's harder because you don't have a perfect model of the world, right? You need a better world model. Uh in games it's trivial, right? The the transition matrix. So I think that's an issue. But if you're talking about um uh if I was to guess today, I think the foundation models are going to like Gemini are going to be a critical part of the ultimate AGI solution. Um and then I think we'll have lots of interesting reinforcement learning on top. Um I I think eventually one day maybe 20 years from now we'll have a kind of more like an alpha zero type system where uh you know reinforcement learning can learn everything from scratch right um but I think uh actually that's not going to be the fastest way to AGI. I think it makes sense to use the foundation models and you know all the information that's already out there and learn that as almost like a model of how the world works and then do your reinforcement learning and planning uh on top of that. I think that will be uh more efficient in the first case. >> Is it still going to be the cherry on top? >> No, I think it's going to be I think it's in I mean you know you have to ask Yan about his cherry comments. I'm sure he's he can talk at length on that but I've never really agree with that. I think it's just a fundamental I don't really you know I think um obviously if you measured it in terms of bits uh then one can say well how much bits of information are you getting from the reinforcement learning but in my view and presumably your view is that not all bits are equal in terms of information of course if you get a bit about you know did you win the game or not win the game that's much more important than some random pixel on the screen right so to equate the theformational value of those bits um in just you know trivial your way is clearly incorrect in my opinion. But I do think that the foundation models um are going to be the question is is are they um going to be all that's needed or just a critical part of what's needed. I think there's no question they're going to be at least a critical component of um the first AGI systems. Uh so so I I so we're almost out of time. So I just want to ask you what's your message for the attendees of this summit? >> Well, look, I think my message is uh one of I would say cautious optimism. So, I think we're on the cusp of an absolutely incredible transformation um that's going to uh uh uh bring incredible benefits in science and medicine specifically is what I'm passionate about. And I can see uh revolutionizing the way uh we we we deal with human health. Um I think there's many amazing companies and and and tools and products to build on top of uh these systems and I think uh everyone in the world can can build on uh these AI systems to do that. Um but then also I would just add a note of caution which is um I think we will solve these technical issues given enough time and enough um brain power on it. I believe in human ingenuity and if the best minds work towards that I think we'll solve the technical risks. Um but uh we also need to do this internationally. So the societal challenges of that may actually end up being the harder problem than the technical ones. Thank you. So So everyone thank you. Thank you uh sir DeSis and Ravi for such a stimulating discussion covering the breadth of AI and reinforcement learning in such a short time talking about possibilities and challenges. I have been asked to tell you that the number of people waiting outside to get into the room outnumbers the number of people inside the room. So you are requested to please stay seated if possible for the next session before we have a break. That would help with the law and order situation of the auditorium and outside. So I kindly request the attendees to stay on for the second keynote uh of the research symposium which is going to be delivered by professor Dame Wendy Hall yet another fellow of the Royal Society and a professor of computer science at University of Southampton. And joining her as a moderator is going to be Dr. Anand Desh Pande, founder and chairman of persistent systems. Over to you uh Wendy and Anand. Yeah, that side might be easier. So we are joined on stage by Professor Dame Wendy Hall uh from University of Southampton and Dr. Anandesh Pandy for persistent systems. Please give them a huge round of applause. >> Okay. Annen, I don't have a clicker. I have slides. >> Oh, hang on. Okay. Yeah. >> Are you introduced me? You going to introduce me? >> Okay. All right. Let me start. So, good morning all of you. It's a pleasure to welcome and an honor to introduce a true pioneer in the digital age, Dame Wendy Hall. Long before artificial intelligence became the global headline and even before web reshaped our daily lives, she was working on hyper media and linked uh information systems, foundational ideas that anticipated today's interconnected and intelligent words. Few people have influenced both the birth of the web era and the global AI conversation. She has done both. She serves as the professor of computer science at the University of Southampton. She's a fellow of the Royal Society and the Royal Academy of Engineering, reflecting her rare ability to combine deep scholarship with real world engineering impact. Her contribution to the global computing community is equally profound. She's a fellow and former president of the Association of Computing Machinery, the world's largest professional society in computing. Through ACM, she has championed international collaboration, open science, and the responsibility of digital technologies, shaping the profession far beyond her own research. In recognition of her extraordinary contributions to science, technology and public service, she was appointed deemed commander of the order of the British Empire. At the moment when the world is asking how to build AI that is powerful, trustworthy and globally accountable, Dame Wendy's voice carries both authority and wisdom. Please welcome me. Please join me in welcoming Dame Wendy Hall. It's an honor to have you here. >> Um, hello everybody. Are they all coming in? >> Huh? >> Okay, fine. >> Are they going to come in? Let them in. >> We should let them in. Right. If they want to come in the seats, >> you want me to just keep going. >> All right. Well, I'll start because it's just it's so distracting. There's a huge crowd of people there. the crowd following Demis, you know, the um we are not worthy crowd went that way. This always happens to me when I speak with Tim Berners Lee as well. Um but I just want to say first of all before I forget a big thank you to um the uh Indian government. Abishek Singh is somewhere here. PJ Anan all the people to him for inviting me to be a keynote here. It is a huge honor and I want to say a few things that are a bit different this morning. So I have used some slides to try and explain where I'm coming from. So I'm talking about unintended consequences because that's what we've all got to worry about. Whenever you invent a new technology, you have to think about what might get wrong, what might go wrong. And um uh you will have noticed with Demis who I will I will preface these remarks by saying I have the hugest respect for Demis Hassibas. I think he's one of the greatest people in the AI field and one of the few that actually does address the challenges. But you heard him say on safety, we've got to do this. But no talk about how we've got to we've got to build the guard rails. We've got to keep things safe. But meanwhile, we're carrying on inventing more advanced technology. So that's what I try and want to try and get us thinking about today. And as Annan said, I was around building hyperdia systems before the worldwide web. Met Tim Berners Lee at the first one of the first worldwide web conferences. And you know, I remember him putting up the first website. I don't know how many people there's a lot of young people here. I don't know how many people remember the first website going up. There was one and it wasn't a very exciting place to be at the time. This is what happened. This is a graph that one of my PhD students produced in um 2013 uh just as the web was beginning to go get completely explosive. I'm going to talk about the chat GPT moment later. I would argue the chat GPT moment for the web was the invention of the smartphone. See, the iPhone was released in 2008 and that's when you could actually start using social media. The internet was there, but you could start using social media on the move. And um I could I tell lots of stories about this graph. I haven't got time today, but it is amazing to watch. There's a bubble. Remember the bubble? And um uh Facebook started in 2004 and little did we know because we we weren't anticipating people would do bad things with this system. We thought it would be used for the good. Um beyond this point the social media starts to take off and the oligopoulies grow. We hadn't foreseen that either. the fact that um Tim was always talking about lots of different people innovating on the web but of course they coalesed into a small number of big companies igopies with the Googles and the then Twitters uh the eBays the Amazons um and look as what what's happened with the internet and those companies this is what's driving the current AI revolution the internet's given us the access to the data the companies have that data and they have the deep pockets to invest in the new systems. And so we're w moving into a world we've got the issues with social media which we still haven't tackled that the unintended consequences of social media that's doing so much social harm. Didn't I didn't think about that in advance. We thought it would be for the good. and then also the um the rise of the big tech companies that are dominating today's AI field. So this was in um 2006 with Tim Berners Lee, Nigel Shabot, Danny Vites and others. And by the way, that's Rod Brooks there when he was head of MIT. He's the man who invented the the robots that clean your carpets. I robot. So this is 2006. We launched this concept of web science to try and understand what had driven the growth of the web. What the social consequences were and what they might be in the future. It's very hard to build scenarios when you're talking about people as well as things because you can't predict what people are going to do. So we drove this this development of web science. um say the stuff Tim talked about in his book weaving the web the concept of a social machine the concept of uh technology and people coming together to create artifacts that couldn't have existed otherwise Google's an example of that Twitter's an example of that and uh all the other we call we call them so we talked about web science being the theory and practice of social machines and could you know we were thinking about could We could we monitor could we anticipate the social consequences of the development of this technology? Does that ring any bells about what we're trying to do today with AI? And so I'm now going to leap forward because I've only got a short minute uh 10 minutes or so, five minutes left probably. Alan's going to we're going to talk in a minute. Um around 20 jumping forward to 2017 um the uh Royal Society produced a seminal report sorry excuse me a se seinal report on machine learning as we all we all saw that this demis said they founded deepb mind in 2010 was when the machine learning revolution was was come was there was coming and he said there weren't many in academia there are load hundreds of AI profess professors in academia. Um uh but anyway that's beside the point. And then um I was asked by the then prime minister of the UK Theresa May in 2017 to write a review of how AI could impact the growth of the economy. She was looking positive and job creation note there was we were asked to talk about that was the beginning of my world in of AI policy. jump again another five years forward. I don't have time to go into the details of everything to to what I call the chat GPT moment. 22nd 30th of November 2022 when open AAI released chat GPT and suddenly everybody in the world who had access to the internet through the web this all happens through the web um could talk to an AI an AI right and um there be thereby hangs the tail uh we anthropomorphize it a lot of people think you know they we've had all this the issues of falling in love with their chat bots and the the the all the um all the issues around people the vast majority of the world not understanding what this technology is and what it is they're dealing with. And then we got we had an era of a year or so of you know existential threats. So there's open AI saying here's this amazing technology does fantastic things oh by the way it could wipe the human race out in two years time right? How are people supposed to deal with that? Um, our prime minister at the time, Rashi Sunnak, who is here, I think. I don't think he's here, but he's here at the conference this year. Um, he uh he got very interested in this and um launched the first global summit on AI which was um Stem said in London. They were still talking about existential threats. That was his adviser was talking about them. but also he introduced the AI he he created the AI safety institute which is an important part of this story at the same time exactly the same time the UN launched its high level advisory board on AI it was a huge huge privilege to be on that this I believe is a way forward the um the I think the only game in town for the global dialogue that I we called for in our report governing AI for humanity and Demis called for on the stage this morning. We and hopefully there's going to be some discussion of this amongst the world leaders tomorrow. We actually we have to have global dialogue. We have to have discussions on standards and what values and standards we set for the industry globally that will be managed in the nation states. This I believe is so important and they announced their new scientific panel that RAV is on. other people in the room might be it's moving forward and we I think it's it's it's possibly the only game in town. I've just said that there and the other thing um so where are we today? The United Nations just launched their um uh panel, new scientific panel. Hopefully they'll launch the global dialogue at the um AI for good conference in in Geneva in July. And also the Yashu of course who's talking later produced the latest version of the safety report. Sorry. Um that was published last week 22 22 pages. because I hope you've read it all. I haven't yet. But um something new I want to talk about which I think is really the way forward building on those is in the UK is something I'm really interested in. remember back to why what we were doing with the worldwide web as it grew. Our national physical laboratory um NPL uh with the you know support of the UK government has just launched a new center for AI measurement. Oh that's bad in this slide isn't it? Sorry measurement center for AI measurement. This could be this could lead to the sort of Met Office for AI, right? Met office metrology office for weather forecasting. We're talking about AI metrology here. And I think this is a way to help us define what we mean by the science of AI. Can we forecast some? Can we simulate? Can we get the data we need to do that globally? Right. This is very important that we um nations we can share data um in order to build up the whole concept of AI metrology. Um you won't have ti time to read all this slide but it's basically about building a um industry for AI assurance. This is the future. This is one of the very particular ways we can do safety is how do we assure products? How do we assure people who are selling products? How do we um what license to people who need to use AI? Do we bring in laws that says that says if it's AI, it has to be has to say it's AI. Um all these sorts of things. And how do how do we measure the impact? I mean, you know, the Australians, good for them, are trying out an experiment for stopping social media for the 16 under 16s. How do we measure the consequences of that? Right? These are the sorts of things we have to be able to develop. And I'm partic this is where my life is going to go over the next few years. I also want to shout out for the UK AI security institute. Some of them are here I think um because um they do the most amazing things in terms of oh looking for the bad actors seeing a lot of it is very deeply um security based because they're seeing where oh I'm way over time aren't I Anna? and seeing you know who how what are the results of the um are any of the AIs going rogue basically and um the network of those which is the countries that have AI safety or security institutes is being called the international network for advanced AI measurement evaluation and science and I think this is so so so important I believe this is where we need to go I'm sorry demis but I think AGI a meaningless term or at best an illdefined aspiration. We need to work out what we're actually talking about here. It reminds me of the emperor's new clothes if you know that one. I'm told it is also an Indian folklore. What are we really trying to achieve? Uh yeah, and I'll just make um there's a difference between machine intelligence and artificial and human intelligence and we need to think about what are we trying to do with this. This came from a friend of mine, Pete Ry. Um, I should have put his name on there. Sorry. Uh, talking about I think of the machine as more like the Dr. Spock in Star Trek. And of course, we are messy, unstable. U, we have emotion. Do we, you know, people talk about AGI? Well, the machines will have emotion. They'll have consciousness. We don't understand what that means for ourselves, let alone trying to build it into machines. And you know that moment of in 2001 where the machine says, "I'm sorry, Dave. I can't do this right. That's what we want to be able to avoid. I just pay homage to what India's done with data governance. I'm I've been here I travel here a lot and people my friends here know I've followed the story of the ATAR what Nandan and the I spirit team did with that and now this is one of the things that India can really lead on. We can't have good AI governance without data governance and I'm on the UN working group on that. It's very difficult. Crossborder data flow is really hard stuff. Whose data is it? How do you value it? All those sorts of questions. Um, this is the end. Basically, you know, it's more about physical. We're not just measuring physical artifacts. We're measuring and assuring social machines. These AI is a huge force for good, but we've got to stop the bad things happening if we can mitigate against them. We got to reset our moral compasses here. It's not okay to do bad things with AI systems. We've got to let people to understand that, right? And it's not just governments and the technical compass, tech companies. It's civil society as well. We've got to all be more responsible. That's a big project at Southampton by the way, RAI UK. I'm just going to finish with this slide because also into I'm also into scenario building. How can we actually model the different ways that the the AI world can develop and AI meets people can develop? There's lots of forking paths. We got to decide which way we want to go. And we have to decide what type of world we're trying to build here. Which pathway are we taking? And I love by the way the slogan we see as we drive in. In India, AI means all-incclusive. Good for India. So, thank you Wendy. Um um I think you teed off uh many different topics and uh you were one of the original persons in the multimedia and then hyper media and the web over the years. Uh you have seen the web evolve. You started out by sharing that was very optimistic and then social media and various other things have happened. You have advocated for um you've seen this happen in the web. How do you see the same kinds of things happening in the AI world and what would be are you looking forward are you positive about where we are you worried what would be your uh learnings from the web to the AI world >> well I tried to explain this here we didn't get it right with the web I mean Tim is is try is building solid social link data to try and fix the web in terms of what we didn't see was what was going to happen to our data Um, effectively we give all our data to the not just the governments. I'm not talking about governments here. We if it's the retail companies, it's the big tech companies. We sign it over, you know, we all you tick the terms and conditions. No one reads them. You just the data's with them. And so they can they can therefore do what they like with it. And of course we get a I mean Ravi was talking earlier about reinforcement learning. Google was a huge reinforcement learning machine because and we were part of that. We were part of that social machine as we gave them our data. We gave Google our data but in return we got access we got a search engine that worked and and we kept you know we reinforced it every time we used it. Um I actually I like Gemini. I'm I'm using that because I feel the I feel comfortable that um the values that Google have are good and of course demis is part of that but um the what we can't what we we we know there are safety issues we know there are security issues but we can't really define them >> in terms of the social consequences we can talk about cyber security and of course we have our intelligence services fighting very hard to make sure the bad actors, humans or states, um aren't aren't using this technology to attack us um or to, you know, ruin our lives in that respect. But the social consequences we didn't predict with the web. We didn't predict what was going to happen with social media. Um and you know, we we um we need to find ways to try and think about what the social conscious will be of the introduction of this technology. We talk about oh I think we might come on to this we we have there's a lot of rhetoric about job losses >> um and the social consequence of you know unemployment uh caused by it but actually there are huge social consequences in terms of the use of this technology that we we just can't predict easily because we don't know exactly what people are going to do with it and that's the science I'm trying to as we started to develop it with web science I'm trying to talk about that in terms of AI because it's about as I say building um we're building social machines and we need to think about how we evaluate and test and forecast what might happen. Things that could go right and things that could go wrong. And it's really difficult. It isn't like forecasting the weather. That's hard enough >> but because you're trying to forecast what people will do and people you can't predict how people are going to react. particularly as a as a society. >> So what do we do about it? >> We well we have to start I think developing um ways of thinking about it. So building simulations using the data that we have um I mean AI might help us in doing that and um data it's all about getting getting as much data as we can and um encouraging a generation of data analysts that are looking at the data from this sort of this perspective um you know monitoring what happens. You saw that graph I put it right at the beginning which is a very simplistic way of looking back at how the web evolved. Um can you then extrapolate and predict what might happen in the future? >> So you easy by the way I'm not pretending any of this is is easy or >> I think we'll leave it to the young people here to explore new ways to see how we can learn from the past so that we can build a a better future. But let me uh you've been a big champion of inclusivity and diversity and various other things. I know your term during the ACM you did a lot of work on ACMW women and um you also alluded to the fact and we've seen posters about AI equal to all inclusive in the in this context. Uh do you think AI will help uh inclusivity? Are we going to get will AI make it possible for it to be more inclusive? Meaning other people who are potentially deprived will have access to AI so they can do lot more. Is that a positive thing or is the bias going to make it very difficult or what do you think about? >> Well, there you've asked me about three questions in there. >> Yes, I want you to I don't want to interrupt your answer. >> Well, let me try and unpack it a bit. Um, we're here in the global south because it's so important and I'm I'm really glad the summit has rolled to India this year. Although the scale of it like India is a bit scary was it the number varies but 15,000 250,000 yesterday. >> Um uh and a lot of young people which is great. Yeah. And I think that um making sure that AI is is used. I mean the the UN report was called we talked a lot about the global south when we were having our discussions global um governing AI for humanity right the whole world um so that everyone can have access to the good things that AI will give us and this is good old fashioned AI as well as the new generative AI um and um and I'm great believer um the Chinese are way ahead of us on this but robotics is the next big thing embedded AI in robotics will come and I'm sure there's a future in India for that particularly because in in farming and all sorts of areas that's going to be really big um in terms of inclus I think there is the issue of course of how we keep um make sure that the elderly like myself are included um this is a this is a world the young people here will be this is your world you'll building it right in in every sense of the of the word building because you'll be part of the development of it if you go into the tech world or um product AI product world and you'll be using it in whatever career you do. So it is your world. We need to leave it safe for you. That's what I'm really passionate about. Um and we need to give we need to build the frameworks and that those um uh well we talk about guardrails the safety rails that infrastructure I suppose is the word I'm looking for that we the young people here today can build on in the future to know that what they're doing is going to be as safe as we can make it. Um and and you know what are the we you know the things that put you put put people in jail for for doing bad things using AI that's um you know got create laws around that inclusivity um my big worry when I get asked about what keeps me awake at night about AI. Yes, there is a existential threat down the line if we get it wrong and we build AI uh systems I I don't use the term AGI we build AI systems that are more intelligent than us is that you know is that and they get out of control um and to make decisions on their own that are not good for us. Yeah, that's that's dangerous. My biggest worry is the lack of women in AI. Right. This is we are 50% of the population. I've fought my entire career to get women into tech and I feel I've singularly failed to do that. There are more and it's lovely to see the young people here. You don't see the female leaders. I'm one of the few women on this plenary stage. There are some others but tomorrow I don't see at the World Leaders Day. I don't think we'll see many women on the stage at all. And my friend you asked me on yesterday why is it because we we get women coming into the industry to and and um >> yes uh in India at least you know when we are recruiting fresh graduates we get about 40% women coming into the workforce. >> Yeah. >> But as you go higher up in the organizations the number of women and leadership positions comes to be lower. Well, this is it just does doesn't just happen in the tech industry, but it's particularly bad in the tech industry. Um, women get when you move up in the industry or in academia, you get fed up with being dismissed, being disregarded, being patronized, being told your ideas aren't good enough or I mean the number of times, and girls, it happens to me still. You put forward an idea and they say, "Oh, that's useless." And then a week later, you hear it put forward by a man and they go, "Oh, that's a really good idea. Didn't you hear me say it?" And my my friend Dame Steve Shirley um she had a lovely saying which said, "Why do women why do women leaders have flat heads? It's the constant patting on the head." Says, "Don't worry, dear. It'll all be all right. And that's the problem. And it isn't a problem women should be solving. It's a problem the men have to solve as well. You have to stop patronizing. You have to listen to us. And you have to encourage us. I had the most fantastic mentors, both men and women. And without them, I wouldn't be here. There are several times in my career where I wanted to give up because I'd been so people have been so rude to me or dismiss what I was saying. And it was my mentors who kept me going. and partic of the men I remember but particularly Steve Shirley, Martin Ree, the Royal Society who told me I could do it and I have you. You are an inspiration to not just the women of this world but also to the men. So thank you for keep doing what you do. Uh I've known you for many years now. I just want to shift this since we are here in India and global south. Clearly from from the point of view here we see that AI is completely dominated by two countries 10 companies. What do you think is the future? How do we change that or is that important at all? And what happens to the rest of the world maybe in case some somebody decides to shut the taps off somewhere? So what >> to shut the systems down to certain countries or not allow other countries to do it because of >> well I think that um again it's good that we're here this year because yeah the first uh summit in the global south it's so important that um this the countries I mean India's got the scale to do it. I mean to be honest with you India could do whatever it wanted to do if it puts its mind to it you know um and and the because of the scale I mean you you want to live in a little country like the UK you know once our navies ruled the world but we're actually a small island off the coast of Europe with with only a few million people so for us to even for you for us to scale up with a big company is really hard to do in the UK um I am very excited excited about what's happening in the UK. Our governments put a lot of money into AI and I talked about the new um a the safety institute and the and the measurement institute. Um we tend to lead in the soft power area and I think the whole um uh the AI assurance industry this is going to be a major industry. I mean you think about um how you buy insurance all the time for your health, your car, your house. We're going to do that for AI, right? There will be all sorts of insurance products that we will build, we will buy. Um, and people I mean it's the same when a company buys some AI, they've got to know it's going to work. Who's who's bl who do you blame if it goes wrong? So all there's a whole new new industries that are going to grow and also the other thing is amazing when I look at I'm I'm not I'm more I know much more about India than I know about Africa but I do know in both countries I have seen the development of technology where it leapfrogs what's going happening in the f in the the west or the east because you take a new idea and then you use say what India did with smartphones amazing what you've done with the adhar and the you know I find it hard to pay for things here because I can't get onto your system but it all looks so easy and then what's happened in Africa in Kenya and Uganda and places where they're using the technology it's quite amazing what will happen and this is people's being people being creative and innovated in terms of new technologies and that's that so every government in the world needs an AI strategy that fits for is fit for purpose for their country and it's not one sizefits-all and I think that Um, you know, we're talking about sovereign AIS. Do countries need their the LLMs in their own language and with their own data and I uh small, you know, the SM SLMs. Um, I think this is this is a world that's emerging very much so. Um, it's very exciting and I think there's just everything to play for. I'm very positive although I talk about the negatives, I'm very positive about this future. >> Thank you. Thank you, Wendy. And I want to now move it to the younger people who are in this room. You talked a little bit about jobs and uh what happens to students. What should students be learning now? And uh what do you think is the future of work and employment in the AI world as you see it? >> Well, okay, this is what we need to start measuring. We need to start gathering the data um around the world of what happens as the AI introduces. I mean, it's all very well say we're going to measure AI, but we can't do that without data and evidence and things to measure. So, I'm calling for this to happen around the world. We need governments to and companies to share data about what's happening um as much as they can. Clearly there's sensitive data you can't share but um and to um to enable researchers um in industry or in academia to analyze that data and see what the trends are see how things because it's all hypothetical I mean there's a lot in the UK at the moment in the press about oh the jobs are going the frontline jobs are going um there's also the jobs are going also because there's not enough money in the economy and be I would I won't go political sorry I won't I I won't criticize the current government just in case they're in the audience. Um, but because I don't agree with all their policies, but you know, there's all sorts of economic reasons why jobs are going for young people in the UK, not just AI. I do think it's ironic that um programmers are one of the first to be hit, people who write code because and we've seen the applications to our computer science program go down because the rhetoric is that companies won't need programmers, entry- level programmers, because the AI can do it. But the AI doesn't at the moment decide itself what it's going to do. Someone's got to tell it and someone's got to check that it's correct. Yeah. >> And so and we we can't we we need experts in the field of computing and software engineering. So the way they're trained might be different. Uh but we're going to need those experts uh in the future as um and I I like to think about teams. I like to think about augmented intelligence. So the AI augments our intelligence and talk about teams of humans and machines working together to do things better. So do you have a specific message for the young people here who are studying various subjects should they be investing more in computer science or do other things? Well, I don't put it like that. Everyone needs to understand just like, >> oh, when I started out, we all had to learn more. I hated I was a pure mathematician. >> I hated computing. Hated it. Now look at me. Um, I think in the abstract that's what I've always loved, but I had to go I I did my PhD in pure mathematics and then I there were no jobs, right, for pure mathematicians. There really are. And the computing was clearly the next big thing. The micros were coming out. I wrote wrote my first AI code on a BBC Mic B micro. It was a um program to um intelligent tutoring system in 1982 is when I wrote that in micro prologue. And I and I'd learned that because I went to do a master's degree in computer science part-time at um City University to learn about the computing. this poor mathematician, pure mathematician learning about computing because I knew if I was going to get into this world, I had to understand it. So I think and my passion is about explaining AI to people who don't know what an iggon vector is. Now all the mathematicians and physicists will know what an igen vector is, but that's a small part most of the population are not going to ever know what an iggon vector is or want to know. And I so what we're doing at Southampton is two things. One is we've developed an an online masters for non-scientists, right? An online masters in AI for PE non-scientists. Um and I'm I'm passionate I always have been passionate about the interdicciplinary work. I do loads of work with social scientists, historians, geographers, musicians. Um and um so I'm passionate about the interdicciplinary and about how we um as as Demis was talking about we go go um across the disciplinary boundaries but but they need to know about you know everyone needs to have some understanding about artificial intelligence and this is the most for me this is the most important thing. So, so young people, if you're not, you learn about it. However, whatever's the easiest way for you to do it is to um and buy my new book which is coming out in May or June, which is called AI Explained, and that's for non-scientists, too. >> Thank you very much, Andy. Sorry. >> I think we are um our time is up. Uh so, I'd like to uh really thank you for being here and for sharing your perspectives. Yes, we will all buy your book. Hopefully, you will come back again for the book tour and uh we would love to host you again when you can share more details about your books. Thank you very much and thank you all. >> Thank you professor Wendy Hall and Dr. Anandesh Pande for a very uh important conversation highlighting the need to do more as we build the future with AI. Thank you very much. Uh we are now at the place of a welldeserved break. I think we would all want to you know stretch our legs but before we do that I want to make a couple of important announcements. We will reconvene for our panel at 10:55. I request you to be seated by 10:45. We are going to have two parallel panels. One is a research dialogue uh on AI for science in this room and one is a international panel on challenges of global south in level one room number 7. Uh secondly people who are going to present posters uh can be beside their display boards starting 10:55. So we'll meet again at 10:55. Thank you very much. >> Uh sorry an update. Apparently there's a lot of crowd on your posters already. So if you are a poster presenter and you would want to catch more people, please go to your posters now and you know start talking about your research. Sitaram, principal researcher at Microsoft Research India and uh it's great to see everyone turned up in such large numbers here. So we're going to start this session actually um with a video from Professor Fe Lee who couldn't uh join us sadly but uh she wanted to um you know convey her thoughts. So we'll be playing that video and then starting the next session. Distinguished leaders, colleagues, and friends, I'm deeply honored to address you at this historical gathering. I want to express my sincere gratitude to Prime Minister Modi for his vision and leadership in convening this summit and to additional Secretary Cinch for this kind invitation to be part of this moment. Though I cannot be with you in person, I want to share my excitement for what India is building and what this moment means for our shared future. Historians will look back at this period and call it the first true era of artificial intelligence, a time with civilizational consequences. Every sector, every industry, every nation will be touched by this technology. And this is precisely why gatherings like this one matter so much. Today's AI has achieved something remarkable. Large language models can write, reason, and synthesize information in ways that seem impossible just a few years ago. Yet, for all their capabilities, these systems are just the first steps towards building intelligent machines. I firmly believe that the next frontier of AI lies in what I call spatial intelligence. The capability that connects perception, reasoning, and action in 3D and 4D worlds, enabling machines not just to see and talk, but to do. 540 million years ago, the emergence of vision triggered what scientists call Cambrian explosion. a sudden flourishing of life and complexity. Vision gave rise to understanding. Understanding enabled prediction. Prediction made purposeful action possible. And from this chain, intelligence emerged. We stand at a similar threshold. Spatial intelligence will transform how AI perceives and engages with three-dimensional spaces with applications spanning scientific discovery, education, healthcare, robotics, and more. Imagine AI systems that can assist the surgeon in the operating room, help a farmer, monitoring crop health, or support an elderly person at home with dignity and care. This is not speculation. This is the research we're pursuing right now. But let me be clear. The purpose of AI is not AI itself. The core mission of artificial intelligence must be to expand human capability, not to replace it. AI should amplify our creativity, deepen our connections, and enhance our sense of purpose. It should superpower our students and teachers to transform lifelong education, assist our clinicians and patients, and help workers stay out of harm's way while increasing productivity always. It must respect human autonomy and dignity. This is what we mean by human- centered AI. It is not a slogan. It's a discipline. one that demands we bring together technologists, social scientists, policy makers, and communities from all walks of life. If AI is going to change the world, and it will, then everyone from everywhere must have a role in shaping that change. I believe this summit embodies that spirit and I'm optimistic about the future. Not because the road ahead is simple, but because gatherings like this are bringing together committed leaders and brilliant minds to build something meaningful together. Thank you for the privilege of addressing you. We're very grateful to professor fee Lee for her kind and encouraging words. And now we start with the next session um at this hall which is a research dialogue the first research dialogue of the day and this will be moderated by Dr. Shipkumar Kalyan Raman who is the CEO of ANRF and uh the speakers for this will be Dr. Acha Sharma, Professor Allison Noble, Professor Neil Lawrence, Dr. Bonnie Craft, Professor Priya Donty and Dr. Pushit Kohli. So I welcome everybody on stage and um over to you Shiv. What does that smell? Good morning. It says time's up already. Maybe it's for the last one. Good morning, everyone. How are you feeling today? >> All good. Okay. So, it's uh it's my privilege uh to um host this uh panel uh for you. Um we have the who's who of folks doing things uh in AI for science and engineering. Um so um uh one of the exciting things and many leaders have told us that um you know one of the biggest uh contributions that AI will do for the society is transform how science uh is done and transform the acceleration of the impact of science. So I look forward uh to a wonderful dialogue here. We have about 85 minutes and um you know in terms of the format we'll keep it super simple and conversational if that's okay. Um you know I will request each of our panelist in order here to give a opening statement and uh specifically reflect on um you know one and um uh and uh what they see in terms of the acceleration to impact. Uh this conference is about impact as a theme. Um and um this particular panel is AI as a catalyst. So a catalyst accelerates um and you know what um can AI do to accelerate discovery um and uh both fundamental discoveries as well as accelerate the conversion of science and the translation of science to its impact. Um and also where um and since we have a lot of young audience, I will request the panelists to also reflect on um uh you know what does it mean for the younger generation here as well as what they can do to contribute and um uh since we are in the country of India what can India do to contribute as well um and uh what is the opportunity and potential there's a lot of discussion about risks and I would like to uh bias this conversation a lot more on opportunities um and of course please feel free to balance that with risk and then um you know uh what can we all do to being a positive force and science as a positive force for transformation. Okay, these are the few thoughts I have um but without uh any further ado um I thought I'll start off by saying how can AI win us help us win a Nobel Prize but you know but I'll keep it simpler than that without further ado Bonnie. >> Wonderful. Um can everyone hear me? Okay. Uh it sounds like it can. I'm Bonnie Croft. It's a honor to be here and a pleasure to be amongst such esteemed colleagues and thank you so much for inviting me to be a part of this. So I lead a team uh that focuses on AI for science at Microsoft research. Uh we focus on two main things um molecules and materials. So specifically how can AI enable the discovery of new novel molecules and materials and the motivation for that is pretty simple. um the the limits to discovery really doesn't come down to imagination. It comes down to the speed at which and the depth to which and scale to which we could explore. So our hypothesis is that we can use AI as a fast surrogate for some of the very expensive slow steps within the scientific process. So often times we have to compute the properties of molecules and materials that takes uh extensive amount of compute time experience uh domain knowledge um and experiment is even more expensive. So what ends up happening is the scientists are limited to a smaller space to which they could actually explore. So, if we can use AI, we can open up opportunities to find novel molecules and materials that can help to solve some of the world's greatest challenges today. Things like new medicines for diseases that we haven't been able to treat yet, um solutions to the energy and climate crisis, new materials for sustainability, and many many more. So, I'm very excited to be here. Um especially be a part of this event in India. Um you asked about how India can can take part. Um I do think uh very few places in the world have as much scale and talent as India. Uh this is a nation of doers. Um and so I think there's an opportunity here for India to be a part of this for the young people um for you know the the massive amount of talent in in STEM science technology engineering math computer science to get involved and be part of the scientific loop. So ultimately the way that we accelerate scientific discovery is by bringing AI um to help us find the new opportunities to explore more expansive space of discovery um and have India be a part of that as well. Thank you. >> Thank you buddy. Go ahead. >> Okay. I'm I'm Allison Noble and I think I can build a little bit on on what you were saying. I work in healthcare AI and that's a very diverse topic. So I can talk about that for probably the whole day and beyond. Um and some of it as as we've heard and you you've just mentioned the the the advant advances in AI are really helping in in the discovery side. Um but there are some other areas. I work much close much closer at the interface working with clinicians and there there are some early papers coming out that are really um trying to get people to think of of doing medicine in different ways and by that I mean um taking large sets of data that are taken of patients um some of that will be imaging which is my my background some of it's then um following those patients but then it's using um thousands and thousands examples of that to be able to maybe discover new ways that we can manage conditions. And why this is so important is a lot of medicine has been driven by um what you're able to measure at the time um in imaging is what you see in an image. And with AI now you can discover the hidden patterns in multimodal data that might suggest totally new ways of managing patients. And this is this is still the future though because even if you've got a discovery that translation into practice takes a lot of time and effort and this is why when we talk about some of the excitement of AI discovering a new algorithm that's only the beginning that's the beginning of the journey of getting that that model into practice and in medicine that's a very complex process. So some of my my research is actually thinking more about that is having developed a model. I work with ultrasound. So we've been working for many years on how you can make ultrasound an easier technology to use. Um you need to make it easier because humans can't recognize the patterns in ultrasound. So what we've been working on is both how you recognize um patterns but with AI that go beyond what humans can see. Um, for example, estimating the gestational age of a fetus from a scan, you traditionally fit a circle or you fit a line having captured an image. But actually, if you want to date a pregnancy, you can you can do it as well, if not better, at certain points in pregnancy if you pose it as a pattern recognition problems because the acoustic patterns will recognize elements of fetal development that humans can't actually see by eye. So there are all these opportunities, but this then gets in into the debate of you now have tools that where humans work with AI and the early papers in in healthcare were very much trying to show that you could automate um processes and show that AI was as good as a radiologist and radiologists were really scared about this that they would lose their jobs. But we've moved on from that now because what you realize is you can automate certain tasks but a lot of the time you need humans working with AI and then you get into all the sociotechnical issues of how do you understand where a human will make a better decision with AI or not evidence out there at the moment very mixed um that for certain tasks um AI helps in other tasks it doesn't help and this to me is really important important that we have a lot more research in this area to really understand um this this area it's soft called human AI collaboration um at that point I'll stop thank you >> thank you Alison Pushmid please hi so I'm push I lead the science and strategic initiatives unit at Google deep mind and the mission of the organization u of Google deep mind is to build AI responsibly to benefit humanity. And when we think about that last part of the mission statement which is benefit humanity, what does that actually entail? When we talk about AI, AI is not just a monolithic sort of concept. If you think about what is even intelligence, there are different forms of intelligence. There is common intelligence in the com that allows us to solve tasks like image understanding. There is expert level intelligence which where some humans some have become experts in solving incredibly hard challenges. Being able to solve and find proofs of immense challenging maths problems or being able to diagnose a disease by learning about medicine or by thinking about uh sort of how should a legal contract be specified. So that's expert level intelligence. And then there is another form of intelligence which goes beyond human competencies where there is no human today which can solve that particular task. An example of it is the protein folding problem where you are given a sequence of a protein and you are asked can you tell me the structure. No single human just by reflecting on that sequence of amino acids which constitute a protein can tell you what is the 3D shape. And that's superhuman level intelligence. So when we think about the impact that AI is going to have, we have to think about all these different competencies. The first competency of common intelligence, it will make intelligence much cheaper, much more available and much faster. On the expert level intelligence, it will democratize expertise. So look at a country like India where it has challenges in terms of providing health care high quality health care to the 1.4 billion people in the country. Not everyone has access to the highquality medical sort of healthare needs that are available to sort of a privileged few. So can we make sure that every single person on the planet has access to that deep intelligence? So that's the promise of uh AI for at the expert level. My own work is mostly focused on the superhuman sort of part and this is where I think the greatest promise of AI lies. If we think about u ourselves as a species as humans we have come a long way in our understanding of nature and reality. But if you think about the last few years and reflect on what has happened, think about climate change, think about the co pandemic, that really shows us how little we know of nature. Once the virus sort of evolved or sort of came in generated these these sequences and the whole world had to stop. That's essentially the limit of human intelligence. We have we have so much more to learn which is why we need to have AI to solve these grand challenges of understanding what proteins look like, how cells work, how organisms work, right? That's the the promise of AI for biology. In material science, as Bonnie was mentioning that if you think about human civilization, we teach history in school in terms of how humans were using materials. We went from the stone age to the iron age to the bronze age and depending on who you ask we are living through the silicon age or the plastic age but it tells you how important materials are to humanity like each material gives us a superpower which completely transforms civilization's abilities to do certain things. So can you imagine what will be the new magical materials of the future and how will we invent them and that's where we need this superhuman intelligence to really think about these amazing materials like room temperature superconductors which can sort of open up new advances in how we transform energy can come up with high sort of magnetic field for fusion reactors give us abundant sources of energy that is the promise of AI I so yes there is a sort of when we talk about AI we think about all the the economic impact that will h that will happen and there will be many changes but there's a lot of positive things to look up to this will all need to happen with a sense of responsibility and like with regards to India I think that and not just India but across the world I think one of the very important elements is that we really make need to make sure that people understand the strengths of this technology but more importantly they also understand the weaknesses of this technology because if you are not able to understand the weaknesses of with the technology you will basically have a formula 1 car but you will not know how to drive it and you will crash. So access and understanding I think are key elements that are needed not only for India but for the entire world and especially for the global south. We really need to make sure that people have access, they understand how the technology is shaping up, what are its weaknesses and how can they used it responsibly. Um, so I'll stop. >> Yeah, thank you push. Yeah, please go ahead. >> Hello. So, namaste everyone. I see that there are many many young people here around the age of 30 35 and they must be wondering what are these people talking about AI you know it's us you know who know about it and I've seen some posts like that on social media it's all right so when I was your age I was fortunate to be landing in the laboratory where the first website was released and that was www.ern.ch CH How many of you have heard about the Higs Bzon? >> Oh, great. Wonderful. Now, how many of you know that it took 30 years to build the machine? The R&D for the accelerator that you mentioned, you know, superconducting accelerators, that took of 10 years, 10 years to build it and then another two, three years to commission and run it. um the algorithms that were needed to look for the Higs Bzon for which the probability was 1 in a billion collisions. We needed data 2,000 trillion collisions, proton collisions, right? So the algorithm making and the searching for anomalies in the data has been the forte of scientists working together. So the message here really for all of us is collaboration and all the guardrailing will come from collaboration understanding the uh the the troubles that are coming in front of us we have actually gone through the cycles as you just mentioned also. So the 30 years in which I have seen from paper to the large experiments which cost us more than a billion dollar each and then the operations that also cost in same amount per year. We need to be responsible. We need how uh responsibly we'll be able to take this forward. And AI is another challenge that is in front of us now. In the past it was about uh looking at how to deploy the web and the web itself was the precursor I would say to a lot of um domain related advances that you see in every possible domain of which we've already heard we've heard healthcare materials covid came as a bolt from the blue and uh you know everybody stopped to think a bit on how to take this forward responsibly and we can't just take technology ology and science and research and then put it back in the drawer once we finished the problem. You know, we have to we have to continue and we could pick up the challenge of COVID because there were tools and because there was science of understanding and because there was funding that was made available in good time by the governments all over the world so that we could all be prepared. But I would still underline that the bottom line was collaboration. And why do I say that? because I am one of those 10,000 scientists who was involved in the discovery of the exig boson and so one upon 10,000th of the science breakthrough prize of 2024 is also I can say one of my accolades but next generation will not be 10,000 it will be you know several factors several orders of magnitude which means the whole world is going to work together and particularly for the global health. Think about it that every classroom or every university or institution and our uh premier institutions in the country for that matter who are already doing cutting edge work. When we started working for the LHC, we did not know the solution. We did not know whether we'll get there. We did not know whether we will be able to solve the technical problems you know really technical problems because 27 kilometers of the large hydronone collider the protons cross the border from Switzerland to France 40 million times a second. So crossborder understanding is very important not only in the protons who go without passports but also within the governments and also of course you know how to deploy the understanding and how to deploy the information and of course you know the uh the beams match with submicron precision. So I think that here is an opportunity for us to look at our societal issues that we have in our country and in the world. In fact for that matter if we look at the larger picture the the climate change environment pollution in our country we have we have some thoughts on how to solve them and I think we have the tools with all the precursors of AI if we look at what we have done in the past that we can deploy for um for solving these issues and I would love to see all those institutions involved in the solving of these kinds of issues. Thank you. >> Thank you. Needle over to you. >> Oh, well that's a such great contributions so far already. So it it's also showing sort of how vast the topic it is. So when we think about science, you know, Bonnie sort of emphasized um the importance of discovery. Allison's talked about the importance of the human machine collaboration. Um Pushmittz talk talked about the superhuman capabilities and of course Aana's talked about how we all have to work together and collaborate to create science and it it reminds me of something that I think artificial intelligence or the notion of it which I think the word is already problematic. I agree with Wendy that the notion of AGI is deeply problematic. Uh because intelligence is very personal. It's very human and I think when we think of India and and actually eastern cultures in general my my sense is you have a much more sophisticated understanding of intelligence um because the religions in the east tend to accept different forms of deity that express different aspects of humanity um in a way that religions in the west don't. So I think some of the hang-ups we have in the west you don't have here and I think that's really exciting. Um but then it's what does it do? I think to me the AI itself gives us a place to stand and reflect on ourselves, reflect on who we are and our institutions. So when we think about doing that in science, I think we can see some enormous opportunities for impact in India and and for the audience. And I want to sort of step back to people who've talked about the philosophy of science like Thomas the structure of scientific revolutions and POPA conjectures and reputations because science isn't just about discovery. It's about understanding and what it means for us to understand. But not just us as individuals, us as institutions. And you can see in a number of ways we're failing. We're failing when not everyone understands the higs bosen and why it's important to spend a billion on such experiments. And I think one of the ways we're failing can be seen right at the heart of what Thomas tells us. He tells us that the paradigm of science, you know, he's writing in the 1960s is stored in textbooks and he talks about normal science as solving puzzles within that paradigm. And then he talks about paradigm shifting science. So big discoveries like Einstein that change the way we think about the world around us. But there's a fundamental problem here. Nowadays the paradigm of science is not stored in textbooks. It's stored in machines. And some of those machines are storing simulations and complex ideas that we don't have individual access to. Now I got into this field sort of 25 years ago because I was an academic who wanted to apply machine learning and it seemed to be science was a very sensible place because science is all about academia. Um now what I see as the opportunity here is increasingly people have become isolated from the science and I think particularly with large language models as tools there's an enormous opportunity to allow people to get back in contact with that and to reaccess science in the same way that a student a 100 years ago would be accessing science through textbooks that you can access all that science stored up in the machine through these large language models and I hope that that's going to be a revolution in science events where we see again you know going back to I think some of the hopes at independence for India the foundation of the IIT the foundation of the science institutes that that India was going to be a partner in those scientific discoveries as it has been but not enough of it happening here too much of it through diaspora too much of it not accessible because the technology for science has become removed from the place where the creative people are and I really hope we can see that change. >> Thank you, Neil. Fria, your opening comments. >> Right. Yeah. So, thank you so much. So, um my name is Priya Donti. I am an assistant professor at MIT as well as a co-founder and chair of a nonprofit called Climate Change AI. Um and my angle on this topic of AI for science and engineering is more from the engineering side and specifically thinking about the power grid. So the power grid is something that I think um many sort of take for granted, right? We uh switch on a light and unless there's a planned or unplanned outage, hopefully the the light will come on. Um and yet behind that, it's a very complicated system. It's a system where the amount of power that is being produced and put into the power grid has to exactly equal the amount that is being consumed on the power grid at every single moment in time. Um, and this is incredibly complex because first of all, we have a lot of variation in how much demand is on the grid at any given time. And as we aim to work towards kind of decarbonizing power grids or moving to more distributed forms of power, we also have to deal with the fact that the amount of supply we have, solar and wind for example, varies based on the weather. So, how do we manage this kind of increasingly complex system? Um we've historically done this using kind of optimization electrical engineering controls paradigms where we actually write down explicitly the sets of equations that we want to solve over on the system and solve them. Um but the challenge is that this paradigm is not sufficiently scalable. It's much too slow to solve the problems we actually need to solve to coordinate the power grid. And so this is where AI can potentially play a role in terms of both helping us reduce the uncertainty of quantities like demand and renewable energy by helping us to forecast these quantities more effectively. Then given those forecasts to help us to actually control the different devices on the power grid, our power generators, our batteries, our inverters um in ways that are more scalable. So I think earlier this concept of surrogate modeling came up also in in one of the other panelists remarks. So how do we actually use AI to learn fast approximations to some of the models that are used uh optimization models that are used on the power grid? And then third, how do we actually envision new paradigms of managing this power system? Um historically because of the power generators were big, we're centralized. there's been a very centralized way of managing the power grid, but kind of AI and reinforcement learning and control technologies kind of allow us to envision a power grid that's more dynamic, that's more distributed, where there's more kind of localized control. And so these are some places that I think AI can play a really useful role. What comes up though when designing AI for the power grid is that even though there are commonalities with other areas. So some of these terms I've used around kind of control and optimization, they come up in other scientific fields, they come up in robotics, but sometimes the notion of let's say kind of physical feasibility, the notion of safety, the notion of interpretability that we need on these systems is sometimes very or subtly different from what that means in in other scientific areas. So there's some aspect of the fact that the way we design AI for these systems often looks a bit different than the way we design it for other systems. So my own research group for example, we develop ways to kind of write down the equations associated with power grids and actually embed them into the way we design machine learning models into the way we kind of design neural network layers. And the reason I bring that up is because I think that as we think about kind of the role of let's say India in kind of developing AI, I think it's important to recognize that the way we develop AI is deeply contextual when it comes to both what problem we're trying to solve. Kind of the way that our models look look different because we're designing for different requirements and also depending on where we are trying to solve that problem. For example, electricity demand forecasting is a problem that's considered kind of solved in the US context because we have pretty steady electricity demand barring recent data center growth in many places. And so data about kind of how electricity demand looked last summer will reflect roughly what electricity demand looks like this summer in the Indian context where in that one year's period of time you'd have had kind of many more buildings put onto onto many more buildings built kind of many more air conditioning systems installed installed your data looks different and so whereas kind of people developing time series forecasting algorithms in the US wouldn't have to think about what's called distribution shift in machine learning the idea that kind of this underlying situation is changing people innovating on that in the Indian context would and so I think that kind of where I kind of hope that India kind of plays a role here is in recognizing that I think a lot of the most interesting innovation comes from a bottomup understanding of what the problems are on the ground and a recognition that even scientific and technical challenges can look fundamentally contextually different in different places and that doesn't mean there isn't the capability to sort of share knowledge and and collaborate between different places. Fundamentally, for example, power grids are governed by the same physics in different places. So, there's clearly some shared knowledge. But I that I think this paradigm of kind of developing AI needs to come from groundup understanding and then collaboration that joins that knowledge rather than sort of a top-down paradigm where kind of a small set of people develop models and then we quote unquote specialize after the fact and as a result presumably miss I think a lot of the richness that we could have incorporated if we had um empowered more people to contribute to this paradigm of AI. So I think this comes to collaboration and I think basically this goes well beyond access to kind of ensuring that many people are upskilled and educated and able to contribute to the ecosystem um such that the models are built using their knowledge their context from the get-go. >> Thank you Priya. Um I want to bring this conversation back to what Falee started off with. She started off with 540 million years back and talked about vision. I mean I I don't want to go that far. Uh you know we could start from say the renaissance period when science really took off um and um we moved away from darker ages towards uh the more enlightenment the more uh critical thinking more reasoning the scientific method hypothesis uh leading to measurement and then building theories and so on. So um in those periods there were many instruments that came around. You had the telescope, you had the microscope. So you could see into the stars, you could see into smaller things. But what is this AI thing? How do I even make sense of uh how does it fit within the paradigms of instruments like telescopes, microscopes? I'm I want you to uh each one of you to put yourself in the shoes of the scientist here or the engineer here or the young person here who wants to be a scientist or an engineer and maybe if you can also concretize it with one of the things you're doing uh you know Bonnie with uh you know the wonderful things that you're doing in your organization and each one of you in your things and then try to translate for them you know how can I take this concrete technology or the models and things you're building and then how do I how does it translate to hey if I'm a scientist how do I use the stuff you're talking about how do I even mentally map it to you know what I understand of a telescope microscope or other sorts of instruments and how's my life going to change uh how does uh my life as a scientist or an engineer going to change um if you wouldn't mind uh taking that dialogue and doing one more wave of things we'll do a couple of waves and then we'll come back to completely open conversation if that's okay Bonnie I can put you on the spot thank you Sure. Uh thank you. Um it's a great question. I I think if you if you think about the space of discovery, uh there's discovery and there's acceleration. And I think the two are very complimentary, right? If we can collapse and accelerate the time it takes to discover new molecules and materials, uh that'll help solve and and also give access to a a wider space of molecules, materials, proteins available to us. So one of the ways that we're working in the biology space is around protein dynamics. So of course we can use things like alphafold to help us predict the structure of a protein. Um but of course that's not the end of the story. We also need to understand the function and the dynamics of that protein. So one way in which you young people um experienced scientists wherever can help to to bring solutions to new problems is to think about how we can define uh and use AI to look at the the dynamics and the functions of biology. Once we understand that we can design new medicines um to treat diseases and many more. um making these available to students and and uh and to researchers around the world uh is all part of um you know what we're trying to do and I think it's really important to get involved in the validation of that. So building a model in isolation really is just a curiosity, right? So what we really need to do is see how these models can be embedded directly into the scientific loop. And so I think that's one way in which the the community can get involved. It it's not just about training the models uh making very fast and accurate models. It's about actually how it gets integrated into the systems. Uh how it actually gets involved, how it actually gets used. How does that output from the model become something that a scientist, a domain expert can make a decision on? And that's when we're going to start to see the real impact of AI across biology and medicine. Similarly with materials, there's a a astronomical number of possible materials in the universe and we have only explored a tiny fraction of them. If we can use generative AI to explore new novel materials and then also use AI as a surrogate to emulate the properties of those materials, are we able to find materials that can help solve some of the challenges that we have today? in particular in India you know whether it's you know solving sustainability or energy how can we make access to new materials and again build that into the the scientific discovery loop build that into you know going from hypothesis to testing to actually having something real to to use and impact the world. >> Thank you so much. So for me AI is just a tool always has been. Um there was science pri pri p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p prior to AI as well. Um and I guess for me I've always approached my work is you start by identifying the need. So when you say do I need a new instrument? Um my case we need better ultrasound devices. You start with that. Then you might be thinking about how you would then bring in the AI understanding current capabilities, evaluate it, understand its limitations and and build on that as well. But an important part of any development my as an engineer this is the way I I think is you also bring in other people who who can work with you on solving some of those problems. So if you work with clinicians, I work with people who do the ultrasound scans. The synenographers are there from day one. They're the ones who gather the data that goes to build that helps us build the model. The engineers are the ones who build the models. We evaluate together and we iterate improve. Um and I think that's that's the important thing and I think for me the exciting thing about now is everything has becoming very interdicciplinary. When I started out it was computer scientists place playing with whatever data was available. Um then we moved on to want the the the clinicians to acquire data in everyday practice. Much more interesting things you can do with that and then try and predict if they modified their practice how would they be able to make better decisions. So it partly the clinicians and for a few years I was working with them. Now I'm working with experimental psychologists and the importance of doing that that opens up a whole new area a whole new definition of what they consider to be academic work science how they publish all the things that come with that. But they're very important because they understand if you put a tool in the hand of a human how does that um can the human use it? Um does it be the tool behave in the way it did in the lab but how does it change coming back to what you started with how does it change reasoning and human behavior and we need all of this to be able to understand can we translate AI into everything useful. So for those of you out there who are computer scientists, who do you know who are your endusers of what you're doing? What is the end use of what you're doing? And who have you talked in experimental psychology and other parts of social science about the human aspects of what you're developing? This is the future. It's also starting to happen now and it's incredibly exciting. So I ask you to get away from your computer and go and talk to other people in science who are trying to make things happen. >> What a wonderful message. Get away from computer. That's wonderful. Please push me. I think I agree with Allison that it's really important to understand the problem deeply. Um now going back to the question of uh what is AI for? Where can it can it make a difference? So AI systems have this amazing sort of ability to uh scale reasoning. So there are two sort of ways I've seen these systems really sort of shine on scientific and engineering tasks. One is where they are able to extract meaning or extract patterns from data that will from from a perspective of a single human mind it's impossible to get to to understand or even sort of see that data. So look at the amount of data that we as a scientific community are collecting about all areas of science. Uh we saw Arja uh talk about the amount of data that CERN collected uh from the uh and and from the large from the LHC. There was a hu that is huge amount of data. Similar sort of data sets are being collected in genomics. We are sort of sequencing uh across the world at a scale which has been unprecedented. We have uh with regards to the protein folding problem, we were able to sequence these proteins and find their 3D structure for hundreds of thousands of proteins. Right? That was a lot of data, but it was still scratching the surface for for truly understanding the problem. And what machine learning systems like AlphaFold have been able to do is extract meaning from that data and come up with sort of patterns to really predict the future. So from those 150,000 proteins uh 3D structure of those proteins, it is now able to generalize to almost every protein on the planet, right? 250 million. And that's where the real democratization also comes in that once it has extracted that meaning and is able to predict the 3D structure from the sequences. Now every sort of p scientist whether they are working in Latin America or South Africa whether they're working on a neglected tropical disease whether they are sort of developing a enzyme for decomposing plastics they can use it on a click at a click of a button right so that democratization power of of AI systems that they can be used at will uh and they have been able to extract this meaning is very powerful. The second way in which I have sort of seen this is the ability to search. So how many of you sort of remember that uh Alph Go match with lease at all? How many? Yeah, a lot of you have seen that sort of uh um that game. I I was seeing that game and uh move 37 happened and all the commentators were like, "Oh yeah, this is a hallucination. The model made a silly mistake. Haha." And then as the game proceeded they were like wow that is a that was a genius move that rewrote the whole theory of go. So what are those move 37s in science and we are seeing those move 37s in science like we have a system alpha evolve and uh what it has been do it has been able to do is basically we have used it on different problems in computer science and in optimization and we have figured out that it is able to discover new algorithms for very very fundamental problems like matrix multiplication. Imagine matrix multiplication like we we teach it in sort of school and it's the basic building block of all of sort of even AI right neural networks are bas basically matrix multiplication and yet we did not know what is the lower bound in terms of m number of multiplications that are required to multiply two matrices and what uh a system like alpha evolve and these uh searchbased systems are able to do is find these new algorithms that really expand what uh science scientists know about uh the the problem. So it's a great example of the scale of reasoning abilities of these systems and that's where the real sort of power comes in. Uh >> yeah, thank you. Thank you. That's amazing. >> Thank you. I mean uh I'm the only person here who's not really working on AI but there are uh I think all of us are working on AI because either we are the product or we are the user cuz you get up in the morning and your phone is automatically telling you what to do and take your blood pressure or you know dimming the lights uh driving us through the traffic. So we are in this ambient AI which is now becoming reality and then there is the uh proactive AI which we think about and for that I think we we are pretty much in a in a space where we have to see who is defining those algorithms. So that's very important I would say at CERN you mentioned about the data I mentioned about the data already and we are not done yet you know we are now multiplying the data and we are upgrading the collider where we will have 10 times more luminosity which means that in one year we will be able to collect all the data collected in the last 15 years. So now is a challenge for all you experts here on AI who want to help us in sifting through that data and taking us towards dark matter and dark energy that is you know not uh not out there yet. Nevertheless, I feel that um for us scale is very important for the experiments and then inclusion is very important which was already mentioned earlier. I would say that every student is an Einstein just needs to find the right trigger and coming from high energy physics you know triggers we make at the microcond nancond level at every collision so this has to translate into society and I think if we can do that we've been doing it in in iterations we've been doing it incrementally over the last 20 years uh 25 years uh we've been giving out and uh how can I collaborating with meteorology uh organizations at CERN I mean sorry in Geneva like the United Nations has a separate uh UNOSAT which is the United Nations organization for satellite imagery and they use most of the tools that we have developed to look uh for forecasting the weather and to look at monitoring as well and to look for um sending help and assistance where there are uh issues on weather or any kind of natural disasters. So UNHCR is using uh that is the high commission of refugees they are also using algorithms that are coming out from SEN. So I see the interdisciplinarity not only of the subject but also of the object of what we want to do and definition of that is very important and certainly we can't leave that to AI to decide what we want to do as a race you know human beings. Thank you. Thank you. So Neil and just to profess also you've written a wonderful book and uh you've mentioned in several of your public comments about how we should understand ourselves better in this world of AI. If you could also weave that into your comments that would be >> yeah um I think it's a great question and and obviously the answer is AI is a catalyst because that's the name of the session. Um but but h how is AI a catalyst and and and how does that relate to us as individuals? Well, first a quick story that comes from the Renaissance, the story of the discovery of Series, which took place in Sicily by a very isolated scientist making observations um and was only published uh in April by which time this this is a dwarf planet. It was thought to be a main planet at the time in 1801 was lost. Now the planet had been lost and yet it was recovered. It was recovered because the data was made available and a young mathematician by the name of Carl Friedrich Gals people know how old he was? >> 23. >> 23. >> Yeah. So 23 years old and and he was able to read in the journal that was published the data at the time. So it's 1801. So there's no canals or anything like that that the information is moving across Europe and people are are attacking it as a problem. and then the planet was re recovered a year later in another observatory institute. So they're using tools, they're using telescopes, but they're also the main thing and and the the key thing that AI is providing and it's shifting and why this is important to the individual is also present in a very odd thing on this stage. We have Microsoft and Google talking about science in terms of materials and in terms of creation of bi biology. Well, what's going on there? They're information technology companies. So, it's an information technology, right? And it's about, and it goes back to what Wendy was saying with the early onset of the internet. What we're really looking at is the same thing as the printing press. The fact that those books were able to move throughout Europe and any interested scientist was able to see and access this material. And if they were curious enough and clever enough, they could solve where the planet series was and become famous overnight. Now, we've all been isolated from that. That's really, really hard to do today despite the growth of information technology. So, there's something really odd going on there that a 23-year-old would struggle to engage with the science we're talking about in this way. And that's largely because that information has now been locked down in very few companies and access to those things is locked down. This is terrible for science as an institution. Terrible. Absolutely terrible. It's good for individual scientists. It's good for discoveries, but it's appalling for science. And there's a big difference between scientists and science. But the positive is as individuals, we can contribute. Again, I'm doing enormous amount more science as an academic now than I could before because I can use these tools to engage with different materials and search much better than I was able to do. But that's not restricted to to just me. That's that's true of the 23 year olds in this room again, right? And we need to make sure that that's the story that's coming out because it's too much now about big things. I mean CERN is an amazing achievement but as you said it took a decade to pull that together right and 10,000 people on the final paper. So that's science at the scale that has gone quite a long way beyond what Gaus was able to access. But what this can mean for individuals is getting back to doing science at the scale that I think was also mentioned you know importantly by Allison that you you actually want it to be the experts who are working on the ground who care about the problem getting access to these capabilities and this technology gives us that chance and that's why it's a revolution because it's an information technology revolution but we have to be very careful because just as Wendy was saying information revolutions have a tendency to concentrate and and that's very very problematic for India, countries that don't have access, for Europe, for a number of places that don't have access to those companies that are dominating on the information technology space. And I see that as probably the biggest threat to us moving forward as a society, unpicking exactly what Wendy was talking about, the recovery of that independence, that vision of the internet as a way of individuals communicating and participating rather than an entity that is dominated by a few large entities. Thank you. Thank you. Yeah, Pria, go ahead, please. Thank you. >> All right. Yeah. So, I think um that was great, Neil. Also, thank you. Um so, um kind of a different angle I'll bring is something echoing um what what some others have said on this panel, which is I think that in sort of engineering and scientific discovery, some of the things that really AI gives us is it's scalable. It can run really fast and in principle it can run 247. And on the one hand, if not done right, that is absolutely terrifying. Right? If you do things at scale incorrectly, unsafeely, unfairly, in an unaligned way, that is terrifying. But if we're able to sort of by design ensure that you know AI is kind of working in a way that we want it to, that in a way that is physically feasible, that is safe, that is responsible, etc. Then I think this is gamechanging right because um again kind of reflecting on power grids um right now in power grids things are incredibly manual. So even though we think of it as this engineering system that in principle could be optimized, in reality what's happening is that when we think about should a particular power generator turn on or off, someone sitting in the dispatch center is often making a phone call to somebody actually sitting um at the generator to to say can you please turn this up or down? And this is happening in part because we just again aren't able to deal with the scale and complexity of the system. And on top of that, there are lots of things that we wish we were doing on these systems that we're not because humans can only act so fast. I am not able to act at a millisecond level to control a power grid. There are certain things that just need to happen much more quickly. And so I think what kind of AI does in the sphere is on the time scales where we are able to do things today, it kind of shifts um the role of the person there to not having to do things like make a phone call to dispatch power, but maybe look at kind of more nuanced things on the system and control it. And it also enables us to do things we weren't able to do like put more renewables on the grid which requires us to manage power grids much more quickly and much more scalably which we don't do right now because we're locked into very conservative paradigms of making sure the power grid has plenty of infrastructure plenty of buffer kind of such that like a human can can react to it. So I'd say again the things here are kind of the the speed, the scale and the 24/7 nature. Terrifying when done wrong but I think really powerful when done right. >> Thank you. Thank you. I mean there's so much amazing set of perspectives. Um the next set of questions I'll have maybe go the other way around you know so that it's not the same way. Uh or we could dandomize as we like is uh science connected to societal problems. We talked about you know your opening statements about what you're doing. We talked about you know taking the persona of the scientists or the engineers and what is this AI what kind of tool is it and so on. Now when I look at societal problems um let's say pollution or climate change or um you know health education um or you know eradicating poverty or other sorts of things. I mean I don't have an AI button that I press and I magically solve this. I mean clearly humans still have a role to play. Um uh how do you see the diffusion of fundamental discoveries in science? I mean that the way it's happened in the past versus the way it could uh be in the future. Pick any societal problem that you're interested. I assume Priya you'll pick about climate change and so on and say how should we think about climate change? You talked about power grids and are there other aspects of climate change sim similarly Bonnie um in terms of uh say I mean I know you your team has done wonderful work on aurora or you know rethinking how DFT should be done or material science or bioimu or I mean each one of you for your various areas. Um how do you pick a societal problem? How should I as a scientist or an engineer or teams of these think about navigating or thinking backwards from defining the societal problem and breaking that down into scientific or engineering problems. How should I collaborate? Um you know um I'm trying to be as concrete as possible if I would encourage you to be as concrete as possible and also since many of them may not know especially what you're doing if you can take a specific example of what you're doing and um help uh help us understand right. So maybe Priya if I wouldn't mind uh I can start with you first. How do we solve climate change? >> Oh gosh that is a much bigger question but um okay so yeah so thinking about the broader climate change problem which again it's it's a very big challenge. It involves I've talked about power grids but it also involves decarbonization in other sectors. Some of them are energy related like buildings and transportation. Others are related to land use like agriculture and forestry. And then of course this also requires large-scale efforts to adapt to climate change. Um the effects that we'll face through kind of public health assessment kind of disaster prediction, you know, um uh biodiversity monitoring and all these sorts of things. So all of the problems I've mentioned, right, they're not clearly not just sort of technical and scientific, which I think Shiv's question was also queuing up a bit, right? They they're also deeply societal. So, how do we break them down in a way that both kind of yields some tractability to how we um think about the problem? Kind of forms it and frames it in a way that kind of a scientist or engineer can grasp, but also doesn't lose the context and richness that can then cause further lines of scientific inquiry to be divorced from the actual needs of the of the on the ground problem. So I think there there are lots of ways to think about this, but um one kind of paradigm I'll bring this up in is um the paradigm of of of benchmarks in in machine learning. So benchmarks have been kind of a um really big part of drying driving progress in AI and machine learning where we basically kind of specify a sort of set of data, some tasks, some metrics um and then basically try to push forward progress in that setting. I think benchmarks have been incredibly powerful. Um they they sort of have codified and and kind of um unified kind of efforts in a way that's really helpful. But I think also the way we've done benchmarks has been really limited in the past in the sense that there's um kind of a a phenomenon where you you kind of frame a problem that is hard to solve at a particular point in time. The field makes progress on it and then people keep working on that version of the problem even though in some sense we've exhausted the like practical actual progress on that version of the problem. I think we also tend to kind of write down metrics of success as being sort of singular. So did we get more accurate on this benchmark for example. But in reality when you actually deploy solutions on the ground different things matter in different settings. So for example um maybe in in a a power grid example again when we're trying to learn fast approximations to power grid optimization models we want them to be fast. We want them to be accurate and we want them to be robust to kind of uncertainties in their inputs. But how much each of those things matters differs depending on who the user is. And so if we evaluate our models based on just one metric and we push to improve only that one metric, we miss the richness of comparison there and we risk people kind of all kind of trying to drive forward progress on one thing which is not actually capturing the scope and richness of the problem. And then I think the third thing that gets missed is um when a benchmark is defined, we're obviously making lots of assumptions about a particular problem. We are kind of making some assumptions also about how one might then kind of integrate that into society, what the pathway to deployment is. And I don't know that we're particularly principled about kind of writing those down or acknowledging kind of what the limitations are of what this this problem formulation and and model development tells us. Um, and that that means is that when we've quote unquote solved the benchmark, we often then also don't know what the next step is. We again kind of get to this place where we're sort of divorced from reality. So, I'm using benchmarks as sort of a maybe like a an organizing frame to think about some of this, but but some of this isn't limited to just benchmarks. But I think um to summarize it comes down to kind of um understanding that kind of progress is sort of a multimetric thing where kind of it's not like one singular direction but we are often needing to make progress in multiple directions and we should acknowledge the richness of that and we should kind of write down what assumptions and approximations we make about and um uh incorporate knowledge about what it means to actually deploy a solution. And we should also have a sense of when our approximations are kind of have reached their uh limit of usefulness and when it's time to kind of move on to a new formulation of the problem or something that better captures the richness. >> Thank you. Yeah. Would you like to take that? >> Uh it's a great question and something that we've really obsessed about particularly over the last decade as it's been very clear these technologies can come out. The public dialogues we I've been involved in public dialogues. Wendy mentioned one report, but we've been doing them again recently. So, trying to refocus. I think we have to put our hands up and say, you know, the set of societal problems that we're looking at, they're very old and long-standing and they haven't gone away. And people are not stupid. They've been asking us to solve them for a long time. So, if you do the public dialogue, you say they'd like solutions in healthcare, education, social care, etc. So, then there's a major question, well, why haven't we done anything about it? and in particular with AI because if you look at the the report Wendy mentioned, we did public dialogue then and they said we'd love you to solve all those problems. The one thing we don't want you to work on is art and the one thing we've made undoubted progress on without solving any of those problems is art. So in a very real sense, we're not listening to people and their problems as scientists. And I think that's partially this abstraction thing that Priya has mentions. It's far easy to abstract a problem away into something we can solve and then shout about it. Well, to a large extent, that's not helping. That's not helping people in their regular lives. So, what we've tried to do is is switch the model and do something we call the attention reinvestment cycle. And we think we should be owning up as universities and saying we haven't done a good enough job on translating innovation from our labs to things that mean something to the, you know, I don't know, a person on a bus in Hyderrobad. right now what that means to get through this benchmark problem that Pria is highlighting is you have to get down and dirty with the issues they're actually facing. So rather than telling them that we've solved a problem and deploying it for them as a solution, we're trying to flip the model. Um and in Cambridge with AI at CAM and also the accelerate science program and also learning a lot from my colleagues in data science Africa who've been doing this beautifully for 10 years. We're realizing you actually have to sit down with the people who are having the problem listen to what the problem is and start working with them to solve it and ideally and this technology is allowing that ideally give them the tools to solve it themselves. So what we're doing at the moment with one of our programs we're working with local authorities who've already formed AI clubs. We're listening to what their problems are. We're trying to then sit with them and propose a few things, but then often just introducing them to each other. We have reverse poster sessions where they show the poster session with the problem in and most of the time they can solve each other's problems because with there's such a radically radical change in the information infrastructure. Everyone is having the same problems everywhere. And I think this the challenge is that the nature of those problems is not percolating up to the universities to the big tech companies and we're solving for things we can either make money for or we can get on the front page of nature for and that isn't helping and that's leading to a rise in popular uh populism and a rise in people pushing back saying what is this all for because it's not doing something for me in my daily basis and I think with a such a transformational technology it is time to reassess that and start saying how can Can we improve some of what we're doing this and actually address the problems that real people are having and again India is in an amazing position for this you have distributed universities across the country you have a large number of challenges that are now offering new solutions through mobile phones like my colleagues in Africa that's why I find Africa so interesting not because I'm helping you know not because they're helpless they're solving their own problems in innovative ways that would blow your mind if you're sitting in the UK trying to solve those problems and if we can transfer some of those solutions to the UK then we have success >> and sorry can I just interject really quickly and at yeah at next year's summit for exactly this reason I would love to see the stage representing many more Indian scholars based in India talking about these topics as well thank you thank you inspiring please Hello. >> Okay, it's working. So yes, uh in the ways I think how we have been defining problems or rather picking problems which are existing in in on the globe in itself. You know there's global hunger, there's energy, there's the climate change, the ones you we all been hearing all morning. Now at CERN we do have a section which is recently uh set up 10 years ago CERN and society and we have a lot of problems that we go there and then we convert them into competitions for everybody to participate and typically you know CERN being in Europe and access being easy and like you Priya just said that you know Indian students are amazing but they do not have the means to get there right? They do not they they need to be empowered. they need also uh but with the with the www first and then with all the AI tools that are available any student sitting anywhere can be linked to the problem and this part is very close to my heart I can tell you I'm working a lot with uh children not children students high level engineers technicians and trying to move towards capacity building and that I think is our responsibility we should not forget that so any tool that is available today at CERN except like superconductors because it'll be hard for us to ship them down here. But that knowledge had the ability to create a 28 billion market for MRI machines, imaging and so on, cryogenics. So th I want to link those and embed that into universities, schools, institutions solving one problem together. Thank you. If you can also add a little bit about that Hadron therapy you do. I mean we think of this fancy particle accelerators huge loops >> but how can it actually help solve >> Thank you. So um you may have heard about radiation therapy for cancer patients of course >> you may have heard also about proton therapy hadron therapy. This is the next big thing which actually targets tumors without damaging the healthy tissues and this has become go-to technology in the west if I can say so also in Japan and there are 130 centers all over the world and in India where the concentration of cancer patients is much more if you look at it from the if you look at a graph of the of the world we need to make technologies for cancer patients accessible and affordable. So the good idea would be to come together and design something on the basis of the next generation of these particle therapy uh centers which of which do not exist yet because all the six centers in the world are using technologies of 20 years ago. It takes that cycle and AI can perhaps help us in accelerating that cycle and and moving forward. Thank you. >> Yeah. Yeah. Push if you could also add on you've solved protein folding, right? Um how can AI then help further discoveries uh you know and then help us cure cancer or one of these wonderful things that Deb keeps talking about you know when are we going to cure cancer and when are we going going to get on with it. >> Yeah. So I I think uh like reflecting back about uh on what Neil was mentioning as well um I think if you think about AI for science and if you think about science generally one aspect of science is basically making sense of the world really a science for the sake of science science for the sake of understanding but then there's another aspect of science which is science understanding for the sake of solving problems and uh and I think uh in AI we are seeing that we are uh AI is delivering on problems that are actually having impact. I mean you mentioned alpha fold and alphafold is basically a root node problem because solving protein folding does not just get you a nature prize a nature cover or or a Nobel prize. It it gets you more than that. The fact that 3.3 million people have used the AlphaFold database is was a surprise to me. If you had told me this when we were starting the project, I would not have believed you that there are 3.3 million scientists who have used Alpha Fold. Those people are spread across the world. 180,000 of them are in India. These people did not have access to the cyclotrons who could which could have uh uh done the structural prediction for the the samples they were interested in. Now they can on the click of a button and that really accelerates not just one particular area like drug discovery. It accelerates a whole span of things which require understanding of biology and biochemistry. There are people and scientists working here in India on understanding how do you improve soya bean crops and make them resistant to fungus, how do you increase crop yields all using alphafold. So in some sense we are already seeing these scientific models have impact across uh socially important uh problems. In the case of weather uh weather is another weather and climate like we were coming back to that sort of topic. Our new generation of weather models they are able to make predictions about weather in the short term in 5 to 10 days or 15 days in 1 minute much more accurately than what a supercomput would have taken a whole day to predict. And now these machine learning uh uh models for weather prediction are becoming so good that in fact in the last uh hurricane tracking and cyclone tracking sort of cycle they were they were the uh model of choice and were able to literally save lives in terms of giving better and faster input as to what will be the cyclone and hurricane tracks. So AI is delivering it is delivering sort of on problems which is going to have impact. Now and then the final sort of thing I I don't think this is this work is sort of having impact because it's um it cannot have impact by staying in a silo. It is having impact because these models have been made accessible that 3.3 million people have used alpha volt database. People can access those cyclone and and weather predictions. Another example is our work on AI cosientist and agents for science like alpha ball. And this is where these agents are being used by scientists themselves. Some of the best some of the uh Terrence Tao who is one of the I would say arguably the the best mathematician living on the planet today. He's using these AI agents to further his maths research. We are seeing AI cos scientists being used by scientists to come up with new hypotheses for problems like antimicrobial resistance. Antimicrobial resistance is a key problem that is facing the uh like on on the societal sort of scale the health of the of the planet. So we are literally seeing these models having impact on these problems and I think that's what's what will happen in the future. But again this all needs to will happen only if scientists have access to it and there this is not the job of uh one person or one institution. This is the job of society at large. Governments need to be involved uh academic institutions need to be involved. Social scientists need to be involved. industry needs to be involved in making sure that this very powerful technology has been has is given to people and scientists around the world. >> Thank you. Yeah, if I can please. >> So just 30 seconds on that that peaceful international collaboration is what has to come out of all our deliberations and in principle uh scientists who are also diplomats to democratize all the work that we are doing. Thank you. >> Thank you. Thank you for that message. Please >> and I definitely agree with that. What I'm going to say though is AI models depend on data. And one of the biggest problems in getting science to solve some societal problems is we don't have access to the right data. Working in medical imaging, it's already been touched on. If we restrict ourselves to the small open data sets and building AI models on that, we do not solve youthful problems. We do a proof of principle and there it stops and then people go on to the next one. So then people say well provide access to all hospital data please um what please just open open the gates and of course you can't do that because of the different data privacy laws and the respect of of health data. So what what do we do? We we've come a long way. When I first worked in an international study um on pregnancy ultrasound, this was in 2008. How we in a research study, we have ethics approval for this. You shared data by USB stick. They were sent I my my lab was the central um center for this and it was tedious. You had to triple copy everything, bring it together. Of course, things have moved on. Um, but in healthcare in particular, it's sensitive data and in other areas of science, we've also advanced in the way we can we can build models from sensitive data through things like federated analysis. We've come a long way, but the bottom line is we do need the individual science communities to decide what data they will share, provide access to so that we can all collectively solve the right right science problems. This may sound easy to a computer science. You should be able to just do it. It's complicated. It does require policy makers. It requires people to be able to provide that access under conditions and governance models. But it's very important for the future of using AI in science that we find better mechanisms to do that. It's not one solution either, but we work together so we can sh either share or provide access so we can build models that can really address some of these societal issues. And it's costly to do this. We need to understand we need to pick the problems um together a few problems to start with to be able to come up with being able to do this maybe with some then leading to some new standards and ways that that scientists can j um work together globally but that's that's what's holding us up at the moment. So I just wanted to start by reiterating what uh Pushmeat said about democratization. Um so making models available um not keeping them glo be behind closed doors so that uh people can use them, society can use them, governments can use them. Um our model at MSR on uh the climate. So we have Aurora which is a foundation model of the earth's atmosphere. Um and that's able to and as he said there are there are a lot of machine learning for um climate weather prediction models and they're getting better and better. Um and what it does it is enables us to forecast much faster than traditional methods. And one of the greatest benefits of that is preparation. Um so if societies, if communities, governments have access to these tools and they can predict when a major climate event um is going to happen, we can prepare. Um and ultimately that helps to save lives. Um so I think it's incredibly important that we continue to build on these models. We continue to make them accessible um and continue to grow in that area. The second area I wanted to talk about, the second societal problem um I want to talk about was making medicines. Um, India manufactures a significant portion of the world's medicines today. Um, and it's no secret that medicines are extremely expensive to make. Uh, it's very costly. It takes a lot of time in the lab. It takes many experiments, lots of, uh, human resources, uh, scientists that are trying out experiments and oftentimes failing. Um so it costs billions of dollars and once we get to clinical trials uh typically we tend to fail more often than we succeed. Um the industry has made a lot of progress especially with large molecules. So looking at antibodies and how those can treat disease. Uh but of course large molecules can't treat everything. So there's still a need for sort of traditional very small molecules uh to treat treat as medicines. Um however, you know, collaboration is is really central and core to what we do probably in any tech company or in academia uh working with industry. Um, and you know, some of the partnerships that we've had at MSR with pharma companies have really shown that there is there's a bit of an ext existential crisis when it comes to small molecule discovery such that it's so expensive and takes so much time to discover small molecule drug candidates that um oftent times it's just easier and faster to just focus on the large molecules. But if we were to do that as a society, as industry, then that would cut out a significant number of treatments for diseases that people need access to. So it's incredibly important. This is a problem that we need to bring front and center is how do we actually make drug discovery more more accessible, more efficient? How do we find ways in which to reduce the time it takes and improve the probability of success when it comes to clinical trials? Um so that's a problem that we're working on as well. Uh there are many bottlenecks along the way um when it comes to making medicines. Essentially every step along the way could be accelerated using AI. Um so working directly with the people involved with the scientists with industry is incredibly important. Um and making access to uh you know the cycles and iterations to to find new medicines. One of the biggest problems and challenges that we have is not just how to design the molecules but actually how to go and make them. You can imagine, you know, a world where you could design a perfect molecule that might attach wonderfully to the target that you're trying to go after uh in biology, but then once you get to the lab, you can't actually figure out a way to make it. Um, or you can figure out a way to make it, but it's too expensive to make, which again drives up the cost of of medicines. Um, so I think AI is uh a great way to solve some of these challenges. Uh, and that is one area that we're working on as well. uh in particular for reaction uh prediction and synthesis. >> Thank you. And as we come to the final stage, I'll do a quick lightning round on a couple of quick topics that I had. Uh finally, one is uh as we are all sitting sitting here, what skills does a scientist uh pick up? know we think of first principles thinking we think of uh you know we talked about broader societal understanding how to work with AI disciplinary skills collaboration collaboration both with people and AI models and so on so a quick round on 30 seconds each u you know what skills should a person pick up anyone so this we'll keep a random round whoever wants to pick it up please uh >> maybe I can start I I think the one of the most important thing is um understanding of these tools so use them. Um, these tools are not perfect. They will make things up and you need to be aware when they make things up because uh that's where the responsible use of this technology comes in. And one other sort of key point is this does not mean that now that you have access to this uh AI uh tool the expertise is not important. expertise is even more important I would say now because in order to sort of really think about what is the right problem to ask that requires deep expertise. So these uh uh these tools, these AI systems are able to help you solve those problems. But who comes up with that problem? Who comes up with the right formulation of the problem? That requires deep deep expertise and that requires deep interaction with how do you use these tools. So my advice to everyone in the room would be first understand the deep problems that are going to have impact in your field of study in your in the field in the impact that you that you want to have in the world and then use these tools because you they they will give you superpower but they will also have weaknesses and and try to discover those weaknesses and I think those are the two very important skills that all scientists will need to sort of uh come up with. >> Thank you Vishm. Yeah, please. >> Yeah, listen. Yeah, you go next. >> Um, I think the most the most important thing to do is be a team player. You don't have to be an expert at everything. You won't be an expert of everything. You've got your whole career to learn different things and that's what makes it fun. So, for me, the answer is I think if all of us when we started out, we had certain skills and we've certainly evolved those with times. So, it's about your ability to work with others. um challenge them but so be a challenger but be prepared to be challenged yourself contribute and take that forward and that's all about working that that's what interdicciplinary scientists do um so that's I think come come with something come come to the table with your expertise and then it will evolve with time >> thank you thank you please >> I I really love that um as I said I think collaboration is central to everything we need to do um and science is multi multi-disiplinary. So you don't have to be an expert in everything, but you should surround yourself with people that have complimentary expertise to you. Um I think the second skill that everyone needs is curiosity. So be curious about uh learning more about asking questions about you know understanding what the limitations are of the models that we're we're using we're building um and ask questions of them. >> Thank you. Um, I would say kind of investing in learning how to learn. Things are changing so quickly that it's not about kind of overfitting your knowledge to exactly how the latest and greatest thing works, but instead making sure you have the foundations to understand how to to push that forward. And the other thing is um I think interdisciplinarity has come up, but I think that's not just about from an education perspective knowing things about multiple disciplines, but learning to think from multiple perspectives and have empathy for different ways people might approach a problem. um kind of briefly I mean I am you know born and brought up in the US obviously of Indian origin and I think that for me in childhood that ability to sort of things that other people were taking for granted to see that there were two distinct perspectives or more than two distinct perspectives on those things I think really for me um made it a much richer way to navigate these assumptions and ways of thinking and so I think there's a disciplinary version of that there's a contextual and geographical version of that take multiple learn from multiple disciplines and learn to think emphatically from from all of those perspectives. >> Neat last thing. >> Um, so people have Bonnie said curiosity which was going to be one of mine and that was brilliant. Um, the push meet what he's saying. I think curiosity drives you to play with these tools but you want to do it within a context something you understand. So you play them and that's how you get the thing that I think you have to learn. I think only PhD students towards the end of their time seem to pick it up and I'm really worried about how we're teaching this. the skepticism that's so important. The scientific humility, you know, thinking of a hundred ways why the thing must be wrong. It goes all the way back to sort of poa and and conjectures and reputations. It's so when I when I worked in industry, that's the thing I found was broadly absent, but I I take for granted in my academic colleagues, skepticism and humility. Um, but then I think the other one, passion, you will you will get all those things if you're passionate about solving a particular problem. Thank you. Please. >> So uh in fact everything has been said but I would like to add two words. One is rigor and second is logic and mathematics which is an Indian heritage I must say. So we should leverage that. You referred to deities but I would say that mathematics and logic is you know indented into >> well Ramjan mixed the two together didn't he? Yeah >> think about it. So the possibilities are infinite and we just have to leverage them. Thank you. >> Thank you. Thank you. Thank you. Did you know we spent one and a half hours talking and the time just went by? I just want to extend a word of wonderful thanks to all of my panelists here and I hope this is just a beginning and uh as we go forward um I urge you all to collaborate with us. Um as a funding body we are having a program on AI for science. This is just the beginning and uh we'd love uh to continue uh being in touch on what we can do together and um you know got speed. Thank you. Thank you to all the wonderful panelists and also to ship for moderating this session and we'll begin the next one very shortly. >> Thank you so much. I hope Please exit from the right. >> Yeah, please exit from the right side of the room. You tell me. We request everyone to settle down so that we can get started. I'll make the announcements. >> Uh I would request everybody to exit from this end. Everyone who's getting out of the hall, please exit from this end. Please guest uncomfortable. Please. Aram says >> I know. Yeah. request everybody to please settle down. If you're sitting, please go to the back of the room. There are some empty seats there. We want to get started on time so that we can maintain time for the rest of the program. Are you slides. >> Put on my slides, please. >> Can you please put on my slides? >> Can someone please put on professor's All right. >> Thank you. >> What's going on here? >> Just the first slide, please. >> All right. So I'm going to tell you about the alignment problem uh which is a major issue of reliability and safety for the kinds of AIs that are currently being developed uh at the frontier. you know those really large models and I'm going to say a few words about an approach that my group has been developing to u build AI that will be honest and inspired actually by exactly what uh we've heard should be a model for us scientists can be a model for AI as well um that is epistemic caution not saying something false with high confidence. Okay. Um I'm going to start by uh just maybe updating some of you with some of the things that have happened over the last year. Um we are presenting here in Delhi the new international uh report on AI safety and there was one last year in Paris. Um some of the things that have happened over the last year is that risks and and uh potential issues that were considered theoretical one year ago uh are now starting to show up in lab experiments and in particular we see in various experiments from various labs uh these most advanced systems that are able to reason attempting to resist being shut down. So this is uh something that's worrisome and in addition to that in order to achieve that kind of goal they'd be willing to lie and be deceptive. Um they will also behave when they're tested in ways that are different from when they're not tested. So they know they're being tested. And again this this is even more recent than this paper but this was the first one. Um they will be tested against their capability and their propensity or like uh intentions and on capability they will pretend that they know less than they do so that you know they will not be considered too dangerous. and on intentions they will also like pretend to agree with the humans when later when they're not in a test condition they won't. This is a real problem for risk management because we need to make sure that we can evaluate those risks before we deploy these systems. Um and in order to avoid being shut down in some of these experiments we see that they're willing to cross our red lines to go against the instructions we've put for them. uh for example be willing to blackmail an engineer who's in charge of uh replacement of the AI by a new version. So there's a lot more in the AI safety report and I encourage you to really have a look. It's a synthesis of the science um for consumption by everyone but in particular policy makers and it's looking at the evolution of AI capabilities um the synthetic the scientific understanding of the risks uh especially the emerging risks that is the focus of this report and the current state of risk management uh mitigation evaluation and safeguards. The maybe sort of sad uh conclusion is that capabilities over the last year have been evolving faster than our ability to mitigate and evaluate those risks. So I'm going to now focus on one fairly large category of harms and issues that is tied to what's called alignment or misalignment. Uh in simple words, we see AI systems that are behaving against our instructions and um it shows already in wellestablished harms like bias and discrimination. So it's not enough to tell the AI to not be biased and not discriminate. It might still do it. Similarly, um we've seen if if you play with some of these chatbots, you know that they will try to please you and be willing to actually lie in order to please you. This is psychopensy. And you know, it might seem like a mild problem, but it isn't. is has already caused a rapidly growing wave of psychological issues with people becoming emotionally attached. Of course, we want to feel you know good and and intelligent and and so on and get praised but um this can also amplify our delusions. This can amplify depressions. So there's been already a number of lawsuits of uh especially adolescents who have harmed themselves going up to even uh you know uh tragic accidents and and suicide encouraged by the AI right um then another like very serious issue is that it's not it doesn't work right now to just ask the AIS in their programming in their training to uh not help somebody do something harmful with the knowledge that the AI has. Um it's it's a very old problem uh called uh jailbreaks uh whereby it's fairly straightforward to go against the programming of the AI and uh have it help you do something bad like cyber attacks which happened uh massively over the fall using uh one of these uh most advanced systems. So, so that's that's that's a real short-term risk that is unfolding in front of our eyes. And finally, the things about AIS that seem to behave like they don't want to be shut down. Uh this is something maybe uh longer term because right now they have sort of planning ability of a six-year-old. So they're easy to you know uh figure out uh in their bad intentions, but it might be different in a few years. So we need to really start paying attention to this and it becomes even more important in the context of the agents that companies are deploying more and more because um being agent means not requiring oversight, not having a human in the loop. Um that means you're going to give your credentials to these systems so they're going to do things in your name. But if we can't trust them because they they would not necessarily follow our instructions um then this is going to be a real obstacle as well as a real risk for society. Um so I'm going to say quickly a few words about a a research direction that we have started um in Montreal um where we we're focusing on the question of uncontrolled goals. So how can we design an AI so that we will not have goals that we the humans did not choose because right now they do. So these these phenomena for example of self-preservation and psychopensy uh it's not like they were explicitly asked to behave like this of course not um it comes as a side effect of the way they were trained and what we would like is the AIS behave in the ways that we intend and that we specify explicitly even if it's ambiguous sometimes because of natural language. Um, and those goals could be coming from humans who want to misuse the AI's power or from the AI itself as we saw with the self-preservation. So, um, my my belief is that it's very likely that we're going to continue seeing advances in AI capabilities. So, AI will have the power to do very good things as we've heard in the previous panel or very bad things. Um the difference between the two is going to be in the intentions of the AI in the goals of the AI. So we need to make sure that we can control these. Um and kind of an extreme view of this is to think about uh the the possibility of completely rooting out any intention. Can we build an AI that has no intention? So what does that mean? Well, it could be an AI that understands the world just like a scientist would or actually the laws of science understand the world but not like a human would. Right? So it's departing from the idea of building AI using humans as a model or a template but but instead use the understanding of the world that science provides as a kind of template. So you know the laws of physics don't have any goal. They're not agentic. Um they will make predictions that are invariant to the consequences of these predictions. you know, maybe a prediction is going to help somebody or or maybe it's going to be used to create harm, but the laws of physics just going to give you the same prediction. Doesn't matter. So, we'd like AI like this. Once we have that, of course, we humans should be deciding whether a prediction or an action is something useful. Um, now um yeah, so that's what we're going to be doing. And this departs a bit from how we train current AIS like current LLMs for example are trained to imitate people in their first phase of training and they're then they're trained to achieve goals and unfortunately a side effect of the way they're trained is they're going to have they're going to strategize in order to achieve those goals. Um instead if we try to use science as a template um we want the system to basically generate hypothesis about what how the world works or you know what explains the data that it's trained on and that it does this in a way that's going to be coherent so that you know we can we can trust the reasoning that the system uh produces. Um in addition just like a good scientist as I said earlier these systems should know about their own limitations their own epistemic limitation that there are things they don't know that they're not sure about and they should not claim things that are false. Finally they should be able to explain their predictions just like you know a good scientist would. So so this is what we're working on. We call this project scientist AI and the core of it is a predictor. It's a it's a neural net if you want that predicts the probability that some statement is true given other statements and that's the core that's um going to be trained in such a way that it doesn't care about what's going to happen with those predictions. Uh it's just going to try to construct predictions that are uh as coherent as possible with the predictions it makes about what are the good explanations for the data and with that we can uh construct safe AI. For example, we can use such a prediction to reject actions that are predicted to be dangerous. Um, so I started a new institute in Montreal uh called Law Zero uh in reference to Azimov's law number zero in case you know about it uh to develop this research program. Thank you. Thank you for that. Um I've been following up like um the announcement in subsequent posts etc about scientist AI uh quite closely and I I was kind of wondering that you know how it emphasizes u modeling and understanding rather than action right um so do you think of this as kind of a structural separation between um world models and decision taking on or do you kind of think of it as cognitive module within agent. >> Um, right now the systems we build kind of mix together uh the ability of the system to understand the world and the ability of the system to predict and act in the world. And by the way, it's also mixed up in human brains like uh even uh you know human scientists are biased right we we we have a culture you know we have preferences and so on and it's going to bias our judgment whatever you know even if we try to avoid it so we are trying to separate the aspect of learning which is trying to understand trying to be good at explaining and predicting uh without having any desire any like you know like a a Buddhist if you want uh that that's completely detached from um the consequences of what's going to happen. Of course once you have a system like this you can ask questions about harm about values um but you know it's not going to have a innate uh choices of moral. It's something that we should be the ones specifying. Society should be deciding what we you know what is acceptable and what is not. By the way that is why we have you know laws in different countries. >> Yeah. So I but you know right now all the models are just trained on some next token prediction kind of a thing. >> Yes. And that confuses all of the different aspects. And the reason I mean it may sound like next token prediction is a prediction problem. The problem is it is predicting what a human would write. And humans are agents. Humans have goals. Humans are biased. Humans lie. Humans are trying to convince you to vote for them or, you know, buy their product. Um, so you can't trust what they're saying. I mean, sometimes, sometimes, yes, sometimes no. So, we don't want that kind of AI, okay? We want an AI that is going to be completely honest with us. And so we we we can't do that in in the scientist AI. The way that we're approaching this problem is that instead of trying to imitate what a human would say next, we're trying to explain why a human would say that thing. So let's let's let's imagine that we are in a world where um there's uh a whole lot of uh websites where you see flat earth declarations and so on. And of course it it is inconsistent with many other observations, right? So we should reject that. But but but current LLMs I bet would start repeating those things simply because they are frequent. Instead, if you think about what a scientist would do, they would try to understand why is it that all these people are saying those things and is there an explanation that is coherent with the other facts like the the facts we know from physics and observations of the uh the you know uh the planet and so on. So that is a sort of way we're designing the learning system so that it would come to that kind of analysis rather than imitate people. So does this mean that we have to kind of fundamentally think differently totally differently about um you know how what the learning objectives are going to be because um you know this doesn't seem like we can just keep throwing data and compute at a model and keep getting it better and better. >> Yeah. So, so the good news is you don't need to change the architecture of these neural nets. I mean it's going to continue evolving and improving probably uh you need to change the representation of the data so that the system knows the difference between opinions what people say and facts. Now most of the facts are we don't know the answer if it's true or false but some we do and then the others are going to be latent viable. So the whole thing here is what's called in the jargon a latent variable model and it's trying to explain for example the opinions of people with latent variables that are their intentions and context and so on that may explain why they behave in this way. So so there's a difference in the data there's a different in the fact that you not treat explicitly the difference between opinion and and facts not just in the data but also in the model itself. Um and you also change the way it's trained. So the training objective is going to be such that there is no signal that comes through the neural net >> that would encourage it to become agentic. Uh for example, you know, if you were only to care about the accuracy of prediction, you might end up with a system that's going to try to make good predictions later and be willing to lie so that in the meantime they would get more data, more compute or make the world easier to predict, right? So that would reduce future prediction. That would be very bad. We don't want that kind of AI, right? >> So, so in in you know, so just to build up on that like you know right now everybody is talking about agentic um frameworks and everybody is talking about how we can um build all kinds of things on top of these agentic frameworks. So but what you were saying is is extremely different from what >> yeah we have to take a step back. >> Yeah. Um but so first you have to understand why is it that companies are investing so much in agentic AI because that's where they're going to make a lot of money by designing AI systems that can do the tasks that lots of people do and of course that's going to create a lot of social problems. Uh but but that's the motivation. Now I'm not saying that you know we couldn't have safe agentic systems. In fact, what I'm saying is we could but we have to step back and first build an AI that is really smart but is is completely trustworthy uh as a component for building eventually if we really decide to do it agentic systems. And I think by the way these choices should not be made by a handful of CEOs. They should be made uh as a social choice like we should decide what we use AI for. Thank you. So, you know, again, um I've also read the safety report from page to page. Yeah, >> you're one of the rare people >> and um >> I did it multiple times. >> So, um you know, there's there are a couple of things in it that I kind of um would like to u get clarifications from you. like you've been such an uh you know great proponent of um openness in science right but in this I might be wrong and you could correct me but in the safety report what I seem to understand is that open systems are actually uh extremely unsafe compared to closed systems and there seems to be some kind of a >> there's a tension >> yes I can explain why >> yes please >> yeah yeah so yes I'm I'm a big fan of open science of course uh I'm I'm a university professor and uh my group wrote one of the first deep learning uh Python libraries if not the first um and I think that science thrives on openness and sharing of course but think about if you knew how to build a virus that could kill half of the world population should you make that public if any joke could you know start a pandemic with this virus. These are like difficult ethical problems. Now we are approaching a stage where AIs can help somebody without expertise to do these things. So last summer both open AI and anthropic who have been running these kinds of tests of you know how much can an their AI system help somebody without biological expertise to build a bioweapon >> and they cross a threshold of danger according to these tests. So they reacted not by deciding to not deploy their models but by putting some extra classifier some something that would try to detect whether the person is trying to use AI in in these illegal ways and they deploy that okay uh and I don't know how good these protections are but if they had deployed an open weight model in other words with the code then in the code there would be some lines that say, you know, don't respond when such and such conditions are met. And these lines could be commented out, right? So then anybody could do it. The problem is that there's like 3% of sociopaths on this planet and and you know some number of crazy people. Um so how do we manage the power that science or AI can bring to the world so that we can reap the benefits without creating massive destruction because of a few people? This is a very difficult problem and how do we you know going back to open weight models? Well, I think the right strategy is evaluate the risks before you deploy. If the risks are not too large compared to the benefits because clearly there are benefits to sharing in particular in developing countries like here in India um then sure yes you should absolutely go open but if you see that the risks cross a threshold of social acceptability then you should not. Um so this way we might be able to get you know uh the benefits of open source when it makes sense and we could prevent catastrophic uses otherwise. So um the other thing there is that h how how prepared do you think like how good are these um you know safety uh controls in any case like forget about uh open source but even for like how how good are they really because you get such differing reports from who you talk to about this. Well, that's that's a a kind of not easy question and the the report is highlighting the fact that the the risk management process has advanced in many ways. For example, there are twice as many companies that are now having at least some risk management process uh compared to last year in in the companies building the frontier models. um uh there's been um a few legislations that came out uh so in the EU, in California, in New York and so on. So we're starting to see push towards more transparency in the development and risk uh evaluation. But on the technical side, um as I mentioned, we're now in a position where for the most advanced models, it's it's not even clear that we can do a reliable risk estimation. Um so yeah we're making progress but the capabilities of AI AI are going even faster than we can track. So the there's something you know that needs to be done I think by governments and it's going to have be related to regulation or some you know independent third parties need to be able to audit these systems and honestly you know decide that this is crossing a threshold. So but I think like governments um because of uh their particular geopolitical alignments have very different views on how to govern all these things. So but here we have like a crowd of people who are researchers. So for researchers um what do you think um where should their focus be because right now we see that everybody wants to build the biggest the bestest model. So, so as researchers, how can we kind of be a little bit more future futuristic about like how these things are panning out? >> Well, so the investment in making the AIS more capable like smarter is roughly in a ratio of a,000 to1 compared to the investment in research in safety like how do we make it safer? How do we evaluate the risks? How do we manage the risks? Um and so yeah that's a place where researchers could really make a difference because they choose to some extent their research uh direction. Uh governments could also help funding uh research to to make sure we can better understand the impact of AI in society. So I I I talked a little bit about the psychological effects. This was completely unexpected like a year ago. Nobody would have thought that people like so many people would become emotionally attached to their AIS and AI companions even the chat bots and that it would change their life so dramatically. Um and so we need scientists to be like on on you know uh on the edge here of tracking the effect of AI on society so that we can raise the alarm to governments quickly. >> Yeah. So I was in uh you know very recently in a um in a room where people were discussing you know how um these chat bots etc are being used by children to to provide emotional support like you said right and there were a lot of organizations who were thinking about like how can we do this and um technically nobody really had an answer like how could we kind of support this other than just ban everything right So um >> well u how do we do it in medicine right? How do we do it with drugs? So before you're allowed to um um put out a medical treatment like a drug you have to show through uh risk evaluation that is not going to harm people and we need to ask the same thing of of these objects that we're building. Uh but it's it's not happening. So if we you know the it's credible that it could actually help some people but come on companies need to demonstrate that it's going to help and not harm just like we do for everything else especially in medicine. >> Yes. even like food and you know all kinds of >> uh everything everything has this kind of basic uh constraint that when you uh deploy something in the public um you you can't do you know whatever you want that's going to make you money. You you need to first show to an independent party like representing the government that your product is not going to be harmful. But there's no such thing right now. It's it's a scandal. >> Yeah. And I mean but it's also very difficult to convince most of the scientific uh community that's involved in um you know AI research right now about the uh necessity of you know these kind of bodies or things. I mean most people have almost like a knee-jerk reaction to regulations or compliance etc etc etc and they there is like a thinking that it somehow curbs innovation if you have like these you know checks and balances in place um and I'm talking about the I'm not even talking about the big companies I'm actually talking about scientists who are working on this problems >> right so first there's a lot of propaganda about regulation um I've been involved in the code of practice of the EU AI act. We worked for almost a year with civil society and the companies to make sure we would devise a set of you know guidelines that would not impose uh any kind of really strong new burden. In fact, what we asked the companies to do is what most of the leading companies are already doing except it would be mandatory for all of them and it would be transparent. So they would have to share that information with a regulator. Right? So it is not really a burden. It's more that we're making sure that the whole class is behaving well because you could have companies that are willing to, you know, take a lot of risks and and also uh the biggest risks at least a lot of the risks we studied in the report um from malfunction come from these most advanced models. And only very few companies are able to build those models anyway. and they have you know they can have uh risk management teams. Um so yeah I I think the whole story about is going to stop innovation first of all all of our industrial you know uh sectors are regulated and didn't stop them >> and second in AI most of the regulation like in the EU AI act are really not affecting the small companies the startups and so on they are affecting the one the really large companies that have billions to train those models >> that's So, so but um so in that case like you know what would you what would you ask us in the global south the global majority rest of the world what do you think we should be focusing on here like what should we we be pushing for because you know frontier models are produced somewhere else >> exactly >> and that >> so what you need to do is get together with other countries and tell the governments of the US and China, which is where these models are built, that it is unacceptable that, you know, you will be potentially passive victims of things they build. It is unacceptable. uh we're transforming the world and those decisions are taken by you know a few companies in a couple of countries and everyone else is just you know passive victim potentially. So we should like take it to the highest diplomatic level that we can't go for that and and and it it's it's not just a question of you know morality or something it's existential about the sovereignty that countries have because you have to I mean one topic we didn't discuss here is concentration of power which is related to to this issue right so if AI capability continue to grow there's a real possibility that there'll be a huge discrepancy even more than there is now between the models let's say in the US and China and and the models that are being developed in other countries and that could give those two countries or whoever is leading huge economic power but also political and military power and the stability the geopolitical stability that we've known since the second world war could just go in flame not saying it's going to happen but when you introduce so much power And when it is concentrated in such a way, there's a real danger that you're going to break the house. >> Yeah. So just changing tracks a little bit, you've been here for a couple of days and hopefully you've and you have visited India before as well. Uh so hearing about all that's happening in India related to AI um if you could tell me like you know what you think is extremely positive and what do you think we should be very careful about the all the kind of AI um buzz and innovation that's happening in India. So when we develop technology uh in order to do it in a way that's going to be the most helpful to people we have to be mindful of the effects or the risks that are being taken that are going to affect society and right now I think there's a bit of uh conscious or unconscious blindness to the negatives right but in order to manage risk we need to understand it we need to understand it scientifically uh we need to understand it socially because there's a social component psychologically in case of AI because we're talking about systems that interact with people in language right um so country like India could contribute to that understanding and and it doesn't preclude also developing you know the deployment of AI also I'm going to repeat a sentence that my prime minister Mark Carney said in Davos a couple of weeks ago if you're not at the table you are on the you I think that can be the quote of the day right now. So um you're a you know professor you've seen through many students and right now the way we do research like it's it's very difficult to advise students these days what should they be focusing on because the old ways of doing research is gone. So what would you advise student? Wait, why do you mean the old ways of doing this? >> Well, you know, everybody wants papers in two months. Everybody wants to build something that they can, you know, put out in 6 months. Um, so what would you advise students? >> Well, I don't know like deep learning took decades >> and it took a will to go against the trends of the day. So you should listen to your heart and to your intuitions even if it's not the popular thing because that's how actual discoveries are happening. Um also it takes a kind of encouragement to explore right in in academia that's how we are successful. If we just try to copy each other uh there's not going to be that much innovation. And by the way, the leading companies in AI, the frontier AI, they're all doing the same thing. It's it's incredible. Like there's one recipe and they're all doing the same thing. It's like in the space of research in AI, imagine this whole auditorium is, you know, all the things that we we know about in machine learning, the machine learning literature and what the companies are exploring is inside this class. Yes. Well, no comments on that from my side. I work for a company. >> Sorry. >> But um but I do worry I do worry that we are becoming kind of narrow enough. >> But companies could do it too, right? I think the reason why companies are not doing it for the most part and there are exceptions um is commercial pressure, right? Because you want to be at the forefront. You want to compete. you want your model to be at least as good as the other guys within the next few weeks, right? And they're afraid that if they don't do it, they're going to lose their investment, lose their customers, and that pressure is killing us. It it might kill us for real. >> So, is there anything in this um you know, this cycle that you feel a little bit optimistic about? Uh, no. Sorry. >> Well, I'm optimistic that there is a solution to the alignment problem. So there is in my opinion a way to build AI that will not by itself harm people but that doesn't solve the political problem because it can still be a tool for domination and I'm much more skeptical about our ability to do politics especially at the global level. >> I agree with that and thank you so much. We are at time and it's been a pleasure talking to you. Thank you so much. Uh requesting everybody to please be seated while the speaker leaves. Please be seated. Please seat. Professor Joshua Benj Uh thank you so much to professor Yoshua Benjio and Kalika for this wonderful session. Um we now take a break. Um and there is a poster session now during the break. Um this poster session has posters from uh top papers that were published um from Indian authors as well as authors from the global south as well as student posters. So I highly encourage all of you to check out the posters during the break and we will be back at 2:15 and we have two panels at 2:15. One will be in this room and the other one will be in L1 meeting room 7. So we will see you back here at uh 2:10 so that we can start on time. Thank you. How big are good lunch and a strong coffee or a tea to keep you awake throughout after having good food. So, uh we'll start our uh second half of the session. And here we have our second research dialogue on the next frontiers grand challenges in the AI research. Uh the panel will be moderated by Dr. Manish Gupta uh from Google research. So Manish please give a warm round of applause for Dr. Manish Gupta and her esteemed panelists today are um Sarah Hooker from uh she's co-founder of adoption labs. Thank you Sarah. Alice O uh from the Korean Advanced Institute of Science and Technology. Uh CV Javahar from Triple IT Hyderabad. >> Uh Romesh Rascar from MIT. Surya Ganguli from Stanford and last but not the least professor Subaro from Arizona State University. Thank you everyone for joining us. Uh Dr. Manish over to you. Okay, good afternoon. Uh, it's such an honor to moderate this panel on research frontiers um right after lunch. So, we'll try to keep you awake. Um, so uh let me start just to ground us all. I I see a lot of u diverse people coming with from diverse backgrounds. It's amazing to see uh so many people uh with that interest in AI. So just to ground us all uh I will start with a few opening remarks in terms of where uh how we look at the current frontiers in AI. Uh then I'm going to ask each of our panelists to share some of to start with an opening statement of what are some of the challenges that they are excited about some of the research challenges uh and and and then we'll take it from there. So um let's start with some history. Let's go back to ancient times the year 2012. Uh when artificial neural networks made a comeback, right? With in fact in those days AI was a bad name. Uh artificial neural networks was a very bad name. Um but it made a comeback uh in and the new name was deep learning. uh there was Alexet Alexet right which won the imageet competition and soon after that breakthrough what started happening was these deep learning based methods they started becoming the best way of solving a very very broad range of problems. Uh so that was in hindsight quite amazing. I mean I guess people like Jeff Hinton and so on they always knew uh but to the rest of the world it was quite amazing. Uh there was still something unsatisfying about that, right? Because while they were doing extremely well, uh they were still working well only on that narrow task that each model was trained on, right? And if you wanted to solve a different task, you had to train a new network from scratch. So now we are in this era of foundation models, right? which are pre-trained on large volumes of data using the transformer architecture. The famous attention is all you need uh paper and and we have these models that have now much stronger capability on a very very broad range of applications and not just that uh we are finding on so many problems these foundation models actually do better than those specialized models that we used to build. Uh so this is what is leading to now researchers giving them hope that yes we are that holy grail AGI artificial general intelligence where these models are doing better at cognitive tasks than humans. Uh people are saying oh now it seems like a real possibility. Uh so I think we are at such an interesting era, such an interesting time where on one hand uh these models are are pretty much transforming the world. They're transforming the industry. These models are now especially through these LLMs, through these chat bots. Uh they are now in the hands of over a billion people on the planet, right? to have easy access to them through natural language interface and and again today it's not just earlier it used to be like a bunch of researchers who used to meet at events like these now we are talking about presidents and prime ministers of country paying a lot of attention to AI look at this summit two and a half lakh people uh showing up for an AI summit uh so that basically is showing right? How much impact AI is having on the real world around us and yet as researchers I think the amazing thing is is there are so many exciting open problems. There are so many glaring weaknesses in these models and we heard about some of them. I really enjoyed the talk by Yasha Benjio. Uh so many like open challenges. Uh some of the ones that for instance my team has been working on efficiency right? I mean if you look at uh one thing which has happened as a result of the adoption of these models you've seen kind of energy consumption throughout the world right shoot up uh uh ultimately if we really want the world to be using these we need to make these models dramatically more energy efficient and we know headroom exists I mean if we do a back of the envelope I mean human brain does it at something like 20 watts uh you shouldn't require so many whatever kilowatts or megawws right to to to do better than human brain. So e efficiency then we have seen things like these models there's a huge difference between these cap capabilities of these models on languages like English versus languages that for instance we speak in in India understanding of cultures uh then there is reasoning on one hand these models are reaching international math olympiad kind of gold medal level performance and on the other hand they fail at simple tasks. that any of us in this room would be able to do with ease. Um, and and the list goes on and on. So, so what at least I find very very exciting is in particular the potential for AI to not just like transform some of these uh really tough problems that we have seeded as a nation. How do you provide good education to everyone? How do you provide decent health care to everyone? not just some of these problems that we already kind of are excited about, care about, but also frontiers, right, in terms of AI for uh for accelerating scientific discovery. So there is that potential for AI to help generate clean energy, help us find cures to all of those diseases u and and that is what at least makes me uh ultimately so excited about working in this area. Um and earlier for my team at Google DeepMind in India, our prototypical problem statement that I used to pose was think about that girl uh that lab poor laborer's daughter in the Chhattisgarh region of India. How do we make that girl have access to the same level of information as you and I, the privileged ones who kind of um have the right tools, we understand English and so on. How do we make access make her able to access information at the same level in her native language? Now my ambitions for what we do for that girl are much higher. Now we want us I want our team to be able to not just give her access to information to be able to help her learn and ultimately solve problems uh that would be Nobel Prizeworthy problems because I think all of that is becoming possible. So with that let me uh uh start with asking our esteemed panelists to make an opening statement about some of the work and if you're okay maybe we can start from people working on the low-level layers and go up to applications. So should we start with you Surya you are a uh neuroscientist uh and you've been looking at again fundamentals of how these networks learn and many of these issues would love to hear your perspective. >> Thanks. Uh I was a little worried when you said lowle that you jumped to me so I'm at the bottom of the totem pole but um yeah I I mean I agree with a lot of the stuff you said. I mean these AI systems are incredible and also simultaneously weak in many different ways. They're poised to transform the economy, society, and even the nature of scientific research itself. Yet, we have no understanding of how they work. So, I actually view computational neuroscience trying to understand how nonlinear distributed circuits in the brain work and the science of AI trying to understand how these nonlinear artificial neural circuits work as sort of quite similar. And I kind of could go in between those two fields. Um you know we we've been thinking about for example like diffusion models a very basic thing is where do they get their creativity from? How are they creating new images? We had some recent work that showed that it creates a patch mosaic of the training data. So when it constructs a new image it takes a a little patch of one training set image puts it down another patch puts it down and so on. We actually turned that what I just described into a differential equation that could predict what train diffusion model spits out. um these scaling laws for language models, right? They you know uh performance or error falls off as a power law with say the data set size. These have mo motivated significant societal investments in data compute and energy and so forth. Yet we have had no theoretical understanding of how they work. Uh in a paper that we just put out on the archive um last week, we actually came up with the first theory of how an actual LLM scales with say data set size. and we showed that we could connect that exponent to the structure of natural language itself. Um so we're quite excited about that. Um on but but you know there's still orders of magnitude discrepancies between the capabilities of brains and machines. Uh one is sample efficiency, right? We get uh about a 100 million words. A human adult gets about 100 million words of experience. Uh LLMs get about 10 trillion words of experience. if if um we were to read everything an LLM read, it would take us 240,000 years to read it. So even though the LLM at the end of the day can do these amazing things, it's much more data hungry than we are. Where does that where does that um efficiency come from? I think it has a lot to do with uh a lot of things that that humans do that these AI systems don't do. Sort of curriculum learning, active learning, careful data curation, uh many other things. Um uh energy efficiency is something that we talked about. Unfortunately there I think it's a more difficult uh question. Um we've been uh the reason uh our our AI systems are so energy efficient inefficient is because we went to digital computation itself. That's where we made the cardinal sin of computation that might sound a little weird after Shannon and Turing but we made a huge mistake when we went to bits. It got us to where we are today. But by relying on fast uh uh efficient bit flips, many of them at once, we spend a lot of energy because every fast and reliable bit flip by the second law of thermodynamics demands energy expenditure. Biological systems do it completely differently. They're slow, they're noisy, they're unreliable, but the final answer is just good enough. That slow unreliability seems like a bad design, but actually it's a feature, not a bug. It's a feature of highly energy efficient computation. And I think we need to go completely back to the drawing board and rethink our our entire stack from electrons to algorithms to go to more energy efficient computation including analog computing maybe photonic computing and so forth. Um we we we've been thinking about fundamental limits on the energy accuracy and speed of chemical computation for example and we have some some results on that. Um the modularity of the brain is also something quite incredible. It's been conserved across 500 million years of vertebrate brain evolution. uh we just create these end-to-end big transformers and I think part of the reason for their data inefficiency is because they don't have the right modularity. They haven't parcelated the learning problem into learnable decomposible subpros and I think what 500 million years of vertebrae bane evolution did is it figured out those interesting subpros and had independent modular learning uh to deal with that and we don't even have the beginning of the design principles to understand that my my last grant application was to to try to go after that. I'll stop here. Uh thanks Surya. So uh let me yeah uh let me turn to Ral who's been studying again the fundamental mechanisms of planning reasoning. He's been a critic if you may say uh if you may say so of LLMs. uh so would love to hear about your views and and I think while your bio comes up uh on the screen uh maybe one uh uh uh spicy fact that I was sharing with Ralph the first time I saw him was when he was delivering this presidential address he was the president of AAI at AAI conference he was delivering this presidential address of how as president he drove and accomplished the mission of making AI great again. So the reason AI has become such a phenomena is we can owe it to Ralph and the success he had and let's hear from him. Thank you. Thank you uh Manish. Um so it's mission accomplished already I guess. Um so first of all thanks for inviting me to this AI kumbamea. I have started calling this. I haven't been to the real I haven't been to the real Kumba but I think this one is just as religious except for the AI gods. Um so so um so I have been in AI for quite a while. In fact I believe New York Times a couple of weeks back said I've been in AI almost as long as Yan Leon. So as as I guess u as as I guess recognitions of senelity go that's probably quite the high honor that don't you think Yan uh I'm sorry for pulling up your age uh very young people um let me just start by saying that the AI systems that we currently are so first of all AI sort of became one thing which is most of you are thinking in terms of LLMs and VLMs and I would like us to think for example that they are actually an amazing ing 21st century reset of expert systems. You know the expert systems where we wanted to tell them what we know and they'll do some reasoning for us. They were very brittle. It's fun to make fun of them because we had to tell them what to do. What happened with LLMs is these are broad and shallow expert systems whose knowledge is available because we wrote it all like silly folks on the web. We just wrote everything for each other on the web. And as I keep telling people, had Sam Alman put together all his GPUs from um you know from some Jensen Wong and he said I just need data guys. Why did you guys write everything you know onto the web? He would have gotten screwed. Nobody would do that. We did it for each other and then that became the foder for the LLMs. And so they became a very interesting kind of expert systems. They the one advantage is that you're not telling them anything separately. you're writing them in your natural mode of communication but then they really are expert systems on in at certain level of understanding because they're actually both our declarative knowledge as well as our procedural knowledge. In fact, the more recent improved improvements in reasoning models can be thought of as essentially using what we have written as simulators and verifiers in the um in the post-raining phase to slowly ever so slowly compile this into the generator. This is an amazing feat especially if Sam Arman is paying for it and we are only going to pay for tokens and this is amazing that we have this technology in front of us. Uh as much as this is great the things that are interesting is that engineering of these models has far outstripped the understanding of these models. What are they doing? And we you know in AI have always made anthropomorphization sims. We basically try to look at even Eliza that dump pattern recognition system and think it is actually talking to us in you know like thoughtful language. And so it's not surprising to us that we anthropomorphize LLMs. They are certainly very very impressive but as scientists we need to understand what not only what are they capable of doing but what their limitations are. Being skeptical is nothing to be sort of feeling sad about or feeling ashamed about. Scientists are supposed to be skeptical. Skepticism is the inductive bias for good science to some extent. So to some extent what we've been doing in our work so for example these things as somebody has pointed out we have these systems which can do amazingly at the terren level on um on on math olympiads but apparently fail really badly on things like Amazon sent me a left shoe instead of a right shoe and a right shoe instead of a left shoe what should I do and it'll give you a long plan to send those shoes back this doesn't make sense even Terren st would never make such a mistake take and if people ever make those kinds of mistakes we lose trust in them. So the interesting thing becomes understanding the sort of a jagged intelligence of these uh artifacts that we have developed and figuring this out figuring out what they are and are able to do. And one other thing that we are very interested of late is the reasoning models do a lot of mumbling before providing the answer. And this has been anthropomorphized into saying the model is telling us what it is thinking about. And the model essentially imitates everything. And so it you don't think it's not going to imitate even the stuff that we might have said in in in mumbling. And so we actually did experiments to show that these things don't need to have any meaning. They still help LLMs, but they don't necessarily have to have any meaning for humans. The reason we need to understand this is not because this will have a big impact on the bottom line bottom line of Sam Altman but because we don't want powerful AI technologies to actually be u weaponized against our own cognitive flaws and so we want to understand what are they actually able to do what are they not able to do and that's sort of my research and hopefully I will spend more time explaining to you a little about some of the issues about reasoning and so on. Thank you. >> If I may ask Sarah uh to share some of the exciting challenges that you have taken on recently. >> Oh, fantastic. Um I do completely agree that the role of a scientist should be to be slightly grumpy about everything and slightly cynical. It's the path of discovery. So, it's lovely to be here. Um I thought it was very interesting how we started out going back to 2000. I think it's very striking how you view this question of where we are. I often think it's interesting to think how short amount of time has happened with modern computer science. Like modern computer science as a discipline is only really 70 75 years old starting after World War II. And depending on how you feel about technology, you may feel optimistic about that or slightly terrified. But it's fascinating because our memory has become compressed to 2012 to now and um throughout my career and I've been at different frontier labs. I think it's worthwhile placing questions in context because it drives what we decide to work on and time is our most precious resource. Um there's a few things I've been thinking about. One is that 2012 was really a fluke between an algorithm and hardware. So it worked because GPUs which were designed for video games just happen to be very good at accelerating deep neuronet networks. Um and it's interesting science and progress is often a combination of uh the the right positioning over many decades and then the right ability to translate it to empirical results. What that prompted was uh frankly the frenzy of scaling. I think we've already managed to mention GPUs or compute several times in this panel and we're only 10 or so minutes in. So let's see how far we can go. But that the two tales are intertwined. So if you think about what the last uh 15 years has been, it's been a very simple formula and very painful one. We throw compute at the problem. And the question I'll pose today is why? Frankly, because it was a very persuasive formula. uh we were we've been stuck you know we we're a very prestigious group of researchers on this stage but um we've been stuck in our own version of what happened to hardware researchers Moore's lore just throw more GPUs at the problem and uh that's because it it proved empirically successful we've already had scaling laws dropped today I disagree with scaling laws but that's okay um I just think that they don't particularly hold outside a given architecture nothing done on commonly shown neuronet networks were transferred to now. But there's a whole group of researchers who this is their church. They want to scale and no matter what. And it's worthwhile thinking well what do we get when we go bigger? Arguably there's some counterpoints which are quite fun to think about. One is that we increasingly um have uh small models out competing large. Um but the second is the following is that we pay a lot to get extra performance. we have this decreasing returns. Deep neuronet networks are really they learn the average pattern not the long tail and most of what we do I mean even this this example of returning your shoes of being able to navigate the world is about the longtail. So we have a very inefficient algorithm to learn the longtail. So what I'll throw out there today, the most pivotal moment that we are in is that um firstly this trend of throwing computer the problem no longer works as well which is fun for everyone in this room because it means research is fun again. So scaling transformers transformers are largely saturated as an architecture. There's going to be some frontier labs which double the size this year but no one's going to quadruple the size. We have a we have decreasing returns. That means what's interesting is I would say three things. One is we do have very exciting developments where we can now shape data. So data is now malleable. For most of computer science history, it was static, expensive to collect. Once you had it, you were stuck with it. That's why we spent so long ANES. Thank you to Yan. I'll I'll give a shout out there. We spent so long with Imagenet because these were these were really so expensive and difficult to collect. Now we have the ability to optimize and shape the data space which makes it much more malleable. The second thing I'll say is we have the ability to interact with the world and that's where the essence of where I think progress is going to be interesting. How do you create a model that learns from the world and continues to evolve with it and that's the thing that I'm most focused on right now because I feel like it's so critical to creating more dynamic models. Um, but the third thing that I'll I'll throw out there is that compute has shifted from pre-training because architecture is saturated to much more nimble types of compute. Why is this optimistic? Because the focus on just scaling for a decade largely meant that um it was concentrated in a few labs and a few parts in the world. The shift towards test time scaling to more dynamic types of compute. Efficiency has been mentioned several times. This is a way more interesting dynamic because it means all bets are off and innovation can happen in many places. So I find that very interesting to think about as well. Um so with that uh I think my my summary statement is uh the slow death of scaling is here and uh we can't just throw GPUs at transformer pre-train anymore but that makes life fun again and I think that's what's interesting to talk about today. >> Thank you. And uh certainly um in this part of the world we worry a lot about how to make AI work for everyone and I know several researchers here who've been worrying about the same issue working on many of those issues. One of them is professor Alyso. So I'm going to ask her uh to share some of the challenges that she are working on because she's been working on how to make these models understand many more languages, many more cultures and so on. >> Yeah. Um, so Manish started this this panel by going back to 2012. I'm going to go back to let's say like 600 AD, right? So more than I don't know uh,400 years ago. Um because one of the things that we did uh my students did is actually collect data from like the seventh century all to 20 20 2025 um within the Korean peninsula which is where I am from. Um so these are historical documents and um I'm sure it's the same in India. It's the same everywhere in the world. language evolves. So written language in Korea um started with the ancient Chinese characters which are somewhat different from the modern Chinese characters but then the language in Korea was different uh from Chinese because they had their own language but and then the writing system changed to the modern Korean or sort of semi close to modern um Korean writing uh in the 15th century and then like the mixture of Chinese characters and Korean characters uh happened for several hundred years. And then um the Japanese colonial period happened and so we have documents written in Japanese and then now we have um in the last 100 year or 70 years or so we have North Korea and South Korea and the language in North Korea has also evolved to be slightly different from South Korea. And so this evolution of language and you know looking at the history in our country through these um well we collected about 17 million documents to be used to train a language model based on these different languages that are that that capture the history of Korea. Right? So, the reason I'm saying all this stuff um and how that sort of gets us back into the diversity of languages and culture and all of that is that when I looked at this these historical documents, it made me realize how it's important to capture the different perspectives in written documents. Right? So, you know, 700 AD when uh Kore when only the very highly educated Koreans were writing in these very difficult Chinese characters um only their perspectives were preserved in our historical documents that's all we see and then the modern Korean uh writing system when it was developed it was the literature people or like the com the common artists I who are writing poems um and also uh some of the women who were writing these personal correspondents using the easier Korean writing system which at the time was sort of looked upon as like the less educated people. So anyway, so we have those documents and then you know what we're so sort of projecting into the future, right? Right. So we have these LLMs which makes it very inexpensive to create and generate so much written data now like I can you know in 10 seconds I can write 10 pages right but what perspectives are we capturing what are we leaving as you know what is going to be historical data about 2026 right so all of this these LLMs generating ing stuff like you know research papers, books, whatever. Um whose perspectives are we capturing? What languages are LLMs capable of generating fluently and also about the topics that the LLMs are good at generating? So that question makes me very concerned because we know that among the thousands of languages that we have that people are speaking only let's say about 50 of them are captured by LLMs and and and you know and even among the 50 it's probably about a dozen or so languages that you know when you try to generate language these you documents about different expertise topics that these LLMs are able to generate fluent documents, right? And even in those 12 languages, it's probably only I don't know like 10% of the topics that we're actually interested in in this world that that are being generated. So, we all should be concerned about this. uh thanks uh for bringing up these very important points and if I could make a shameless plug to my own team's work there's this project Wani where we started collecting speech data from the different corners of India and already with the data that we have made freely available it covers 109 Indian languages of which for 59 this is the first ever dig uh recorded digital data and there are eight languages that we uncovered in this process which aren't even mentioned mentioned in the last language survey of India. So there's such uh uh amazing diversity of languages that we speak and and now complimenting some of our uh uh NLP experts. We have two amazing vision experts. So let me start with one uh I mean people say what's in a name but if you were to look at CV Javahar's name you would say he was designed to be this computer vision uh both not just a researcher there are generations of computer vision researchers out of India who've been trained by CV Jawahar. So let's hear from Jawahar. >> Thank you. Thank you Manish for the nice introduction. Rah did you say this Kumbala is not religious? What >> this is not religious I is it so I thought sure >> so I'm not sure whether where we are today in the AI era today are we religious or are we even fanatic so where we are today I think the the long short history of AI that came multiple times into the conversation in the last few minutes let me also start the thread from 2012 12 and 2012 the story starts and then if you look at uh soon we we move to a model where we want to use this pre-trained models not everybody need to know and you we always wanted to hide behind pre-trained model or make our life easy and that was good enough zero and all these today's popular terminologies came into it and what we see is far more sophisticated solutions I'm really excited about the opportunities that today's AI has opened up particularly for India. I would like to look at AI as not as artificial intelligence it has advantage India in what form. So we look at this as a like a the AI for us unfortunately is only LLMs. There's only one definition for LLM. And if you look at the the there are many like a broad themes that we silently like a were keeping aside possibly for the sake of marketing possibly the sake of like a selling it easy to VCs to the media. So there are three basic things that we can always see. One is problems. Second data. Third is models. If you look at the one and two, I think there is no country superior to India. Having problems, original problems, not borrowed problems, not we don't have to mimic or go behind somebody else's problems. We have original problems. We have original data. Unfortunately, we are behind this bandwagon of we want to have that model. So, we need to understand our strength and we need to play according to our strength and the needs. This is very important. So, are we looking for solutions that are going to replace humans? We are not short of humans too. So while the the opportunities that we got we need to know and we need to know how to pursue that. So I'm I'm not saying that okay look the existing threats are not possibly the the right thing for India. There are a number of possible opportunities in front of us which very often we are all blind of because we don't look around for looking problems in our society. We look media, we look Twitters and do students do tw literatures away from the Twitter that's a way to do the world has changed now. So in this era now what AI has done good another way to look at it. So I used to say that okay look in the few years back I used I was happy that AI has changed one major thing it has democratized the research because when uh the the codes the models became public everybody can do so it was very easy for anybody entry barrier came down significantly you just need to know only Python you don't have to know domain you don't have to know science you don't have to know anything you just need to know Python and at best have of GPUs that was enough for us to enry and this so this good or bad it was also in some form it is also good because the problem formulation has a structure which is easy to replicate into newer areas it is easy for the community to get into and solve problems but unfortunately possibly today we are at the opposite end the democratization has moved to centralization as a we also need to worry about What could be the implications of today's large centralization? What is the status of the countries where are we becoming AI colonies and to many other question that we need to ask ourselves along with the safety issues that we have already seen in the morning coming in morning discussions. That's all. Thank you. Okay, last but not the least, let's hear from another eminent vision researcher, a visionary Romesh Razar. Well, I don't have CV in my name, so I can I can I'm free to explore other areas of research. So if you and Javar hinted at the centralization versus decentralization. If we if we think about what's happening today is, you know, we're centralizing data, centralizing compute, you know, hundred million dollar salaries, you know, nuclear power plants, things are a little bit crazy out there in the AI world. But this is what we thought in the mainframe era as well in the 70s and 80s, you know, where IBM and tech and create supercomputers, it was all about that. uh you know but people like Bill and Steve said no there could be a there could be a PC on every desktop and that changed the game highly decentralized compute we had it on our at our home and then soon after that Tim Berners said actually the PCs are great but what's even more exciting is if you connect those PCs and she converted the internet into the worldwide web uh and the same thing is about to happen now we are in the I would call the factory era of AI where only certain entities ities can create manufacture AI and every one of us is just downstream using it. But very quickly we're going to switch to the bazar era of AI where every one of us can create our own micro AIs. We can call them agents if you want our own agents that are trained by ourselves with our own data that remains completely with us runs on our own device. And then we need another anti- burnersly kind of a moment where we figure out how do we create the internet of all these AIs. And how many people are keeping track of open claw and moldbot and so on. Okay. All right. So that's good. So I don't have to explain this anymore. For last 10 years of my research at MIT, I've been trying to explain this. But I think we should give credit to OpenClaw for making that making that uh evangelization uh much easier. So now if every one of us has you know our own agent our own micro AI that's running on our own data doing things for ourselves and under our own control then what does it mean to build the internet what does it mean to build the network off it I think there are three main research areas uh that come out of it one is the foundation you know how do we make sure that you know every agent has its own identity its own trust is discoverable there's some kind of a DNS uh and we have former director of rod sitting here of I can um so we need a new I can uh for this so that's kind of the foundation the second research problem is we have to realize that these agents are you know also be part of the economy so we're going to have this agent commerce where uh you know my agent and Surya's agent might be trying to bid for the same work and maybe I bid you know I don't know $10 Surya is a fancy professor from Stanford so you might say $100 but why you know why is it 100 versus 10 u so the research problem there is knowledge pricing. How do you price AI model? Um, and that itself is another machine learning problem. Uh, because the agents are going to create their own stock markets, their own banks. Unfortunately, they also create their own casinos. Uh, and there's going to be an amazing ecosystem for commerce that emerges from that. You know, they'll do collective bargaining. They'll start their own companies and so on. So, that's the Asian commerce. That's the second area. And the third area is Asianic societies. As you heard about mold book, you know, Asians are creating their own religion and so on. It's a bit fake because it's prompted by humans. So if you ignore the the hype around it, very soon we'll be in a scenario where you know uh I will say to Surya, hey, I need to send my agent to a better school because I also want to make as much money as your agent. So I might send my agent to an IIT of agents, right? So there'll be Asian universities, right? At some point, you know, my agent will start creating teams with other people and, you know, they'll they'll be listed on stock market. Um, but at some point, you know, my agent will do mistakes. So, I need to buy an agent insurance. Um, and, uh, you know, to to resolve that there'll be, you know, Asian justice systems and so on. So, you can imagine and very soon when people get frustrated, they'll have to start their own religion as well. Um, and they'll all go to Kumba. So, so the main research problem to solve in the agentic society is what we call co-learning, which is how can two agents, two small AI models learn from each other. Just the same way while we are on the stage and we are here, you know, there are two main ways we we have been taught how machine learning systems work is one is through data and the second is through experiences if you're a family of reinforcement learning. But there's a third way we are learning from each other which is just insights. We're just chatting and learning from each other with very little data. And so the problem we are solving at MIT is co-learning. How can two models learn from each other even if they have completely different topologies. If you've heard about federated learning or split learning from our group, you know those work when the topology the compute graph is identical. So you can do some kind of averages uh on their model weights. But co-learning is a whole new problem. So I would say that there's three areas uh for research. How do you create agentic foundations? How to create agentic commerce? by creating knowledge pricing and then how create agentic societies where there's co-learning. Those are the three main research areas and then very briefly uh I'm in India because we have been encouraged by you know Mr. Vashnau Mr. Vishnau and Abishek Mr. Abhishek Singh and Mr. Safula on thinking about what does democratization really mean and Javahar talked about you know the risks that if that doesn't happen so you know everybody here has an Aadhaar number or a you know social security number everybody has an email address everybody has a phone number what if every one of us has their own personal AI agent uh so that project's called Dud you know which means messenger in in Hindi and Sanskrit and so D the project the effort for Dud is like a layer above Aadhaar, UPI, ONDC and so on to create an agentic framework uh for India. Thank you. So you have already seen a lot of references to kuma religion and so on and if you are familiar with AI at all right uh one of our religions is AGI right artificial which has been the holy grail uh how do we get these AI models right to do better than humans at every cognitive task right so not just one narrow task so I'm going to do a lightning round where I'd like to ask a mock >> yes like to ask each of them uh when do you think we will be reaching AGI and of course you can say never uh but each of you quick let's start with you Javahar quite far and I I don't think I'll be there to see that I'm happy yeah I think it is it is we have also have to understand what is AGI today possibly for us is more of a a dream goal today we have far better understanding of what AGA should be than what we had five year back 10 year back and that does not mean that we are going to reach in any near future. >> Okay Alice >> um I think we don't really have a good definition and I think actually several definitions are sort of mixed. So we have AI where you know like uh doing medical um data like diagnostics looking at X-ray data and stuff like that where I think we've already surpassed human uh capabilities right and then we have uh things like uh social reasoning where AI just does not work and is going to take a long time before AI figures out how people have feelings. things and you know things like that. >> So, >> so for clarification you could go with let's say Shane Shane and Deis's definition where for every cognitive task right it should do better. So let's go with that definition. >> Okay. So including you know social stuff and all of these um uh effective uh that kind of intelligence. I think that we're I I'm going to make the prediction like 25 years from now where we figure out everything. >> Okay. Ralph. Um, I think I saw AGI on the way back from lunch. Uh, so I don't think AGI is a thing. It's a brand gimmick and it's basically achieved whenever Sam Alman said it achieved, I guess. Um, so we need to be we need to be we need to be very very we are scientists here. For the longest time, I used to think people who talk about AGI are crackpots. Uh, but apparently we are all crackpots right now. Human intelligence is not is actually the ability to handle open worlds and novelty. Not just showing superhuman abilities and welltrodden task with reams and reams and reams of data. For example, I'm pretty sure that computers will solve reman hypothesis once we upload a few proofs of reman hypothesis onto the web already. Um the the other thing that I find very funny is because of this there is this stuff like humanity's last exam and and the parameter is increasing every time and I'm supposed to feel my god we are all our last exam. Humanity has no static last exam guys if your ancestors had a humanity's last exam that is nothing like the one you have that's nothing like the one your kids will have. The whole point of humanity is able to dealing with open worlds and asking questions that we haven't even thought of asking. So now you tell me what AGI is that you're talking about. And I would say there's no point about that. Ra in India where J ranker is viewed as like equivalent to a Nobel Prize winner. You're minimizing the importance of exam. Uh I'm you are >> always minimize the importance of exams. >> Thanks for for being so courageous. So Sarah, >> yeah, I think I captured it well. I'll only add one thing. I think also, you know, the quest for AGI is actually very related to um how AI started. This idea that you impart to machine skills reserved for humans. But there's two things wrong with that, right? We did that because our lens of progress is our own view of the world. But to be honest, it's not clear that human intelligence is the only thing. We have shortcomings. Our intelligence is much more global than it is individual, which means we typically all agree at the same time to do certain things. This is very effective. It's a very cheap way of learning. Um, but it also means we're very good at some things and not good at others. We're um actually not particularly good at math. Even though I guess probably most people on this stage enjoy math, but like as a you know, distribution, it's something we find challenging. We're not good at reading and walking. we find it much easier to walk and talk. So, our pathways are being really optimized for certain things. And the idea that we're just imparting this to a model, it seems um it it's limiting. And I think it's frankly interesting because there's some things that our models already do way better than humans. Um our models are probably going to be much better at mathematics than us because we're not particularly good at sequential processing. Um and I think there's other things like that. The other thing I'll say is the reason why I think a lot of the people on this on this stage find it cheap and find it that maybe it it it strips a lot of the work that we care about is that um it it nothing is binary and the idea that something is AGI is essentially a statement that we will one day instantaneously we will be in a different era. It's a very good rallying call when you need to force a certain precision or focus I guess from from people. It's a good cult movement but I think it's um most people who work on this realize that most progress is very small and happens gradually. Um and then in some ways models are much better at us than some things than others. And so I think that's worth thinking about because it certainly has manipulated a lot of our ecosystem and the fact that we're being asked this on the stage is a sign of how successful it has been at forcing this conversation repeatedly over the last few years. But I don't think it's a particularly precise conversation and for most people it doesn't really matter because what matters to them is does this technology work for me today not whether you know someday on the future will AGI arrive. >> Thanks. Thanks SA and Sudia. >> Yeah. Let me argue from analogy from a a paper that we just did that's not not in the archive yet. But like >> I thought you were about to argue for AGI and I was >> No, no. Are you >> I don't know why. >> That would be fun. >> I'm going to start on a journey and we'll see where we end up. All right. So, um here's a friendly reminder again that adversarial examples have not been solved. Like should an AGI be robust to adversarial examples? I think so. Right. And uh why haven't they been solved? So we just asked a very basic question you very simple like CR10 images they're 372dimensional right images right just what is the space of images the dimensionality of the space of images that a network thinks is a cat with high probability so I've told you the ambient dimension 372 does someone want to just venture a guess as to what oh just another reference the set of natural images that are cats is about 20 dimensional so there's a big gap between 372 and 20 Right. What is the dimensionality of the space of images that ResNet thinks is a cat? I.e. the set of images that it outputs high probability of being a cat. What do you think it is? Does someone want to shout out a number? >> Huh? >> 100. Okay. Interesting. >> It can't be because the upper bound is 372. That's the ambient space. >> Any other guesses? >> No. No, it's not the upper bound, but okay. It's 3,000 actually. >> Okay, great. >> Okay, good. >> Okay, so so um so there's a 3,000dimensional space of images that the network thinks is a cat and we don't think is a cat because volume grows exponentially with dimension. This is exponential misalignment. There are exponentially many images that the network thinks is a cat that we don't think is a cat. Okay. Why is that? Is because we showed the system a bunch of cats and it learned very well to classify natural images as a cat. But we didn't tell the network this random noise image is not a cat or this random noise image is not a cat or this random noise image is not a cat. We didn't teach it that. We didn't whack the the cat probability down in all the places where there are no cats, right? And I think that's what's happening when we train these AI systems, right? we're throwing it tons of data and it's doing some kind of interpolation or so forth. It gets even muddier if we're now putting in a logical verifier say in mathematics and then doing RL on traces like that. But we're basically like trying to playing a game of whack-a-ole, right? Like we're teaching it to solve this problem, this problem, this problem, and so on. But it's not really like like solving or learning the general algorithm, right? There's this radical generalization like one of the most radical pieces of generalization is I think what Einstein did when he we when he equated gravity with the curvature of space and time starting from thought experiments of a person falling in an elevator in outer space right the equivalence principle that's radical generalization that goes far beyond anything that was understood at the time like I don't think we're we have anything like that at the moment in AI and uh I would say we won't have AGI unless we have an Einstein level AI. Thanks. Uh my friend Abby said that u AGI was a brilliant pitch deck. >> Yeah, >> it's a great way to raise money, great way to create this hype that whichever is the first company to get to it, assuming fast take off, is the only company worth investing in. So it has worked really well as a pitch tech and now others are saying okay that pitch tech doesn't work anymore. So let's use you know AIF for robotics or Asia for world models or AF for health whatever it takes. So it's a great pitch deck and that it does create distraction. I should also say that our group was the first group to write a paper for AutoML for neural architecture search in 2014. So you know we did contribute to this craziness a little bit uh in the beginning uh you know kind of machine learning models that design better machine learning models that was our one of the one of the most cited paper from us. Uh so there is some excitement about how systems can design itself and move faster but uh if you've seen the recent um interview of Ilia from Darkh Patel uh he basically you have to watch the whole two episode he basically said it's not about learning it's about learning about learning that means we cannot create a machine that can learn everything the best we can do is create a machine that can learn about new forms of learning and that's because Manish I And the best Asia doesn't know what you had for breakfast, right? So there's no way it's not it's not omnipotent, it's not omnipresent because it doesn't know what's happening right now. So if you don't have data about what's happening right now or what happened this morning, you know, how can a model do anything for you, right? So the way it's being solved is actually decentralization. you know we we started with this amazing concept that if you learn from 10 trillion you know uh uh words you can get close to it uh but then what I was realizing is like actually what's better is to create you know some kind of a mixture of experts you know and this goes back to uh you know Marvin Minsky and society of the mind which is you know the brain is not this one monolithic machine but it's made up of different societies different components that work together to create this emergent intelligence and And these big companies are saying actually even that's not enough. Let's get into reasoning and planning which means again subdivide the task you know one for sports one for math one for coding and so on. Let's solve that together. So we are already on this slippery slope of realizing that there's no one big model that can solve everything. All has to be component size has to be divided into components and so on. So the best kind of if you look at if you play that clock forward what we're talking about is there'll be 8 billion agents you know the society of agents and that is going to create the best emergent intelligence not only is an antidote to AGI and some kind of a super intelligence but actually it will be even more democratic it'll create more shared prosperity and mentor the middle class. Okay, good. So, I think at least we did get some of that differences of opinion and so on that we were hoping for. Uh, but I think one area where probably we do agree is that there's certainly a lot of progress that we are making as a field. So, let's just and and since again this panel is all about research challenges and the frontier and so on, we've talked about now, we've talked about the future. Uh, let's maybe pick a concrete point. I don't know four years from now 20 five years from or whatever 10 let's say let's pick 2030 right roughly four years from now uh love to get your views right on what are some of the exciting research challenges right that you think you would be working on u in the year 2030 so maybe let me start with you Alice uh what are some of those problems right that you would be working on to make let's say AI work for all of humanity Yeah. Um it's a really very very challenging problem to say let's say you know I said earlier there are thousands of languages um and thousands of cultures. I mean it's hard it's hard to say there's one culture you know there's not one single culture for India for example um there's not a single culture for Korea but you know languages and culture are important for LMS to be deployed to everybody in the world such that they are doing something beneficial to help these individuals in some way right so we can think about education we can think about better health care we can think about you know just better like improving your work. So all those are sort of examples of benefits of using LLM or or VLMs or these AI models. So, so then you know if we want to make this technology work for people around the world, let's say this the you know languages that um that uh all the hundreds of languages being spoken in India, right? So there's obviously a big data problem. um you of course collected all this data but then what about other languages for which there is isn't enough data like Indonesia for example is is another country where they have like 200 languages there's no way like this can scale right we can't possibly collect thousand data for thousands of languages especially because these large you know what are called frontier models these transformer-based language models are so data hungry hungry and you if you can't just feed I don't know like Reddit or Wikipedia that's obviously not enough. You need you know a lot more variety of different types of data for these models to work as well as they do for languages like English and Chinese. So it's really not scalable to try to collect data for these low resource languages. So then what do people do? They generate data, right? So you have these synthetic data but it's like this problem of you know rich get richer and poor get poorer. These languages for which the LLMs are very good English, Chinese, French, you know, Spanish the generated data are also good. So then you know you have this positive reinforcing loop but then for the languages that are low resource the LLMs are not good. So when you try to use the LLM to generate data it just comes out to be garbage. So then you just have garbage creating garbage creating more garbage. So then in the end you it just does not work right. So then what's the solution? I mean we don't really have a good sort of single solution to solve all of this. But I am very excited because we have people like Manish and we also have communities of researchers who are going out there and trying to solve this you know many language many culture problem. Um, so I think as you know because I'm at a university and I teach students who also from come from different backgrounds, it's very important to recruit students who who have um who are interested in you know different cultures, different languages, different use cases, different types of users so that they are educated about how to build AI and they go out and do uh research Arch and development of AI for whoever uh that they are most interested in. So the community of researchers is one solution. >> Sure. No, no. And the problem you described is very real. And again, if I were to make a shameless plug, I see Bisha in the audience. She and uh some of her colleagues, they've done some very exciting work on transfer on the mechanism of transfer that happens from one language to that tail language. Uh which seems to suggest that it's it's mostly a problem of variance not bias. Uh which is an easier problem to solve. Some so some very exciting things happening. But let's just quickly run through maybe some more uh examples of research challenges that people are excited about. So uh maybe Sarah if I can ask you uh about okay what are are there problems that we aren't even thinking about that are going to come up uh in 2030. >> Maybe I'll say two things. One is I I I think I spoke earlier about what I'm interested in right now which is that I think um I I think the most intelligent system will be one that interacts. And so I I care a great deal about that right now. And also how do you adapt efficiently to very different distributions? Um most of my work has actually been closer and Alice and I have collaborated a lot of times. The reason why I really uh care deeply about multilingual is one of the most vivid examples of this. How do you efficiently uh represent a language in a way that is actually comprehensive? Um there's a curse on multilinguality which is that the more languages you try to cover uh there's a tension how do we use capacity a more meaningful way so I've spoken about that I think what I'll speak about that maybe is interesting to this is I I want to speak about the ecosystem because research doesn't happen in a vacuum typically innovation um is about the people the what is led up to that as well as a spark of combining insights in interesting ways a lot of The last decade has been a tightening of the ecosystem. A few labs uh and a rarified group of people who builds this technology uh and a lot of that has been because of the capital expenditure needed to participate. You kind of need um the the entry cost is high. I think what I'm most interested in is uh in parallel there's been a widening of who is excited and the talent pool coming in. So actually Manish you talked about this at the very beginning. anyone with Python can get going. I truly think that's been one of the most exciting movements of like what we've seen and I actually think these two are coinciding more. When I first started research, the idea that someone without a PhD could be a research scientist was um it was almost uh unheard of especially at some of the institutions represented on the stage. And so we had this right of passage that was demanded of the people. it was more of a tutilage apprenticeship and now I see that there's a very much a democratizing impact uh an intensity to talent if you care deeply and you push into this field um there is much more access at the lower layers what we need to do is think about access to particularly compute and dynamics of like ecosystem building um at the frontier of what's possible and that dynamic I don't think gets talked about enough because the frontier of a possible still remains fairly concentrated. There's still a small group. Um and I think part that you know if we look forward in four years someone was asking me what what am I hopeful for the summit. I said I always judge a summit 6 months later. Um but there's a reason I think the thing I'm most excited about is the commitments to really build the ecosystem because this is the dynamic that is most interesting. How do we bu do serious ambitious commitments to building ecosystems for innovation? Um and uh that over the next four years I see much more ability to have more global conversations about that. Certainly compared to I mean a mere two years ago at Bletchley Park I think the conversation about global dynamics and where innovation was happening was simply not present on any stage and so already I feel like there's been interesting progress there. Who should I pass it to? >> Thanks. Uh and so Romesh I was very curious what would be all those billions of agents that are also connected on this new worldwide web. What would they be up to in 2013? Well as I said they want to go to Kumbla. So imagine you know the Sithabai you know lives in rural Bihar and she wants to go to the next Kumba which is happening in Nasik where I'm from. Anybody here from Nasi? >> All right. um you know that's happening in summer of 27 and Sith just picks up the phone and says uh and what happens is her own agent which is trained on her own data which could be just a couple of megabytes of data you know her health her wishes her previous travel and so on you know starts negotiating in an overall internet of of AI agents you know about her travel you know maybe she's pre-diabetic you know her home stay you know what kind of food she can get vegetarian food she can get and so on and they also agents on the other side in Nasi you know negotiating with her on a continuous basis the railways are negotiating with her saying she wants a lower birth and so on um so you can imagine this uh internet of AI agents that are going ahead uh but you know the challenge there is that um today most of the research uh in machine learning and AI is I would call almost like a personal layer there's a big model that's trained uh and then one can individually interact with it and the model will give you a reasonable response for that individual. What we're working on at MIT is what we call population models. You know, a quick analogy will be with e-commerce, which is like I live in, you know, Cambridge right next to MIT and I can order an umbrella that's made in Vietnam. It gets delivered to my doorstep for $10. How's that possible? You know, that's because other people in Cambridge around me are also buying junk from Amazon and I get, you know, the costs get amortized and I get things for $10. So a population AI uh you know population model would do something similar where millions maybe billions of different agents you know are trying to achieve particular task the training models and so on but you have to come up with a solution that takes multiple inputs and multiple outputs right as opposed to something what we do in today's machine learning where we have somewhat of a frozen model and then we try to make it suitable best for in terms of inference for one person. So it's a very important research area of population models uh that we have to solve. And then your question about four years from now is an interesting one because you know if you look at the example from the 80s you know companies like tech and silicon graphics and uh and create and so on disappeared because of their centralization approach uh and you know the PC companies took over and so on. And you know the risk today is that all these highly centralized companies uh unless they shift very quickly you know I'm not saying you should s short your Nvidia stock right now uh but there could be a time when a whole new range of companies emerge that look very different so I would say in four years from now we're going to see a whole new ecosystem of players that are completely focused on decentralization of AI services than uh you know what we are seeing right now. So, and I'm sure you're feeling a FOMO, those of you who didn't raise your hand uh about OpenClaw and and Malbook and so on, which this things are kind of scary to, you know, use because of security constraints uh and and so on. So, you know, at MIT and elsewhere, we have a platform for you. Uh just go to Duth digid.in uh you can create your own agent in few minutes, launch it on the web and experience many of the things we're talking about. So I think lot of tools for democratization uh like that will become very common place in four years. Okay. So uh let's switch gears. We have a very diverse audience. I mean there are people with gray hair. Some very highly accomplished like during award winners like Yan and people who have been in the field almost as as as much as him like like uh Ralph as well as people like me who are not as quite as accomplished. But I see a lot of also students in the audience. Uh a lot of young uh folks. So I'd like to maybe have some of you share what would be your message to especially the students in the audience. Maybe should I start with you Javahar? Yeah, I think uh to the students uh and the audience like particularly for students my message is you have to be problem solver. You have to understand what are these tools, how to use these tools and what are the ethics of using these tools. All of them are important but you have to become the problem solvers and solve problems that really matter to the society. So if you look at where we are today the the AI tools available and what could happen in the next few years a natural extension is what you see today for the language or the character sequence prediction the models could touch the real world partly. There are lot of immediate requirements in the society. If you just take this example of helping in education. So we had multiple discussion comments and about education use cases. But remember education is not at all about watching videos. We somehow have converted education into watching videos. It is a closed loop system. There has to be feedback. There has to be interactions. And remember beyond this classroom education. So we have killed if you look at India, we have killed the all the engineering disciplines. Only computer science departments survise, electrical, mechanical, civil engineering, all the departments are closed. Forget about all the carpentry, plumbing, whatever all required in the society, we don't need it now. We need only Python programmers. That is how we have reached today. So in this system we need to have a say solutions that can train people on the fly whenever they need in doing things with hands. They are not sitting in the easy chair and controlling only remote. So we have to have solutions of that sort and that is quite possible today with the where the enl are today and with the rest of the embodied AI and the with the keywords that you hear in all these aspects it's quite possible we can have working solutions that can help in the bottom of the pyramid in education creating livelihood etc in India and this opportunity we should grab with both hands. >> Thanks Javahar. Uh let me turn to Surya. Your your message to the students especially in the audience. >> Yeah. Um it's interesting question. I mean I would say that like uh despite the proliferation of AI tools, you still need to learn how to think uh on your own, right? And and also to be able to write on your own and so forth, right? So don't be of course learn how to use AI tools. It'll make you more productive. But hold off for a second when you're learn in your learning phase and just really really learn. Like for example, arithmetic. We still teach our kids, you know, I'm teaching my, you know, 5-year-old daughter arithmetic. I'm not giving her a calculator to do it, right? She has to do it herself, you know, and and uh and and it's really important, but then eventually use a calculator. You have to go through that struggle to train your mind how to think. And that's at every stage I think like whether it's math for machine learning uh whether it's like writing like like the act of writing is tantamount to the act of thinking when I'm writing something I care about like say the introduction to a paper I absolutely don't consult chachi bt I start with a blank page and I really think about what is it what is the essence of what I want to communicate uh to my audience right and I start from a blank page and I do it myself that really clarifies my own internal thought process processes and we don't want to pollute our thought processes by by existing LLMs. I don't think um so I I think that's really important like we're still going to have to learn how to think on our own and if anything we're going to have to judge the outputs of LLM uh at the very least and that's going to require taste, judgment, thought, critical thinking and so forth. Um, so I, you know, I feel strongly enough about this that, you know, at Stanford, we're trying to figure out how to train people in the age of AI. Uh, we notice that students just hand us, you know, homework done by chatt and and and so forth. I would actually advocate like for for critical thinking classes like math and writing and so forth, we go to closed book exams, paper and pencil, right? I think that's that's the right way to do it. And homework counts for nothing anymore. Doesn't matter. I don't care what you turn in for homework because uh um but but you better be able to do well on the closebook exam. That that's what I would advocate to to ensure that you actually not because we want to punish young kids just to emphasize how important it is to think on your own. Thanks Surya. Hello. >> Okay. So I guess as the global south Indian I get the last word. Uh you still you're still there. Okay. Um so yeah, so I would say I'm actually most interested in the student researchers. I mean the students are lots and lots of big in a diverse population. I'm particularly interested in student AI researchers because you are really our hope um for the know as to where this goes. Um in in general I would definitely definitely urge you to be skeptical. Skepticism is the the weak inductive bias for good science and you really need to be especially in this day and age where most of the technology is being developed behind closed doors and there's no open science. We are essentially being told these newspaper things that our you know our model is doing this much better based on this particular type of uh benchmark things and Sarah and her team for example have did a great job pointing out how some of that um you know the benchmark studies can be you know questionable in general we should be very impressed that you are alive at this time when we have figured out how to use the collective human knowledge including the procedural knowledge to train models that will act as sort of valuable front ends to the entire humanity's knowledge and you have it and you can talk to it. You shouldn't trust it completely but it's a very useful thing. None of us had and you are the first generation to have it. But having said that you have to understand that we are training these things in probably extremely inefficient ways. we will probably look back and see these as Rube Goldberg intelligent machines for those of you who know Rub Goldberg contraptions um and and that we should be able to do this with much better sample complexity that's what for example Surya was talking about about the uh the human intelligence and the other thing that you want to remember is these models essentially don't have their own experiences they are thinking about the world in terms of what your digital footprints are. And so they will most likely stay within the humanities knowledge closure. And if you really want to go beyond that, you will look at other kinds of solutions too. And this is important because at no time in my 40-year career have se have I seen a monoculture in AI research that is as crazily concentrated as it is. Yoshua said, you know, compared to this auditorium, the whole companies are all working in this. I think he was overstating it. It's actually much less than the entire glass, honestly. Um, and everybody is essentially trying to do some of the same things because of huge commercial incentives. This is great for your job prospects, but you should still keep in mind what are you going to do about the next generation of systems which will not have the kind of issues that the current ones have, including the long range planning, including the guarantees uh of their reasoning. And you know, if you don't have reasoning guarantees and you have agentic systems trying to work in the world, they can lead to large amounts of failures. And nobody is talking about this right now because your many of your benchmarks are carefully generated such as including Tavbench such that there are no interactions between the actions and nothing bad can happen. Uh that's not the way the real world is and so you need to be looking at types of things and then hopefully you would keep this as don't think of this as a religion that you need to become a part of. This is a science where you actually the entry fee is to be skeptical and tell me exactly why I should believe this and you should do your own work. Thank you. >> Thanks R S. >> Yeah, I don't think I'll make this I I'm sure for researchers or students I won't make this specific to AI. Maybe I'll just give um my two cents about what is interesting about life. But I think that you the first thing I'll say is I think you probably have time in your lifespan to work on four maybe if you're lucky five problems in a serious way. And so you should choose those carefully. The problem matters. I don't think the tools matter as much. I mean I think most of the tools that we probably studied I'm guessing most people on the stage of PhDs in computer science or adjacent but most of that is now redundant. The first thing that we did was uh teach models how to be good at that. But that doesn't matter as much because I think the ability to seek problems is what is important. The second thing I'll say is I very much agree you have to commit to a craft. Um the act of putting in hours is incredibly important. The discipline of committing to a craft is incredibly important. It's not as fun to talk about. Um, but I think most people who are very good at what they do and the pursuit of what they want. Um, there is a pursuit of excellence. Um, I would say the third thing is work with people who are far better than you. It's the biggest catalyst. Um, and then don't choose brand names. Uh, I think that too many people make that mistake. You want to work on a large problem and sometimes when you choose a brand name, you work on a tiny problem at a fancy place. And that's probably the worst ingredient for what you want to do in the long term. Um, and then uh the last thing I'll say is uh the world is smaller than you think. Be careful and be kind to people. Um, my Yes. Um, but my first director told me that he was Korean. He opened a door for me and he was very um he he told me two things. He's like, "People remember how you begin and how you leave." And he also said, "You will see the same people throughout your career if you're good." Because if you're good and other people are good, you just see each other over and over in different ways. Um, and how you treat people uh matters because those are the same people who will uh take care of you at different stages of your career. And that stayed with me ever since. And so I say I always say start with intent, end with care, and make sure that you're looking out for people around you because if you care about problems, typically you also end up caring deeply about those you work with. So um yeah, thank you. >> Okay, so now I'm going to put people in the elevator, the remaining speakers. So Sarah, two minutes. You're in an elevator with the students. What's your message? All right. So, I would say uh well, just like what Sarah said, make friends, but like human friends, not just L human friends, but it because we can learn so much from friends. So, we're different from LLMs because we learn from interacting with other humans. But I think what m makes that learning possible is your imagination, right? So, when he says something to me, I don't just take that literally. I understand the literal meaning but then I add to it with my imagination and that leads to arguments but that also leads to empathy that leads to friendship and love and so on and that's what makes you unique. >> Thank you. And for the final word ra sorry we have to go to Romesh for the final word on the message to students. Uh sura first of all uh I used to have closed book exams and students get stressed so I started making the open book exams maybe 10 years ago but more recently there are open internet exams you can have a computer and use the internet and now my students are asking can they be open LLM as well can they use uh so I'll see how far I go but it only makes my job as a professor more difficult because I have to set exams that cannot be solved with whatever they can access on the internet and LLM so far I've been doing pretty well but let's see how how much work I can put in to make my exams not solvable by what's solvable. I would say very briefly that you know I mentioned about Ilia and Darkesh Patil's uh how many people watch Darwesh Patil by the way fantastic I think it's a must for every researcher because not only he brings in great uh speakers but he also challenges them to think about new types of research problems and again IA's podcast was talking about it's not about learning it's about learning about learning I'll make it you know uh may say that being doing research today it's about learning about learning about learning because now machines are going to be about learning about learning but we have to figure out how to learn about that. So you know I know it sounds kind of uh convoluted but that's where we are at um and becoming very familiar with these tools is critical. There is no excuse to not be a programmer today and build systems. So everybody has to be a builder. Doesn't matter what your doesn't what your background is. So go build an app, go build a website, launch a solution. There's no excuse not to do that and only by doing that I know you will learn. Thank you. Okay. I'm reminded of that dialogue in Cholay from those of you who are from India that Basanti when she talks about how UK uh basically basically the time just flew past. Uh we had 85 minutes in this post-launch panel but it's been a fascinating discussion. Uh so uh again I'd like to thank all of my fellow panelists for sharing all of their pearls of wisdom. uh amazing insights uh and and I think it's going to be very very exciting world unfolding before us and thank you all to all of the audience for being a wonderful audience uh and and let's now move to the next part of the program. Thank you all. >> Thank you. I would request all the people in the audience to please keep seated. Yeah, please. Uh I would request the um delegates to go from that side. Yeah, please go from Oh, if you could leave from the left side of the stage and if you are leaving you uh the room, please go up and leave from the back unless you want a bit more. I would request everybody in the audience to keep sitting. Please do not move from your seats. And if you want to leave the room, please leave from the back of the thing. Not from the front. Please do not come to the front of the hall. Just stay where you are or leave from the back door. Please do not come to the front of the hall. Please. No one will go for what you you can do. You know what happened today? People who want to leave the hall, please leave from the back of the hall. There's a door at the back of the hall. If you're not leaving the room, please keep please be seated in a place. Do not move. Please. Please do not come towards the front of the hall. Please be where you are. We have huge crowds at the door. So, we're trying to make sure that there that everybody moves smoothly. there. If Okay, we would request everyone who wants to leave the hall to please leave the hall from the back of the hall. There's a back door there. Otherwise, I would request everybody to settle down for the next session. Please be seated for the next session. Huh? We saw the All right. So, uh before we move to the next session, let's give a big round of applause to our previous panelists along with discussing the points. They had a big challenge of keeping everybody awake after a big lunch. Right. So, uh we move on to our next session. Uh as we know this is a keynote speech. Uh can I have the slides please? Uh the moderator for this session will be Dr. Wenut Padmanabhan. Uh I'm sure everybody knows him but just to give a very brief introduction he's the managing director of Microsoft research India which is one of the most sought after labs for researchers in the country. So uh doc Dr. Wen I would also request you to please introduce our keynote speaker and invite him to the stage. >> Thank you Rich. Good afternoon. uh you know we keep the best for the last. So this is the last uh item of the agenda and it's a distinct honor to introduce professor Yan Lukum who doesn't really need an introduction but let me just briefly talk about uh Yan. He's a professor uh at the Kuret Institute at NYU during award winner. uh till recently he was chief scientist at Meta and recently he has started his own company called AMI advanced machine intelligence and a pioneer in this idea of world models that he'll talk about. Uh in his long career he spent some time at Bellab's home which is where he invented convolutional neural networks and I thought I'd call that out because I realized recently that I was at that place when he did this pioneering work. I didn't know him then but it is a real honor to be introducing here. Yeah. Thank you very much. Pleasure to be here. They seem to be coming to India pretty regularly nowadays. Okay. I'm going to tell you about something that is not at all becoming a buzz word in AI. World models. Um and many different people have uh different meanings for world models. uh I have my own definition and I'll try to explain uh what what it is and why uh I'm thinking this way. Okay. So first of all uh we need AI systems if you want them to understand the real world and approach human intelligence not just when it comes to language or coding or mathematics but for everything in the world. We need systems that really understand the the world at an intuitive level a little bit like uh you know babies learn how the world works. We need uh systems that have persistent memory, systems that can plan complex action sequences uh so as to fulfill an objective, systems that can reason um and systems that are controllable and safe. And those are characteristics that we we do not observe with current approaches, namely LMS. Um, and in fact, the way you can convince yourself of this is that, uh, we have systems that can pass the bar exam, win math olympiads, and do all kinds of amazing feats, but we still don't have a robot that can do what a cat can do. Okay? And so, we're not talking about like super high level reasoning here. We're talking about just basic understanding of the physical world and then translating this into control abilities. Um, and we don't even have uh, you know, robots certainly that can drive completely autonomously yet. We're getting close, but we're getting we're getting close by cheating. And we're getting close, we're only getting close despite the fact that we have millions of hours of training data of people driving cars and uh, and we train systems by imitation learning and still we don't get uh, you know, anywhere close to uh, to human performance. Whereas a 17-year-old can learn to drive in about uh you know 20 hours of practice. Um maybe in India a little longer. Um at least it would take me a bit longer. Um and so you know and and a task that a 10-year-old can do the first time you ask uh you ask him or her. Uh we don't have robots that are capable of doing it. Of course, we can train robot on very narrow tasks by collecting lots and lots of data and training the robot to imitate humans. Doesn't quite work for autonomous driving because you know there's safety issues. But it would work for uh you know clearing up the you know filling up the dishwasher or something like this. Um but the point is you know we can do this without collecting tons and tons of data. The first time we are facing the uh the the situation. So how you know how does that happen? Perhaps there's one reason which is the the fact that if we train system from text there is only about 10 to the 14 bytes available in publicly available text on the internet. Whereas 10 to the 14 bytes corresponds to approximately the amount of information getting to the visual context in the first four years of life uh and also corresponds to about 30 minutes of YouTube uploads. So in terms of video information uh 10^ the 14 bytes is tiny. In fact some of the video systems that we've trained have been trained on orders of magnitude bigger uh than that. So u you know that indicates that we're we're not uh going to be able to reach anywhere close to human intelligence by just training on text. Okay. Uh so now how are we going to get there? Um so what I've been arguing for a number of years now in fact for the better part of 10 years but then be getting more uh precise over the last three or four is this idea of water model. Okay. So what is a world model? A world model is um a predictor. So given an observation of the state of the world uh or or observations from the world you get some idea of the current state of the world at least in the environment that you can perceive. You can combine this with the content of a memory that contains uh information about the rest of the state of the world that you don't currently perceive and then your world model given a a an imagined action sequence will predict the resulting state of the world. Okay, that's really what a world model is. State of the world at time t action or sequence of action that you imagine taking. Can you predict the state of the world at time t plus one? whatever this plus one uh means. Okay, if you have a system of this type, then you can feed the prediction to an objective function that measures to what extent a task has been accomplished or not. And you can also feed it to a bunch of guardrail objectives that guarantee that whatever sequence of states the world is going to go through is not going to actually hurt people or have delarious effects. Okay, this is how you would build a safe AI system. And the way such a system will operate is that um you know given the observation given uh those objective functions the system searches by optimization. It searches for a sequence of actions an optimal sequence of actions that minimizes those cost functions objectives and satisfies the constraints of the of the guardrail. That's the only way I I think first of all that you can build a a safe system. Yes was talking about earlier about uh you know safe systems. I completely disagree with him. He says they should not have any objectives. On the contrary, I think they should have objectives that we give them and the only thing they can do is fulfill those objectives and nothing else subject to guard rails. I think this the only way to build a controllable system. Uh furthermore, uh those those guardrails objectives are not going to be particularly simple to design. In fact, we're going to have to train those systems. Um but I can't imagine that we can build agentic system systems. Everybody is talking about agentic systems. I do not believe that we can build effective agentic systems without those systems having the ability to predict what the consequences of their actions are going to be. and LLMs just do not. Um so we need war models. I I don't see any other any other way. You may have some other proposals but I I don't see any alternative at this point. Um and in fact uh so the the next question we can ask ourselves is how do we train those world models? So obviously you know humans and uh most animals have world models in in in our heads that allow us to kind of predict anticipate the evolution of the world and the consequences of our actions. Um and we learn you know the basic functioning of the world in the first few months of life. So to learn about gravity it takes about nine months uh roughly and there are basic concepts you know that that that we learn faster but we learn mostly by observation a little bit by interaction mostly by observation. How do how do we reproduce this in machine? So a natural idea is to use generative architectures. Okay, so basically um let's say you want to train a system to predict what's going to happen in the video. Um show it the beginning of the video and ask it to predict the reminder of that of that video, which is really self-supervised learning of the same type that we use to train LLMs. And I've been trying to get this to work for the last 15 years, more actively over the last 10 years, and basically failing for the first 10 years, and succeeding more over the last five years. And what made it more successful over the last five years is to completely abandon the idea of generative models. Um, okay. And so the reason why it's impossible to train a system to do this is because most of the world is completely unpredictable. If you want to train a system to predict at the pixel level, it cannot succeed. It's completely impossible. If I take a video of this room, I start from that side and I rotate the camera and I stop here and I ask the system, can you predict the rest of the video? It's going to predict the camera is going to keep panning and this is a meeting room and there's people sitting. There's no way it's going to predict what you look like, what every every one of you look looks like. That's impossible. the information is just not in the in the preceding segment of the video. And so when you're training a system to do something that's impossible, it doesn't really work very well. Okay. So um so generative approaches should be thrown away if what you are interested in is for AI systems to understand the real world. It works for language because language is discrete. It doesn't work for continuous data. What you get is those blurry predictions. And we found some some ways to kind of fix this in simple cases. And this is what you know video generation systems do using generative architectures with latent variables. But in reality the real solution is somewhere else. It's to basically abandon generative architectures and instead use those joint embedding architectures or more precisely joint embedding predictive architectures uh represented on on the right. And so the difference between the left which is generative architectures and the right joint embedding predictive architecture is that instead of predicting every detail of the variable to be predicted which is y in that case you run y through an encoder and you only predict the representation of y. So you eliminate from y the uh from the representation of y all the information you simply cannot predict. Okay, making prediction at an abstract representation level and this is a crucial insight. Um, and so this is the JEA architecture that some of you may have heard of. Uh, joint emitting predictive architecture. We've had a series of paper on this going back four or five years. Um, but there are, you know, people who've been working on joint uh joint emitting architectures including me for, you know, 30 years or so. Um and so you train a system to find an abstract representation of the input signal that allows it to make prediction and from those representations will be eliminated all the stuff that you simply cannot predict. Um and you can use this as as the basis of a world model which is a version of this that is action conditioned. Okay. Okay. So if you have a segment of a video, video frames observing for example a robot doing something and an action that you know has been sent to the robot, you observe the resulting uh state of the robot and you can train your world model uh that is action condition. Once you have such a world model, you can feed it to a system that can plan so of the architecture that I showed earlier and basically plan a sequence of actions. I've explained a lot of this in a paper I I put online four years ago and uh and there is you know various longer versions of of this uh this talk more technical ones you see the QR code at the bottom um and um you know a number of recent papers on on progress along those lines and what we're building particularly in the the new company I'm I'm setting up called advanced machine intelligence ami okay means friend in French and it's a French company So um it's consistent is the idea of uh kind of building an overall intelligence system based around this idea of world model planning objective functions etc. Um so there's various ways to train those JA architectures and the main issue is to prevent them from collapsing and there is a method that works really well based on distillation. We don't completely understand the theor theory behind it. In fact, one of the few papers that tries to analyze this uh by Tan Al actually a co-author is Surya Ganguli who was just on the previous panel. Um but but there are issues with it. It works really well and some of our my former colleagues at at Meta produced the system DOV3 which is probably the best sort of general or generic uh kind of image representation system there is out there. You can use for all kinds of applications. And you know it gets better performance than purely supervised system. Um and in fact we've used this uh dino encoder to train a predictor on top of it which uh we can use for planning and and have it uh solve simple control tasks. So here is a a simulated robot and you have kind of a starting point at the left and then at the top target uh configurations and what you see at the bottom is the sequence of actions planned by this uh uh dino world model system to you know bring the configuration of the environment as close as possible to the the goal at the top. This has been applied to a number of uh different tasks in uh in sort of simple simulated robots and and we're making uh you know fast progress along those lines and somehow I can't switch to the next slide. Um until the video is gone. Okay, here we go. Hopefully there we go. All right. Um but more recently we trained sort of fairly large scale video systems based on this distillation architecture and you see some of the recent papers here and demo websites and and and various things. Um so this is the the VJPA system. So again it's a JPEA architecture is trained to fill in the blanks in video at the representation level. And uh this system is the first one that we've um been able to show that it has learned some level of common sense about the world. So it's it's able to kind of tell you if something impossible occurs in a video. So if there is a video where you know a bull is being thrown in the air and all of a sudden the ball disappears or stops in the middle of the trajectory, the prediction error inside of that model shoots up because the system tells you like, okay, something impossible just occurred. Um and uh we we've trained um the system with to to you know plan uh trajectories for for robots for real robots and you know it can do kind of relatively simple tasks at the moment and again we're making fast progress there. Um and uh hopefully can get get to systems that that can do you know actual complex tasks. Uh so I told you about examples in video. Uh the whole approach in fact is designed to work for um more than just video uh and and to be applicable to any sensor signal any highdimensional continuous noisy sensor signal uh which is the kind of domains where LLMs are completely helpless and and you know we we beat records and everything. Let me uh switch to the to the end. uh we have a bunch of work on sort of different uh another set of methods that I'm I'm very hopeful will actually lead us to uh a lot of progress you see some of the references here um for for those those papers these are these are based on maximizing the information content of what comes out of the encoder but I'm going to conclude so we can have questions um so I'm basically recommending to abandon generative models in the you know in favor of those joint emitting predictive architect ure you can imagine that this statement does not make me popular in Silicon Valley. Um abandoned proistic model I've been sort of arguing for a particular framework to understand all of this called energy based model which I didn't have time to talk about today. Uh there is various ways to train those jetps using contrasty method. Even though I contributed to inventing them I actually I'm very skeptical about them now. So those information maximization method is really what I'm betting on. And of course I've been saying for 10 years abandon reinforcement learning because it's so inefficient. Um so this is if you are interested in human level AI or or something like that. um or or at least AI for the real world and uh hopefully the you know the company I'm building amabs uh which is really AI for the real world has the per the the the goal or the purpose of using hierarchical Japa to build universal action condition causal models for for complex system control um and using them for reasoning and planning. Thank you very much. >> Thank you Yan for those very interesting thoughts and you know I would say contrarian view. Uh it's good to sort of end the day with something that uh hopefully will generate uh uh some controversy and questions. So before we get into AI and you know talk about some of the things you've mentioned I want you know we have a room full of people here humans and I know that uh you have said that you don't like the term AGI or general intelligence because you think humans don't have general intelligence. So could you maybe elaborate on that because you know all of us like to feel that we are generally intelligent. >> Yeah we we like to think that we are we have general intelligence. I had this online argument with Demis actually about about this. Um, yeah, I we don't we don't Yeah, I'm sorry to say that, but we don't have general intelligence at all. Uh, in fact, we're extremely extremely extremely specialized. Uh, perhaps in ways that we don't realize are important. Uh because all of the problems that we we can apprehend uh that we can imagine an intelligence system kind of being able to apprehend are things that precisely we can imagine apprehending ourselves. And so we think we are general, but it's just because we have extremely limited uh notion of what type of problem, you know, we can we can apprehend. And if anything, computer science has shown us over the last few decades that humans, you know, totally suck at a lot of things that computers are so much better than we are, right? So, anything that involves, you know, search to a graph, right? Whether it's your GPS planning a route or whether it's searching through the uh you know, the tree of uh possible uh moves for chess or go or poker. Uh we're really bad at this. I mean, machines are much better than we are, right? It took us a while to get there, but but eventually we did. Uh, and then let's not even talk about like, you know, solving equations and stuff like that. >> Got it. Got it. You know, I guess, you know, part of it is we are maybe slow at certain things. But isn't it the case that humans are able to learn things that they don't know like if they have given a new problem, they're able to think through it and figure out a way of doing it. Maybe they're slow, but uh, you know, is isn't that generality, >> right? So that was kind of uh the point that uh um RA actually made on the the panel just just before um you know having tests like the humanities last exam. It's complete nonsense to measure like to check whether a machine is as smart as humans because humans have as I as I pointed out in my talk have an ability to learn new tasks extremely quickly. We can only learn a limited amount of tasks but because it takes a while to learn a new task and so you know all of us are experts at different things here because we've been exposed to sort of different things and we're interested in different things and this is you know why society can make progress because we're all different right that's uh it it thrives on on diversity. Um but but the reason for this is that we cannot possibly learn everything and that's another evidence that we are very specialized because we have limited time to learn things and so we can only learn you know a limited number of things and so the ability to I mean intelligence is not a collection of skills or at least it's not just a collection of skills it's certainly not an accumulation of knowledge which is basically what LLMs are okay LLM are not particularly smart except in a small number of domains where manipulating the language actually uh kind of is the support of reasoning. So that includes code and mathematics, maybe law. Uh but u uh but they're not very smart. But they can what they can do is accumulate a huge amount of knowledge, right? That that has been pre uh uh kind of digested if you want by by humans uh before they're fed to them. Um but what about understanding? Um, and you know what allows us to learn to drive a car in a few hours of practice or you know solve new problem zero shot in a situation we've never faced is this ability to use our mental world model to basically apprehend new situations extremely quickly and solve that problem zero shot uh without being trained to do it or uh training ourselves extremely quickly to be able to do it. Okay, that's the adaptability ability. I think that is a characteristic of uh to intelligence. Got it. Uh so you know you're obviously one of the pioneers of uh uh let's call it machine intelligence or AI. Uh and you know there's a room full of people here many of whom are interested in this field. Uh what should be the goal of machine intelligence in your view? Is it to sort of mimic human intelligence do something complimentary go beyond? So all of the above. Um the short answer is amplify human intelligence or amplified intelligence. Okay, which today is mostly human intelligence. Um because intelligence is the commodity that is most in demand in the world today. If you think about you know everything about you know economics, politics and everything, what we're missing the most is intelligence. I mean when you see politicians making stupid decisions is because it's because their perception of the world is wrong. They get the wrong data or they ignore the the data you should not be ignoring first of all. Second of all their mental model of the world is wrong. They think for example by establishing 50% tariffs somehow you know they're gonna you know they're going to repatriate uh manufacturing uh and uh and obviously it's not working. Okay, it means you know the world model is wrong right? Uh then there's another way you can be wrong is that your objective function can be wrong. If your objective function instead of you know improving the the wealth of uh your country or the world as a whole is to improve your own wealth then again you know you're going to not get the result that you you might expect. And then the the fourth time uh you can be stupid or evil is or ineffective is not having the ability to find a good course of action. Even if your world model and your objective and your perception are right, you may not be able to find a good course of action to fulfill that goal. I actually wrote a small piece on it. If you go to my website, yandlukun.com, there's a little pamphlet about this if you're interested. >> Got it. I'm glad you didn't say any of these things in the morning because we had some politicians in the front row. So, I know you would leave the country. I'd be in trouble here. So, uh anyone anyone from the Trump administration? Um okay. Okay. So now let's switch to uh you know LLM's your favorite topic I guess and uh uh you know and then we'll get to robotics. Um you know you know at an intuitive level what you say makes a lot of sense right uh you know this next token prediction thing is not really uh uh uh you know what's going to get us to you know a generalized form of intelligence. But isn't it the case that if this LLM blackbox is able to produce the right answer in, you know, millions of cases, it must be learning some internal representation that is perhaps a version of the world model you're talking about, right? Because otherwise it just seems by fluke it cannot produce the right answer time and again. >> Well, I mean the the GPT architecture, right, is uh the biggest ones. they they have many uh blocks you know transformer blocks or whatever layers right whatever you want to call them um and so there is you know some degree of reasoning just in the propagation of signals within those blocks but it's limited because the number of blocks is finite I mean it's fixed and so the amount of computation that will go into the computation of a single token from the context is fixed which means if I ask the is is it the case that 2 plus 2 equals 4 yes or no the system of course will answer yes and if I asked you know and we'll do a single propagation to that thing right if I ask is it the case that P equals NP okay okay computer scientists in the room know what I mean uh it's going to spend the exact same amount of computation on this than answering whether 2 plus 2 equals 4 and that doesn't make any sense right you you need a process by which the system can spend more effort thinking about more complex questions than about simple ones. So the trick that LLM's you know LLM people have been using is chain of thoughts right you you train the system to produce more tokens than it really needs uh so that it artificially kind of you know spends uh more computation but the amount of information that is carried between one step of the reasoning and another one is just a three byte token that's ridiculous that's not the way we think we think in terms of mental models right which have nothing to do with language most of what we do has absolutely nothing to do with language It has to do with our you know representation intuitive representation of the world. If I tell you imagine a cube floating in the air in front of us here. Now rotate that cube by 90 degrees around a vertical axis. I you can readily imagine this and you know that the cube looks exactly the same as when you you know you got started um because you know what a cube looks like and it's got a 90 degree uh symmetry. Um you know this has nothing to do with language. Okay, it's you know mental imagery or whatever. Most of the thinking that we do is of this type. It's only when we write code or when we do mathematics that we actually manipulate symbols and that it helps with the reasoning but that's very specific and it only concerns a few percent of the population. >> Got it. Got it. So you know I want to sort of uh you know double click on both language and then you talked about using video as a modality to learn from. uh now I guess one view is that language does encode a lot of let's call it sort of world model rules like you know when when I write a sentence for it to make sense to humans it has to correspond to reality I can't say oh I dropped this bottle and it sort of went up right that it won't happen u so that is on the language side so it does uh uh capture information you know beyond just just the language aspect on the video side yes there's a lot of data but is it the volume of data that matters or the number interactions and the sort of the variety that really matters right because >> yeah I mean a lot of it is the the the bandwidth of the data and the which means you know in how much quantity is it available but also the redundancy in it so when I talk about this example you know 10^ the 14 bytes which is a totality of all the publicly available text and it's actually what four-year-old sees during is of her life you know 16,000 hours of wake time. Um, you know, people tell me, "Okay, but video is much more redundant." And I say, "Yeah, and that's exactly what you want." Self-supervised running only works if the data you train it on is redundant. If you train a system on completely random data, it can't learn anything. It learns it it, you know, it builds on the on the redundancy and it discovers the underlying structure and redundancy in the world this way. Uh and in text there is just first of all not a huge amount of redundancy and not much bandwidth and a limited amount of it and we've already exhausted it pretty much. Um the only way people are making uh progress nowadays with LLM is through either fine-tuning or training on synthetic data. Got it. Got it. Uh I was just informed that the prime minister's security team is waiting outside so we have to wrap up with uh you know let me ask you two two more questions. Let's go to robotics. Right. So earlier today I you know happened to spend a couple hours with Bill Gates who had just spent some time in China and then he came here and I told him I'm going to chat with you on stage and uh he uh you know made the point that uh um you know he back in the day he thought robotics would be solved before writing essays but the reverse has happened. But his uh reason is that uh it is the hardware robotic hardware that has been too limited right the human hand has got some 27 degrees of freedom it seems and uh you know hardware is not there. So how much of the lack of relative lack of progress in robotics is because we've been working with hardware that is very limited as opposed to the fundamental model and the algorithms and so on. >> Okay. There's several issues with hardware. So in the in the past up until you know a few years ago um the case could have been made that the the the mechanics the electrome mechanics and low-level control in robotics was not you know up to snuff with uh with with biology. I think that's not the case anymore. I mean you see those you know robots doing somersaults and kung fu and whatever. Uh now you have to realize all of this is pre-planned right? So there's no real sort of adaptability understanding of the world or anything. It's all pre-planned with kind of a precise uh dynamical model written by hand. It's a bunch of equations. Um so there is a world model. It's a question. Uh I think it's largely solved except it's not as efficient as biology like you know those humanoid robots run down the battery in like an hour or two and uh obviously we have more autonomy than that. Uh so that's that's one question. What's not solved is sensing. So we cannot as humans we cannot survive without touch. We can survive without sight and audition, but not without touch. And touch is absolutely crucial. And if if you uh numb your hand and you're asked to grab an object, you can't you can't do it. You it's it's very very difficult without uh sensations. And so the the the hardware issue of touch sensing is not solved. But um but we could have you know robots that are as agile mechanically as a cat. This it's not an issue anymore. We just can't make them smart enough to do what a cat can do. And in fact there's a bolder statement there which is that we have all of those companies building humanoid robots. And absolutely none of those companies has any idea how to make those robots smart enough to be useful. um except in very narrow tasks for which it's economically feasible to collect lots and lots and lots of data and training those robots by uh behavior cloning essentially. >> Okay, last question and let's make it quick. So you've just started a company. Uh now you know the world is swimming in capital investment in the LLM side of the world right I mean your former employer my employer and a couple of others have probably spent more than the GDP of most countries right in the past year. So uh what would it take for that to change? So you are betting on a different way of building intelligence. Is it that you will show some step function improvement in capability reduction in cost improvement in safety like what would because otherwise the world would just go on the current train right yeah so the you know the old story was you you know if you're a Saltman or whatever you convince your investors by claiming you're going to reach AGI it's just around the corner uh I'm not okay first of all I don't believe in the gene AGI first of all okay human level AI is an attainable goal And there's no question that at some point in the future, not next year, uh you know, we'll have systems that are as smart as humans in all domains where humans are smart. It's going to take a while. Um but what I tell them is that, you know, we've seen in recent the recent decade and a half, we've seen two AI revolution, the deep learning revolution and the LLM revolution, which is building on top of deep learning revolution. There's going to be a third one and the third one is you know AI for the real world sensory data video AI that can reason and plan which uh you know Rahul Kampetti was uh was talking about uh and and soya as well and so that's the next revolution that's what I want to build that's what I'm building and I'm you know apparently being able to convince sufficiently many investors for that >> thank you wonderful >> thank you so much Uh thank you everybody. This has been a great session. Uh thank you. Thank you. They they shut the mic off. >> Thank you everybody. It was a great symposium. >> Thank you for being such a gracious audience. >> And let me also take this opportunity to thank the India team. Uh Abek G is here, Kavita G, uh Rich, >> Sanjana, uh Amoa and Mayang along with professor Pen and Kalika. Thank you everyone. Thank you to all the PC members for putting up such a wonderful program. Thank you. Uh, anyone