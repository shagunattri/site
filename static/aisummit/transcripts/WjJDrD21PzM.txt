Speed to tracking fraulan or safal utapan LVM3 M4 rocket rocket. Thank you. >> That's it. Okay. Now that is what showing off looks like. Um so uh again as I said the speech recognition is where it all starts. This is a very efficient model. Little bit over a billion parameters which can run real time run with multiple speakers run across languages. The same model uh supports all languages. So you don't have to deploy them separately. I think this is where it all starts in terms of generative AI. Of course, the next thing is you got to make the AI speak back to you and that's where we have Saram Bulbull which is our texttospech model. Um whether you're experiencing it as a voice board or a voice mode in a phone, this is what you actually touch and this is what Sarvam Bulbull does. We now have built very natural expressive Indian voices for a variety of use cases, right? Whether it is storytelling, whether it is a a voice of a person in a contact center, whether it is someone acting a bit bit funny, all of those things are supported. Uh these are low latency models which can support streaming. So you can actually stream the audio back and they are production grade in terms of stability. This is very important because um often you do not recognize that in these large language model based tools there is variation and the variation can be high for audio synthesis and we have focused a lot on ensuring that there is stability between generations of this audio stability across multiple turns stability across long tail of words etc. So in terms of benchmarks uh on the 8 kilo herz uh frequency which is what you hear on a telephone uh we have compared uh externally the preference of our model with models from other companies and clearly find that servul does much better. In fact at the cost point it is available it is a significantly obvious choice for all folks building with voice in India. So I'd like to call on Himman Shu on the stage to again show some cool demos. Uh hello everyone. Uh thanks Pis for talking uh about Bulbull. But now I will let Bull do the talking. That was so funny. But um honestly today was a bit much. Yeah. Like tell me what on earth is wrong with Rohit? Every single time full drama mode one thing after another and I kept thinking please just spare me but then I don't know talking to you right now. It's kind of nice. Makes things feel a little lighter you know. Okay. No problem right. So as you see uh Bullbull can gossip better than your best friend. It can explain you topics in a way you wish your teacher did and it can even narrate your native folklore stories just like your grandparents. So see bull in action. V2 V3. Let me show you how. Force Newton. artificial intelligence. So be it voice box, content creation, edtech, just bring your use case and make bullbull your voice. Thank you, Himanchu. Uh again would like to uh recognize how important it is means for education. Then we have the remaining 13 bits in which the 12th bit is called the small a bit. Then the remaining six bits are compute bits. These three are the destination bit and these are the jump bits. In small computers. So with serum dub language should never be barrier when it comes to education. It's not just translated content but transformation at scale. Thank you. Over to you Pradesh. Thanks. So this team did not want to show off so much. What they did earlier this month was to live dub the budget speech of the finance minister as it got telecast on live television. Right. There is no harder benchmark because the budget speech nobody gets to see. So we definitely didn't get to see the budget speech. Uh it was live telecast. Uh it had all kinds of jargon numbers. Um it reached about 4 and a half cr homes. Um and the kind of feedback that we received uh there were examples where somebody said for the first time I understood the budget as it was playing because I heard it in Hindi. Uh and somebody else said uh oh is Nirmala Daraman ma'am speaking Canada right so questions like this came up and we are very um enthused by this because language should not become a barrier it should be a bridge right and the ideas should flow through no matter what language you're speaking all right so that is dubbing state-of-the-art models in that and already deployed at scale uh I would now like to move on to vision u it's it's Yes, I mean in the in in the human uh brain for example, the amount of gray material for vision is so high. It's one of the most important perceptual tasks and it's an area which started from scratch in the last 8 months and have now built state-of-the-art models in this area with a small team uh which is pulling quite a bit of weight, right? Uh our focus was quite a bit on general vision recognition but with a focus on document intelligence. We are very deeply interested to digitize documents whether it is ancient documents in variety of scripts or modern documents with complex tables, handwritings, notings etc. So quite a bit of understanding uh was focused on given a document extracting the layout appropriately. How do you read the page? Uh visual grounding was also an important thing. You need to take large language models and ground them on understanding vision. Um we of course also had to in tailor it uh for various components. Uh what I mean by that is we took from scratch a three billion parameter model. It's called a hybrid model because it combines state space with attentionbased layers making it very efficient. We trained this model uh for I think about 16 trillion tokens of Indian language of English code etc. And then we took this model and grounded it on vision capabilities uh with a continued pre-training on 400 million images. That's the visual grounding and by adding these new components for vision. Um and then this became uh the uh b the baseline with which we then fine-tuned models for different tasks. And here is a a benchmark that is making quite some u rounds uh on an international benchmark almo which is uh by Alen AI which is a nonprofit working in the space of AI. They released their own models in the open source on English. Uh we were able to perform the best improving on variety of models. including being able to detect tables, uh, handwriting, math, multicolumn, all kinds of complexities that documents have uh, naturally. Uh and this is a combination of high quality continued pre-training, the supervised fine-tuning and as you can imagine reinforcement learning. The ability to take a task like vision and be able to improve it with reinforcement learning to solve these long tail of problems was one thing we focused on and I think we are just getting started in vision. As I said eight months back we did zero vision at Serbam. Today we have a state-of-the-art model and we are just getting started and we feel very excited that we will build very strong models on all aspects of vision including for example uh detecting what's happening through a through a CCTV camera. I also on Indian languages our lead is even higher. We are comparing ourselves against models of much much larger sizes and we are able to uh significantly improve accuracy. I would now like to call upon Krishna to talk more about this. >> Thanks Pratush. Um good afternoon. Um I would like to say uh what is highfidelity document digitization? It's not just a simple text extraction problem. It is much more uh involved. For example, there are several types of documents which have much intricate complexities such as newspapers, government records, textbooks and so on. All of these have to be identified for their structure and the content they have within them. So how do we do that? Firstly, we do document layout understanding. What that means is given a document we are able to parse where is a page number, where is a heading, where is a paragraph, where is a table and so on. Now with this information what we are able to do um next slide please. Yeah. So with this information we are able to perform visual grounding and reading order predictions which mean that given a complex newspaper with easily 100 blocks here we are able to say what is the headline what is the title of a article and then say that is order number one two and so on all the way onto 108 reading order. So with this kind of visual grounding and layout understanding, we've been able to put a very tight hardness around the server vision model. So moving to the next example, in addition to all the hardness that we have, we also do something called knowledge extraction. Most traditional vision language models and OCR models perform text extraction. What we do at Serwam is much more uh advanced which is knowledge extraction. For example, the chart present up there is not just extracted with the text there but we are able to caption it in various languages and present them in markdown and JSON and other complex formats so that downstream applications can easily ingest the data. And finally with all of this uh architecture we've also been able to solve some of the most complex handwritten documents which on the left you see this is a letter from Abraham Lincoln from 1800s and this is from Dr. Bedkar from early 1900s and we've been able to digitize it with like almost 100% accuracy and this is serum vision for you. Thank you. Thanks Krishna. One use case of vision that I am very deeply passionate about is using vision for recognizing what students have written on paper to digitize their work and then be able to provide them personalized feedback on what they learned and what they did not. Because in the absence of being able to recognize actual human work, we are restricted to forcing students to always go through digital interfaces. So imagine students across the country writing exams on a weekly basis, not to be tested, not to be evaluated, but to be given exact feedback on what they understood and what they need to improve on. Right? I think that is a genuine possibility with the uh with the work we are doing. In fact, we are collaborating with the DPS school, NCERTT, the Ministry of Education to make that happen uh in this academic year. Now, I would like to talk about our large language model. Uh we have been of course building models uh across the vision model. for example is also a large language model but it is a three billion parameter dense model again trained from scratch by us over the last 8 months but it is important to scale up and there are two other models that we trained and we are talk talking about releasing them today one is serv 30 billion this is this is a 30 billion parameter model of course all of you know uh that the larger the model, the more the parameters in it. A it is more capable but of course it is harder to train, takes longer to train and longer to uh run on in in production as well. But 30 billion in today's time is a very small model. It is actually a mixture of experts model. It has actually just 1 billion activated parameters. Meaning we have a 30 billion parameter model but in generating every in output token it only activates 1 billion parameters. Other competitive models such as Quen 30 billion for example have three billion activated parameters. Right? So even in the mixture of experts world we have gone towards systems which can be very very efficient for inferencing. It supports a context length of 32,000. Uh meaning that you can have longunning conversations with it, longunning agentic interactions with it. Uh it is pre-trained again from scratch on 16 trillion tokens of text. Uh this is a lot of tokens. So a token of text think of it as um about uh one about uh one one two/irds of a word, right? That's a good estimate for English. Uh so you're talking about trillions of words of text uh that have that have been used to train this model again curated completely uh within serv uh it also is a very very efficient thinking model. It beats all models out there office class in efficient thinking and I'll show you the results of it. Uh again this is in the towards the principle of making these models efficient. These are reasoning models. H then they think but the amount of thinking they do can impact how long it takes to get an answer. How how costly it is. We have worked to make it very very efficient. And finally the intent of this model is to be a realtime conversational engine for things people build. It's small. It has single one billion active parameters. It has a large context window. uh it allows you to work with Indian languages and then have conversational experiences with users. Quickly showing you benchmarks. These are very popular international benchmarks on math, programming, uh knowledge and you can see our model being compared across open models from different companies and you can see that in variety of those things the server model 30 server 30PB actually does exceedingly well. And if you look at agentic benchmarks where agentic is of course where there is tool calling, there is usage of multiple tools which the model has to choose from on variety of things. For example, browse comp. It is the ability to use the the the the web search to improve the answers that the model gives out on on Sweetbench which is about programming on Tao Square which is about tool calling. You find that our model is competitive with the best models that have been released in this model scale while being significantly smaller in terms of the number of activated parameters. If you look at thinking budget, it's one of the most important things here, which is how long do you give the model to think before you can answer. And on the x-axis here, you can see how much of thinking is allowed for a model before it answers questions on math from this benchmark called AIM. And you can see that other models perform very very poorly if asked to be in some sense fast, asked to be compact. And you can see that the serum 30B significantly outperforms both at the 8K and the 16 thou 16K scales compared to the latest models that have been released from uh other companies at the same size. I just would like to just again bring this into focus to what we are doing. We would like to make AI work at a population scale and being able to do it efficiently becomes a very very core thesis and things like this add a huge step up to how efficient these models are. I can actually deploy a model with much smaller token budget achieving the goals uh which would otherwise be much more expensive. also on diff another task here hmmt even in this task you can see that the performance significantly is higher for both the 8,000 and the 16,000 token budgets of course this is English math reasoning that I showed you on Indian languages we of course do very well whether it is on fluency being able to follow a particular language usefulness conciseness we significantly outperform models that have been released in the open source source at this model scale. In fact, these benchmarks don't do justice to the fact that the model understands Indian languages natively. Uh it can answer a question in math specified in an Indian language while being so small, right? And to therefore demonstrate uh those use cases. I would like to show how India at scale can use a model like serv 30B by demonstrating what is possible with a feature phone. And to do that I would like to invite Aditya. >> Thank you Pratush. Uh super excited to be here. uh just wanted to uh I think uh referring to what Pratus has said I think we want to serve a billion Indians and small efficient models are important for that and what we have been able to do is uh plug this 30V model into the uh uh into a conversational AI assistant and uh you can actually use the conversational AI assistant by through a phone call and that's what I'll be demonstrating >> you can mention What phone is that? I don't suppose people see Nokia phone startups. Victim services. Yeah. So this is what the 30B model can do. Uh vernacular, low latency, high performance uh for a billion Indians. Back to Pratish. So just to recap, this was a 30 billion parameter model trained from scratch in about 16 trillion tokens uh supporting Indian languages with the very very efficient custom tokenizer. We have built very significantly small activated parameters makes the cost of inferencing very low. Supports state-of-the-art performance on things like browse comp which is required to search the web and answer questions like this. Able to do agentic tasks very well and on all other things like math and reasoning is very very efficient at much smaller token budgets. Right? So we think of the 30 billion parameter model as the efficient workhorse that will run at scale to power a billion conversations a day and we're looking forward to deploy that across all the things that we do at server. All right now moving on to the next model that we train. We so we trained a 105 billion parameter model. Now this is also a mixture of experts model. Um it uh actually uses 9 billion activated parameters. The ratio of activated parameters is actually larger in this model. But the reason we ch did that is because it uses efficient mechanisms of what is called MLA to make inferencing more efficient at this size. Uh such that it is roughly about two times more expensive than serving compared to the 30 billion parameter model. It has a larger context window of 128,000 tokens. Therefore allows you to do more thinking and do more complex tasks. It is on par with most other open models uh and also with several closed source frontier models of its class and it is also designed to do complex reasoning tasks very well. I would like to now show you some benchmarks. These are uh these are again hard reasoning benchmarks. GPQ at Diamond, AMA 25, Beyond AM, HMMD and MMLU Pro is a knowledge task and compared to even larger models like uh the GPTOSS 120B GLM 4.5 air again a larger model we perform very well across the benchmarks uh in this particular uh model right and these are just to give you a sense pretty high numbers where you can solve complex tasks with a model at this size in terms terms of uh Indian language performance you can clearly see that we perform much better than models of other uh from other uh companies in fact even with something like Gemini 2.5 flash which is a bigger model more expensive model we find that the Indian language performance of this model is even better right on live codebench which is a programming task we find that we are almost close to the uh best models out there of of at the model of size enabling this to be used also for software engineering where you can fix smaller bugs, write smaller pieces of code with this particular uh model on browse comp. Again, something that we have focused a lot on which is being able to search the web. We find that the model outperforms other models significantly and hence we'll be able to effectively use search in grounding its answers. Right? In terms of agentic tasks where there is tool calling involved, we are able to show that the model actually outperforms different models at its scale uh compared to how they perform. We would like to welcome honorable education minister uh to the presence. Thank you sir. So uh we find that even on the uh to benchmark we have state-of-the-art numbers at at a model of this scale. In fact, I should also mention that while this model is already performing this well and is state-of-the-art uh at various benchmarks, this model can go even further and the team has many tricks up its sleeve to improve this model further and we'll actually come back with much better numbers in perhaps a couple of weeks time and have this model put out there. Right? So okay with that bench with that background I also want to again highlight that at this size at a 105 billion parameter model just to put in context what this model can do this model at this size on most benchmarks beats a deepseek R1 model released a year ago right which was a 600 billion parameter model we are today at this size able to do that of course this is the fast evolution that these models are able to go through but this was a model. This was a model trained from scratch 16th the size of that that model and today is now providing intelligence which is competitive to what deepseek was earlier in terms of getting a sense of how this model performs. It is cheaper than something like a uh Gemini flash but outperforms it in many benchmarks. Right. With that background I would like to call Ishan to show us some use cases with it. So, a quick sneak peek into the 105P server model. Okay, so here is a extremely complex task that uh require that has a company balance sheet uploaded and needs to do structured analysis. This includes a bunch of code execution where our own model is writing the code and it is also being executed by our own code interpreter. This includes two three hops multihop reasoning and as you can see the data is shown on the left pane an editable artifact where it is performing analysis across three years of the balance sheet. So you can go ahead and ask whatever questions you want as long as it has access to that code. It'll just keep doing it. Bringing it down a bunch. Here's a question that a lot of Indians probably have as a fast growing two four-wheeler market. As you can see, this is a thinking model. So it will think what how do I analyze the user's query and then it'll search the web as to what where where can I get this answer whatever sources it likes it can go and get a lot more information from them before summarizing the entire thing. Okay. Now this is a quick video about so a bunch of us actually think in our native languages but we go on. Can someone pause this? Oops. Can you pause this? Yeah. So a lot of us think in our native languages but we write it in Roman scripts and hence here is uh students struggling to learn trigonometry and asking about the basics in their own language. Uh as you can see it writes down everything and uh puts it down in a nice format in a table. Can you play And lastly, India is a country of many languages and we cater to each and every one of budget. Here the model was asked in h in Maratti to explain the impact of the latest union budget on a textile exporter and it responded in Marati calling out all the benefits that have been given in this budget. >> Okay, let me just go through that once more. Right, if you can go to the first example. Uh, of course what you're seeing here is our chat application. Right. And uh this chat application will be in your hands soon like tomorrow. Right. Uh but what what we are showing here is somebody uploading an a CSV file and saying that I need to show me the structure of the data, column name, etc. This guy does not know programming, Python, etc. He's able to do that. On the right side opens what we call an artifact or a document. You can see the data. You can actually edit it. You can actually maybe make something else, make changes, export it, etc. The person goes on to ask uh display the recent three years side by side. So what is happening here is that the model is not answering this directly. The model is processing the input, processing the uh the data given, writing code which then runs on the data. And the important part is that the code execution is stateful. So what I do in the first turn of my execution that same code state is available for subsequent states for subsequent turns of the conversation. This entire orchestration we have built grounds up and you'll hear a different team talk about how we have built this this particular orchestration engine. But notice that every step of the way here is handled by serum 105. It understands the question. It parses the data. It writes the code. It gets the output. it writes this document. So a model like 105 billion parameter model trained from scratch in India can be a productivity tool for variety of things India does. I imagine laptops coming with a tool like this connected to the 105B model just 9 billion activated parameters and a bunch of productive tasks happen. The next video please. In this case the person asked something in romanized uh Hindi. They typed Hindi but with English alphabets and the answer comes in the same style. It's of course a question about trigonometry and I have to think a little bit to see if it it is all correct but you are able to get answers. We genuinely believe that for education this can be a very important tool where students can write about their questions and because the model is very strong in reasoning as strong as deepseek R1 was the 600 billion parameter model last year it is quite capable in answering questions end to end both with scientific reasoning uh with with grounding in terms of knowledge etc. And the final example if you can replay that >> this was somebody exports latest. So you can of course use voice to write a question because sometimes people find it hard to type it and because the model has been trained on trillions of tokens of all Indian languages, it is able to respond back in that particular language and you can continue the conversation. So that is uh Saram 105B model a very capable model in terms of reasoning, math, coding but at the same time very capable of working with Indian languages if combined with the agentic orchestration that we will show you. This can become the productivity workhorse for what India will build. That is server 105e. As I said, the team has a few more tricks up its sleeve and we will even improve on the benchmarks that we see. We are very clear that we'll beat every other model at this model scale uh in all the v all the benchmarks that matter. Okay. Uh so before I move on, I want to say the following. the 30 billion parameter model, the 105 billion parameter model and the three billion parameter model which I showed earlier for vision. They were all trained with the compute that we got access to from India AI as part of the um mission India AI mission. We would we are grateful to our partners in Yota who provided the compute. We are grateful to our partners in uh Nvidia who have worked with us as if they were part of our team uh and really made this zero to one journey. Uh it is hard to appreciate how many challenges come in a zero to1 journey where you're creating trillions of tokens training models of this size uh getting infrastructure up and making it reliable and all of that all of that difficulty we went through but I think it was a superb learning experience. We just know exactly what problems to solve going ahead and we'll focus on them. But to ensure that everybody else can leverage what we build, we will open source 30 billion and 105 billion parameter models. We would genuinely like to make this a community effort where people are using these models are able to build agentic applications for their own uh apps uh able to build conversational experiences with this and we take that feedback and keep improving it. As I said very very small models for perception, small models for real-time conversations and larger models for productivity. The journey does not stop here though for models. Of course, one can build even larger models. One can build a trillion parameter model. One can build from all likelihood the even the largest models out there are multi- trillion parameter models. We want to be mindful in how we do the scaling. We don't want to do the scaling mindlessly. We want to understand the tasks which really matter at scale and go and build for it. We are deeply committed to figuring out how we can have an Indian alternative uh to coding models out there. We are working on it and we will have something on that soon. But we want to be very mindful of what we do with model scaling. We want to figure out ways to make these models available at scale and use that to improve their accuracy. So that's models for all of you. Okay. So that was models. But all these models need to be working with applications and it is these applications that provide us the clarity the insight about what to make these models good on. Um and that is where we have focused quite a bit on applications and I am delighted to let the different teams that have built these applications uh present them to you. The first one is serum for conversations. Uh conversations voice AI uh I think has graduated from being a product uh uh platform to actually being infrastructure. Just like we think of HTTPS protocol as infrastructure we build on top of it. We should be thinking about voice AI as general infrastructure on top of which people can build variety of experiences and towards that we have taken a very strong step with Saram for conversations for which I would like to invite Minakshi and Shoubam to present it. >> Hey hello I'm Shbam. >> Hello I'm Minakshi. >> India is a diverse and vast country. I'm sure you're well familiar coastb and we are a voice country where voice is not just the UI of AI but it's also the UI of AI. Uh and I'm sure uh you you would have understood that conversations in India can probably start with somebody yelling in the background, a baby crying in in in a traffic jam and still the conversation can end with right. This is where autonomy stress tested. This is the stress test of AI. And building any conversational agent that does any work for you is not a demo sport. I'm sure a bunch of you would have seen some demos, built some PC's, tried out yourself. It's a deployment sport. It's it's a contact sport. It's hard. And the difference between a drop off and trust is one word. Empathy. The difference between something being fully in control, something going off the rails is governance. Who can access it? Did somebody really access it? Where do I see all of this data? These are the problems that that need to be solved for conversational AI to be truly real for India. So with this in mind, we built out the Sambad platform with the goal of making every conversational truly personalized to the billionth Indian absolutely reliably. And I'm sure a bunch of these things I'm I'm sure you you would have seen. Let me take a deep breath and and show you around. With Sambad, you can actually build out a humanlike natural conversational agent that can speak the language that India speaks in 22 scheduled languages of India. Deeply embedded in the organizational fabric of an of of any organization is something that comes naturally comes comes built in not bolt-on. This is also something where that that understands where and when a citizen, a customer, a partner lives in the context of your organization. With this we built out Sambad to be fully in-house the full stack of AI that uses the state-of-the-art models SARS bulbull and the sovereign models that you just heard of to have that deep sense of control that every organization needs to deliver that truly personalized conversations and sambar would allow you to scale elastically to whatever your organization demands. It is built with fundamental principles of self-improvement in a truly governed system with Indian unit economics truly at heart and and enough of speaking I'll probably let a demo do the talking and and this will probably be relevant to somebody who is much like you high productivity. >> Hey Siri call Swiggy Instamart please. Calling Swiggy Instamart mobile. delivery Press charge packet layers packet two packet nachos or salsa dip pad. India.5. Don't worry. 2.5 L two packet nachos one salsa dip or 142.5 L bottle after total bill 308 order in. Now, let me welcome Minakshi to share a little bit more about how these truly empathetic agents come in action. Thanks Shbam. So I'll take you through behind the scenes on what makes conversational agents reliable and scalable. Firstly, we'll start about what does it mean to build an agent. Whether you're automating a high volume customer support desk or u or a sophisticated sales engine, what you would need is low development time in order to develop your agent. In Sambad, we offer a co-pilot where you can provide natural language intent on what your agent is supposed to do and that converts into agent SOP with guardrails and the agent is production grade from the get- go. We also offer features where you can configure the language colloquialism. What this enables you is that you can customize it and suit it for a genzi in Pune or a farmer in Pley all for the same agent. Agents can be equipped with MCPS, tools and knowledge bases to ground the context based on your organizational data. Now that you've built an agent, how will you deploy it? How do you know it is ready to face the world? Thousands of user personas can be simulated with sambad where you're going over conversations even before a live user call is placed. This helps you to identify any issues uh which can be related to anomalous behavior or edge cases and resolve it even before you get to production from day one. The next thing that we deeply care about is at scale. How do you ensure that the agent caters to every user's needs and preferences? Sambad powers a hyperpersonalized customer journey multi-agent orchestration which spans across multiple days, multiple channels and the way we do is longunning persistent memory which has a shared context across channels. Okay, now that you've deployed at scale, you're looking at interactions, but then millions of users are interacting with your agents and manual quality checks is absolutely impossible. Sambad solves for this by converting the unstructured conversation to structured signals which will help you to do self-evolution of agents. The way it does this is whenever the instructions are leading to spoious behavior or caused customer frustration, those agents those agent instructions are improved over time. What this helps you with is the agent is not only consistent but it gets smarter, better and more cost efficient based on the data as a flywheel. Well, talk is cheap. So, let's just go to the numbers. I'm very happy to say that Sambad offers subsecond latency and because of this and because of this our customers are able to go live within a day and we are already powering 100 million interactions and the customers are also able to realize 10x ROI. In fact, the demos that you've seen today are all powered by Sambad and we are using the underlying state-of-the-art models SARS Bulbull and our sovereign LLMs. >> With this, I'll hand it over to Shoubam. >> Yeah. Yeah. I'd like to share some more numbers. So, that thanks to your technology that you've been cooking for a while now, we've actually grown three times every quarter and we've crossed a million interactions per day. We actually hit 2 million a couple of days ago as well and that I think is truly called exponential scale and that is what we really like to take pride in building for population scale solutions as well. So what I think is important is that this technology I think is fundamental to engaging customers to engaging farmers, patients, citizens, partners at population scale in manners, form factors and surface areas that India really speaks about that India thinks about that India regulates in form factors that India scales and in manners that India actually pays as well. With that, I'd like to take Thank you. >> Thank you. >> So, let me put it in perspective of how I see it, right? Uh people talk about India being um uh low RPO country, India not having demand for AI etc. We started off as a frontier model building company. That is today marks a important inflection point for that we have shown that we can build the state-of-the-art models but meanwhile we also took upon ourselves to build a product that can truly scale and I think that product that will scale to a billion people in India is Sambad voice infrastructure that you can scale today to any language uh across the country. The team showed a chart which had 1 million there. That is the 1 million minutes of calls every day on the platform. Right? So it's 1 million minutes of calls every day. In fact, since the chart was built, I think two weeks back, we are at 2 million today. Right? 2 million minutes of calls every day. If I were to think about providing a tutor to every child, providing health care access to every person, providing advice in agriculture, advice in uh let's say legal matters, anything that you can imagine, I think voice will be the medium we will deploy it and I can imagine the s the samad team which is cranking up and up may reach 100 million minutes a day by the end of the year. That is the real potential of population scale AI and this is all happening with our models running on GPUs that we control. So the entire infrastructure remains both secure and low latency. I I I'm genuinely enthused by where we can reach with uh somewhat just like we had conversations uh it is which is external facing which needs to be low latency which needs to be small efficient the dual to that is productivity. You want to be able to run inside your organization large models to be able to do complex things but do them reliably, do them repeatedly and do them efficiently. For that we have an entire vertical that we have created at Serbam. Out of experience of stuff that we did with the armed forces, experience of the stuff that we did with NITIO, we have now created a vertical on Serum for work for which I would like to invite Vedant and Harshett to talk to you about. Hello everyone. >> As we know AI is now moving from chat to real work. It is touching your internal systems, moving money, talking to your customers and representing your brand. But even so, enterprises after investing lots of money in pilots are not able to see needle moving impact of AI in production. Let me take an example to explain this better. Take any fintech or consumer internet company, right? They run multiple campaigns to acquire customers, retain customers. This is their day and day in dayout job, right? For this task, they come up with new campaigns every day. Uh this requires collaboration between four different teams. Uh interacting with seven different internal tools. This process roughly takes two weeks and still is very very errorprone. Right? Naturally, given the high value and high frequency nature of this problem, a fintech or a consumer internet company would want to use AI to solve this better. The first demo is built very quickly. It takes a week. Um, it is 80% there. But when you connect it to real data, you start finding that it starts hallucinating, right? You start finding it on day three when the wrong email has gone out to customers. Then what does the developer do? He changes the prompt, hopes that it will get fixed. But something else breaks in production. What does the developer do next? Maybe changes the bet, maybe changes the model, puts a bigger model after this. Maybe adds a retry loop. And what he sees is the same user is getting multiple emails or worse multiple rewards. Why is this happening? Models are not the problem. models are already better than most developers out there winning gold medals in maths Olympiads. It is the system around the model. There is no way today to control how AI is behaving in production. Let us doubleclick on that. Right? AI is fundamentally probabilistic. When you ask the same question twice, it can do something else. It may stop midway without any uh without without any reason, right? And the only lever this developer has to make AI work in production is prompting and praying, right? This AI which is super probabilistic has to work with your enterprise setting which is very rigid and very brittle. Your enterprise setting is full of workflows and processes which can't change data which is in different silos, schemas that don't talk to each other. And unless there is a marriage between this probabilistic AI and your enterprise setting, you will not be able to see value in production. This is the reason why most demos today are narrow constrained toy demos and nothing real value of production is being shipped right to fundamentally make it work developers have to write a lot of plumbing to make this marriage of probabilistic AI and this messy rigid enterprise context they had to write a lot of plumbing they had to figure out how to control this AI how to log its actions and This is plumbing that every developer across every team in the world is writing. This was the same problem in 1970s before the operating systems existed. Later operating systems like Linux, Windows, they abstracted out this problems so that developers can just focus on building and solving business problems. We think that moment of AI is here. Now we need this operating system of AI to make it work reliably in production and for that I would like to invite Harshed who has built this system designed the system from ground up uh to talk more about how we have designed it. Uh thanks Vant. So if AI is going to move from experimentation to infrastructure it needs to run with the same uh reliability and auditability guarantees as other mission critical systems. So we built Arya around. So we have a strong opinion of what those guarantees should be and they are that it should be composable, it should be declarative and it should be controllable. To illustrate these points we are showing an illustration of some work we did with a large logistics company where we ingested a very hairy corpus of multimodal data and then told the mod told the system to go and explore the data and come up with some novel insights and structure and that was it. Everything else that you see it is executing on its own. So um what you see is the system decomposing the prompt into several modality specific workflows drilling down when necessary and aggregating these results to form a coherent answer. And the answer that comes is not prescripted in any particular way. It is an emergent property of how the system is designed. So to get to these we have three basic ideas. Uh first idea is that the system should be composable. So what it means is that every pro every uh u component over here is built from a small finite set of primitives and complex behavior comes from how they are combined. So the analogy is to let's say a automobile manufacturer where uh the factory doesn't rebuild the assembly line for every product. uh it uses fixed parts and fixed stations and the separation of concern brings the Unix philosophy back into the agentic world and where allows scale to emerge from composition rather than through complexity. The second major idea is declarative. So you specify the objectives and the constraints and the system figures out how to actually execute them. And this is similar to hiring a good engineer where you give the task and the boundaries and let the engineer execute. Uh in our case, Arya abstracts out all of the machinery underneath for persistence, telemetry, replay, checkpointing, failure handling etc. uh all of the hard problems in distributed systems and let you lets you focus on intent rather than on the machinery. Yeah. So third idea is controllability where enterprise systems cannot rely on uh improvisation. There has to be some notion of what can happen and under what conditions. So area executes inside a graph where we provide uh checkpoints and roll back behavior when uh systems uh checkpoints and roll back behavior. So what results is not a demo that runs once or runs stocastically. It's a infrastructure that scales across use cases. Okay. Um slightly different I suppose you heard a lot of lot of text. Let me let me frame this uh how I see it, right? The models are getting better and better. But you might have here heard the MIT report that 90% of AI things fail. And I think what is missing is a systems engineering view of how models are embedded in what else there is. Right? And Harshad is our systems engineer who has been thinking deeply about it and looking at building agents which as he said can be declaratively written, can be composed with very few primitives, can have concurrency guarantees, uh can have uh guarantees on the schema of the data that agents write to each other. and thereby we are able to build agents that are far more reliable. An important distinction is the building of the agent and the execution of the agent. Our view is we should use frontier models to build agents and then once they are built proven to be accurate as per our requirements run them with much smaller models. We've been able to show you can take standard tasks and make 10 times more efficient while actually increasing the accuracy. uh this is an early product but this is something that we are very excited to to bring to enterprises. In fact even Arya the way it has been designed with systems principles we would like to open source and then let people contribute on how an infrastructure can be built for reliable uh orchestration of models. So that is serum for work. I would now like to uh move on to uh the next topic which is serum for content. Just to put you in context, we had serum for conversations which is for having empathetic conversations with your customers. Serum for work internally and servum for content for which I'd like to call Arjat and Krishna back onto the stage. Some please applause for the folks coming in. So um knowledge and content in general has gone through a tremendous evolution over the last century. What started off with the invention of the printing press then onto the radio then television and now the internet has quickly evolved content into various formats such as audios, videos and texts. Now imagine a world where I a native Tamil speaker can read a poem by Rabindraat Tagore in my language and similarly think of a complex mathematical uh formula and an explanation and a proof written by Rammanujan in Hindi. How would we do that today? Today there is no easy means to achieve that outcome. With servum for content we make all of that possible. Firstly we focus on document digitization where with high accuracy we digitize all the content in the native language. Then we move on to document translation which retains the linguistic complexities of the original natively written document. And then also we focus on AI for dubbing. Now on the document digitization side, we have built a platform as part of this uh stream which achieves sot accuracy using server vision, our in-house OCR model. A culture is preserved only when people can read, debate and build upon its ideas. When literature circulates, when it inspires new writing, new thinking, and new creativity. The result was about 90% accuracy. That may sound good until you realize it means nearly one error per line. My name is Raj Mashuala and I'm a co-founder of an NGO called the Ekatra Foundation. Ekatra partnered with several large technology companies to build indic systems. Very quickly though we ran into hard realities. That is when we partnered with Saur. The technical solution is a pipeline of specialized models. First, the system understands the structure. Then it recognizes the text within each block in context. It also provides a workbench where proof readers can give highlevel agentic instructions. Instead of correcting every single character, we have moved from one error per line to one error every 10 pages for mainstream books. But the progress will never stop. We have reached a level of accuracy in both character recognition and layout detection that makes large scale processing practical and affordable. With Serum's OCR AI, we are no longer just preserving literature. We are returning it to the people readable, searchable and alive. >> And for the document translation and dubbing uh Arijit take over please. >> Thanks Krishna. So we saw how document AI is uh let's see like when it comes to translation the traditional translation is slow it's painful it goes to translators who edits line by line come back in weeks or months and it's the overall process is pretty tedious let's see how we are solving that with soam document translation So not just translation of the content but the contextual nuances, the terminologies, the layouts all of it is preserved on the studio. video with option for publishers, editors to go over the content, proofread it, uh give it their own, you know, writing style and make these documents published ready within days, not months. Right? So we spoke about document. Let's talk about the form of content that is mostly consumed. Right? Uh Indians consumes over millions of hours of videos every year. But the gap is that most of these content are in one language, right? So with server, let's Okay. Yeah. Okay. Yeah. Let's see how sum transforms the video content into multiple languages with the dubbing platform. Hey, hey, hey. So with sum for content we are transforming and reaching millions of Indians in their own language. So every piece of content in in every Indian's language within hours not weeks. Thank you. Okay, cool. So we showed you a variety of applications for conversations, for work and for content and uh all of these are built on the models that we have showed you but we are excited to be building this layer and interacting more with developers and companies across the board. The final thing that is required to make the sovereign AI stack come together is infrastructure uh which is being able to train these models being able to serve these models efficiently and there we have been focusing on variety of things and I would we would quickly run you through what some of the things that we are doing one of them is to focus on edge models and I would now like to invite Tashar to talk about it we can keep a little brief given that we're running out of time. Hi folks, let's talk about something that's literally cutting edge. When it comes to scaling When it comes to scaling AI in India, there are three key challenges. Training and serving models is is costly because cloud is expensive. You need access to 24/7 internet which is difficult if you're in a remote part of the country. And your data is leaving the user's personal sovereign boundary which makes it risky if you're dealing with sensitive data. Edge is our attempt at solving some of these challenges. At Serbum, we believe in frugal innovation which led us to develop models which are small. So they are they occupy MBs of space rather than GBs. Models that are efficient. So they can easily run on your CPU or NPU which is part of almost every smartphone today. And because these models are small and so efficient, you can run these models completely offline and your personal data never leaves the phone. All of this without compromising on model accuracy. Now why is this important? We want through AGI through AJI we want to bring intelligence to every phone, every laptop, every car and even new types of devices in the country. We believe that with edge we can make existing devices smarter and reimagine how humans interact with technology so that you can have new types of devices which have never been conceptualized before. Now let's see a demo in action. Imagine you're in a remote part of the country. You don't have internet and you don't speak the local language, but you want to hail a cab. Serum Edge can come to your rescue. So these are models completely running on device allowing you to seamlessly interact with someone who doesn't speak your language. Now, we we realize that we cannot do all of this on our own. So, to bring AI to you, we are proud we are fortunate to partner with three leading companies who've enabled us to bring AI to your hands. First, I'm proud to announce a partnership with Qualcomm where we've optimized our edge models on Qualcomm chipsets, allowing us to be in almost every device around you. Let's see how this works. Namaste. Very excited to be here and represent Qualcomm. Edge AI matters to India because AI must work at population scale. Cloud alone cannot serve all the needs in India. Hence running AI on the device enables a set of use cases especially for India in our own Indian languages and dialects. Qualcomm and serum have a very simple objective to bring edge AI to every Indian without barriers. We >> so all of us have tried AI on smartphones and laptops right but we want to go beyond that. This brings me to my second announcement. We are very proud to partner with Bosch to bring AI to vehicles all across the globe. Let's see what Mr. Moven from Bosch has to say. Last maintenance appointment center appointment. Hello, welcome and namaste. I'm happy to announce our partnership for innovations with serum.ai who bring sovereign. So far we've discussed about bringing AI to existing devices. We thought why not try to imagine a new device powered by AI. In India about 10% of the population still uses feature phones and hence they cannot access generative AI. We decided to partner with Nokia HMD to bring India's first AI powered feature phone so that we can get AI to the last mile India. Let's see what Mr. Ravi from Nokia HMD has to say. Namaste. With just one button and one voice, people can now access information, services, local markets, government schemes, and support in their own language. Our partnership with Serb is about putting useful intelligence into everyday life. We plan to bring these experiences across portfolio of our Nokia feature phones and HMD phones reaching millions of users across India. >> Thank you so much. >> Cool. So, uh there's a lot of research and development that goes into this. The models need to be made smaller at the same time they need to retain the fidelity. There's a lot of work that goes into optimizing it for a particular form factor. Again, it's a hard problem but a problem that needs to be solved to scale AI in India. Um I would now show you something little cooler because it's it's actually here. I would like to invite Pavan to come on stage please. Yeah. Yes. over to you. Thank you Pratush. Hi everyone and thank you very much for joining us on this special day. You've seen so all our wonderful speakers talking. I wish you had the special device with you because it would have broken down all the technical challenges that the company is uh been trying to crack on in a very simple bashame. That's because the products that we've committed ourselves to build are fully developed, designed, thought of, developed for a billion of us. I want to leave you with two key challenges that we decided to take upon. The first one was to make sure that we stand for trust. Our honorable technology minister made this statement saying that all five stack of AI are fully developed here in India and we stay true to that commitment. It's sovereign at every layer. The products that we are talking about will be designed and will be soon in production in factories near you and with use cases for a billion voices. And you know what is very interesting is as I was listening to all the speakers and Pratosh I wanted to make this appeal. Please talk to us. Talk to us in Marathi, Gujarati, Asamese because now we can tell us what you want. Tell us the kind of products you want. While today we will let you know of two very interesting products that we bring for you. I think soon enough we'll play a small AV but the fact that with serv we can you can talk to us with your emotion in your language and it will all come to us and it will help us to create bigger journeys more emotional journeys for you. These products are designed for everyone from every part of the world. thinking about security, thinking about our defense forces, thinking about our farmers, but also thinking about all of us because we in India we don't necessarily work out of our offices are, you know, in fancy glasses and air condition. We are always on the move and these are the smaller nuances that we picked up to design our product. In fact, what you see, what I'm doing right now is I'm capturing those emotions with all of you right now with the product that I'm wearing. So, these are no more concepts. These are products that we have. I'm wearing one. I have this ring which is a healthcare ring and it's also controlling all my devices, controlling my phone. It's controlling my eyeear that I'm wearing. And it's captured this whole moment. And maybe I can show you as we go along. So this entire conversation has been captured. It's now processing. It will analyze and it will create a beautiful summary in the language in which it has been spoken. And you can then ask these summaries to be documented. Now think of these as we go to work as we go for our sales journeys how all this information is captured and help us to create deeper analytics. That's the story for today. Let me ask someone to play the AV for you so you get a better experience of these products. >> I think it's Yeah, I think it's good to show the device itself. >> This is Kaz. >> Mike, please. >> Yeah, >> this is Saram Kaz. Maybe you can take a closeup of the device itself. Uh how it looks. Um, and yeah, I can take the mic. >> Yeah. So now you can see that our conversation is nicely summarized. It's in an audio file and it's been it's been processed. >> Great. No, I would like to uh say a little bit more about this particular point, right? So, uh I think I think Pavan showed the stack. We need sovereignty at all layers and the device is a layer which is where the experience of these models comes true. We're delighted to be working together and building the first smart glass designed and manufactured in India and coming with models built in India. Um and and unlike unlike maybe the glasses that have been around for a couple of years which can you know you can you can talk to them you can call a particular company's AI this is actually a builder's device you can build with the serum platform different agents and then deploy it here what showed you now is what you can do when a salesman goes and talks to another person you can record the conversation summarize it get insights but a variety of things could be done imagine Imagine law and order. Imagine feet on the ground. Uh imagine gig workers. Imagine people on the move using this. We are delighted to bring this to you this May. All built in India. >> Thank you. >> Thank you. All right. U so I I think we we would like to a little bit speed up because we want to show you a little bit more. Uh there is an aspect of being able to serve the infrastructure uh the models that we need to run all the stuff with and there is extremely complex software that goes on top of hardware of accelerated compute to make that happen and we have been working deeply uh at how do you create that software layer so that capacity requirements can be met. We have worked with Nvidia very closely to build a system called PRAA by which we are able to create a token factory. Really AI requires factories and these tokens need to be manufactured with the precision the efficiency that with factories work with. We built technology whereby you can have GPUs in multiple data centers and they can all be aggregated to serve models. We believe this is the single most important problem to solve to actually make AI like UPI. AI that is available to everybody at a fraction of a cost and we are delighted to be working with Nvidia and taking this forward and having India's first atscale uh token factory with a variety of our models and open models available to all. Right. Um I will just skip through some of the aspects of this and then quickly move into uh a couple of places where we are creating impact. So we have showed you the models we have built, the applications we have built, but another important place is where are we creating impact and there are three broad areas we are creating impact. The first one is for developers. I would like to invite Sahed to please come over. We'll be super brief because we're running out of time. Just the essential parts and also money from the other side. Yeah. >> Hello. Hello. Good afternoon. Incredible show of models today, right? Bullbull SARS vision dub it's just very very hard to pick a favorite one but my favorite has been taking the dub video going to our dashboard making a video of dubbing of me in Telugu getting it to Punjabi showing it to her mom and seeing a spark in her eyes and today we want to talk a little bit about the spark the ideas possibilities and inspiration and how we can extend that spark to millions of developers in India India is home to 15 million plus developers we the fastest growing community of developers in the world This isn't just scale, it's momentum building is happening in India and a lot more of it is AI native and at server builders and developers have been at the heart of everything that we do. Open hati server one serverm all have been open sourced and a lot of developers have tried fine-tuning it building applications on top of it etc. We have also launched our API platform that has scaled to hundreds and thousands of developers and many people have built some very cool applications. Today we want to talk a little bit about our belief belief of developers, what developers are building, the impact that we're creating and what next. To me, what's been the most interesting point about the model APIs is that just within a few weeks of launching, we had thousands of developers already trying it from all over the country. And even a more remarkable was the fact that we had a very good distribution of individual developers, startups, and enterprises come up. The other thing to also highlight which the trend will show you is that our growth for the model APIs has been very consistent and very rapid. >> Given this this sort of signals to us that within India within the developer ecosystem in India there is a certain hunger there is a hunger to build to innovate and to deploy and as serum it is our responsibility to give them the tools to do this. with SARS v3 with bulbull v3 with server vision we have done this to a good extent wherein our usage has gone up by approximately 10 times furthermore moving on from the numbers right the idea becomes that what are people actually building right we have a very budding ecosystem wherein we have folks such as Ashraf or Jay Gala who have created some very cool applications wherein let's take English language learning right folks may need confidence in terms of learning English to let's say apply for a job give a particular exam or on on the other hand you may need health care assistance to understand or diagnose particular symptoms where doctors are less accessible less affordable and so on. Again the ecosystem is very broad. These are specific examples of instances where um there has been cool applications developed but over the past year we have had a lot of love and support from the community which extends to multiple developers to the extent that we have over three lakh developers using the model APIs as of today. Again beyond the developers, we also have a lot of enterprise software engineers, developers building for their larger organizations and larger use cases. Without speaking too much about it, I will let um Okay. Um yeah, there should be a video playing at this point. At Eternal, the home to brands like Zomato, Blinket, District, and Nugget, we aren't just building for the urban elite. we are building for the entire nation and that's why Serom's focus on Indic languages has been such a gamecher for us. We have been piloting with their new ASR and TTS models and the results have been quite encouraging. We are seeing voice interactions that feel natural and sound accurate even in the long tail of regional languages. I'm looking forward to seeing where this partnership takes. India first sovereign large language model. It was much needed. Wishing you all the best in this journey. We will explore synergies and partnership ahead with you. Thank you so much. At Policy Bazar, we have been using AI for the last 3 4 years. We have been building a lot of in-house capability because we see the impact that voice can have on the Indian consumer and in buying insurance. Insurance is a complex product and I think consumers will find it easier to understand on using voice rather than in any other way of search. We look forward to the work that Serum has been doing. Hey, I want to talk a little bit about the belief that we have for developers. Keep it very quick. One, we want to meet developers where you already are. So, if you're building applications in India, we are available on APIs, SDKs for JavaScript and Python. We also have integrations with live kit and pipcat if you're building wise applications. Second, the control stays in your hand. We provide a lot of parameters, steerability for the models that we have. Each use case is different and we want to put control in the hands of developers, parameters, everything that's available. Third, um yeah, we want to make it super easy for you to get started. So with a free private general program you're able to get about 33 hours of ASAR, 7 hours of TTS playgrounds and everything available and MCP support for you to build very very fast. And last yeah I think we're very enterprise grade in the way that we deploy things. So all of your data never gets used in training very high uptime reliability and scalability. Okay now I just want to touch on a little bit more about extending the belief in developers beyond the APIs and models and and how we want to founders early. We are founders at heart. We are we are backers developers and we want to make sure that we are providing the right platform for people to have a head start. And so when we were discussing I think Petush and V have come up with the idea of how we can enable a startup program that can enable developers to get get started very very fast. And so I came in I I went to Petush and I said hey Brush how about we announce one lakh in startup credits for developers. Pretish looked at me and said to I said five lakhs. He said maybe to 10 lakhs. Then I went to Vic and Vick said maybe we can do a little bit more. I said do you have 50 lakhs in mind? No. So he said a little bit more. I said do you have 1 cr in mind? And I was about to enter 1 cr on the slide. Both of them looked at me and said money I think we should do a little bit higher. So today we're very happy to announce about 10 crores in credits for startups to be building on our platform. So this is specifically applicable for startups and early builders who are building for India and on impact use cases. Select startups can apply at serum.ai/startup credits. Every startup is eligible to get up to three to 10 lakhs in credits, higher rate limits in compute and support from engineering team. You'll hear more about this soon. >> And folks, that's not all. Given all the love and support that we have got for Bullbull V3 and Serum Vision, we have made sure that for the rest of this month, both those models are going to be available at absolutely no cost. So, please feel free to try them, build cool applications with them, and scale them up. Furthermore, for the rest of this month, for every credit that you purchase, we will back it up with an additional credit. So, you will receive twice the value on any purchases that you make. So, folks, this is the time to build. This is the time to innovate, use the server APIs, and with the incoming sovereign models, the opportunities are endless. Thank you so much. Over to Pratish. >> Cool. Looking forward to what India will build with all the different uh tools. In fact, it is very gratifying to see people come back. I was today in an interview in a TV program and uh the person who was a media person there said actually I've used your models for doing something right. So I think the diffusion of uh the technology once it is easy to consume becomes very interesting. We would now like to talk about enterprise and to do that id like to call upon claps please. >> Thank you everyone. You've heard from our wonderful models and products team so far. We do an equally rigorous job when it comes to taking this technology into the hands of our customers and partners and that's where I come in. Um I would love to talk about how deeply we are engaged with our customers, our partners, several of whom are in the room today and we are very grateful to them for joining us. I will talk a little bit more about the servant enterprise playbook and how we approach these engagements to make ourselves from builders of AI to going and reaching out to the consumers of AI and ensuring that AI reaches the entire population of India. So let me start with one of our early engagements and u again this takes me back to almost a year ago uh when we got a phone call saying that we want to do policy renewals for 5 cr people in just 10 days we had never hit that kind of scale before. Uh but this is not the kind of customer you say or no to or an opportunity you say or no to. So again the stellar team here we worked midnights we burned weekends uh but we delivered and it's experiences like these and opportunities like these that customers have given us which have allowed us to hit this milestone today. So again very very grateful to all the support from the ecosystem. We often hear metrics like 95% of all pilots fail. Enterprises are stuck in a pilot purgatory, right? But we don't believe in that at Suram. We've learned from our experiences to now perfect what we call the Surum Enterprise playbook. You have already experienced our product stack. Building on top of this stack allows us to undertake very complex applications for enterprises. You've seen voice applications and mass in the market today. But the world of AI doesn't end there. It barely starts. And that's where we have already stepped into right across an organization starting from sales to onboarding to back office operations compliance across diverse industries. We've taken some of the most complicated use cases possible and using a stacks of server for conversations, serum for work and server for content allows us to take any use case an organization has and automate that with AI. We truly are the providers of end-to-end AI transformation and again very grateful to our customers for giving us that kind of platform to deliver results at this scale. The second secret source of the way serum works is in how deeply we engage with our customers um where our forward deploy team comes into the picture. A forward deploy team is a new concept within engineering which has recently come about in the age of AI. Think of them as hybrids of business consult consultants and technical implementation partners. What a forward deploy team does cannot be summarized in words. Right? To take a pilot into production, tech can only take you to the first 90%. The final 10% is what makes that difference between a pilot to production. And that is where people come in. You need all kinds of things to be aligned. You need things to be tested. You need things to be scaled. And that's where this forward deployed team plays a very major role. Think of them as your tech and business consultants all rolled into one team. We work at very high speeds. Of course uh nights and weekends included but that said uh we are able to undertake very complex projects not in months not in weeks but in a matter of days and we don't work as vendors to our customers we work as thought partners and again we are grateful for the kind of stage that our partners have provided us these are some of the pictures of our forward deploy team in action um I think all projects start like the first three and end like the fourth picture Um I'm also very proud to say that nine out of every 10 pilots we undertake move into production at scale really driving business ROI. We work deeply across the enterprise segment in India, very deeply embedded in the banking and financial services space. Also working with a lot of tech and digital natives, a lot of whom would be here in the room today and again would be very happy to engage with anybody who wants to work with serv. The last thing we are very benchmarked about is having measurable outcomes. We often don't take up use cases where we feel it will not really result in an ROI for the customer. Here are some of the examples of the benefits we've driven. We worked with a gig work platform to drive activations for their delivery partners via voice AI and it drove an almost 2x revenue in their peak season and these are all real use cases. We worked with a top 10 NBFC in India to reduce their customer acquisition cost by 50% by using a combination of WhatsApp and voice together. We are working with a 5% higher customer engagement as compared to a human contact center by using an orchestration of the AR platform that you saw earlier today and deploying this at a leading bank in India to drive better results than a human contact center. We are again very grateful to be trusted by some of India's leading enterprises. I would request the team to play out a short video. Our partnership with Serum has enabled us to scale personalized product specific and segment focused conversations across the customer journey. By embedding multilingual capabilities across our consumer loan products, we are expanding our reach with greater relevance. Serb has been thought partners to Tata Capital in its AI transformation journey. I believe that the future of financial services will be shaped by voiceled customer engagement, AI based intelligence and deep personalization. At FBI, we are using technology to drive towards our brand locally. We are using AI now for uh customer engagement for more than 8 crown customer and now in the process of embedding AI in our distribution enablement processes which will be used by more than three and a half time distributors. The intention of all these AI processes is to drive meaningful business impact do projects at national scale in native language multiple Indian languages. We are very happy to have serum AI as our partner in the journey. >> Context is very important to AI and enterprises and the Indian context is hence very important you know when we have Indian customers and you know when we are in India and finding you know gems like server uh has is is quite important to this whole storyline of India enterprises and AI right. Thank you again to all our partners for giving us the playground to experiment and learn. Thank you. >> All right, the uh enterprise is covered and the final thing that we want to talk about is governments. Uh we are very interested in governments also adopting AI at scale and like to invite Alle Sharon to come and present that part. You need a mic from there. >> I can help you with this. >> Thank you Prat. So server as a startup is unique in many ways. One of the differences between Saram and many startups is that we've chosen to work deeply with the government. The founders spoke about scale earlier and we believe that in a country like India to scale and to truly impact citizens, we need to partner with the government. Just going back to the basics, what are the principles enshrined in our constitution? Sovereignty, democracy, equality. These are the pillars of a welfare state. But sovereignty uh but sovereignty uh is incomplete without security both physical as well as economic uh can we go back to the previous slide? Yeah. Um and then equality equality needs state capacity. So we need to empower our government uh folks in the government to be able to impact at scale. And finally democracy is a conversation. Democracy is a conversation that we have amongst ourselves to be able to achieve outcomes and we've talked about how AI can achieve these things. So I'll go quickly through some case studies across all these three pillars. The first one in the prior slide we are really proud to work with work for the security of the country. We can't talk much about that. But the main feature of this platform that we have built and and the products we have built that we bring together and our models is that we're able to collate a lot of inputs. We are able to understand through humans through folks like the defense forces who are seated here who can actually understand how to plan and then finally take actions which improve this loop and make it much faster so that we can take more agile actions toward towards our security. So moving on another topic that we another uh topic that we have embarked on is the transformation of states. We recently announced two large MUS with both Tamil Nadu as well as Odisha. And again this is about economic and data sovereignty. How do we have AI native compute within a state powering its applications with data residing there as well as the capacity to bring in best of breed research um as well as uh you know keep all the all the data inside and and build applications that impact citizens in that state. Now I'll play a short video uh of the announcement with the government of Tamil Nadu. I don't know if you've heard of survi. uh that that story that's a big big story coming out of Tamil Nad and uh that's going to be a huge growth story for India and its indigenous capabilities in several other sectors like in healthcare like in education um data sovereignty it's going to be huge so this is not just for Tamilad this is for India and the world >> so we are in the process of creating that ecosystem which will be the base for our startups in other things to experiment and work on and develop. So if you see one week before we already had that investment which is with SA was with the government of Odisha. We have a similar partnership with called SAM with the government of Tamil Nadu. Uh we can play that video as well. >> That was Tamil Nadu. That was Tamil. Now we are going to play the Odisa one. Orisa just played. >> Today we also witnessed the signing of some very strategicus including one with Sarbam AI. The full stack so AI park would be a purpose-built innovation district that brings together compute, talent, research, startups, global enterprises and government use cases within a single integrated physical campus with deployment of population scale and voice enabled AI applications across priority sectors. This will enable citizens particularly in rural tribal areas to access information on entitlement benefit and girians to dress through simple conversational interfaces. Thank you gentlemen. >> Thank you. So now I'll move on to very quick um use cases around how we power conversations with citizens and I'll be very quick. So one of them we have been able to and are currently in the process of calling 8 crore farmers across nine states to be able to understand their crop uh crop survey what they plant, what their landolding pattern is so that they their livelihoods are protected because their subsidies depend on this. And we were able to figure out some systematic error patterns that now can enable policy makers to target their interventions so that it is solved. Another uh another project we recently did with the National Health Authority is that we called senior citizens and we uh we we sensitized them about a government scheme that gives them health security and we were able to increase by 40% enrollment rates within a span of 10 days um and were able to uh show that across various languages. So again the basic principle here is the G2C interface. How do we make that seamless and how do we get citizens to interact with the state and the states and the state to interact with citizens seamlessly? Similarly with Aadhaar we have an air gap deployment completely on prem because of the security and the and the and the sensitivity of of that database and we're able to call citizens from there and ask them about their experience um of getting an Aadhaar card. So that is another project we have done. Moving on, we've also worked in local govern governance. Uh we believe that at that layer there is real interaction between government and citizens at a very very minute level. We were able to these are some we were able to work with various municipalities. One of the use cases was being able to being able to talk to them and understand whether they have paid property tax or not and deal with that humanely. Now understanding whether someone uh whether there is a unique need or whether the whether the state can actually provide a loan etc can be done at scale rather than citizens approaching and then and and then uh somebody approaching them that you have not paid your tax. So we able to do that and uh recover you know 20x of what the what was the cost that the state put in in terms of revenue which will be then used for other purposes as well. Recently Pratush talked about uh you know how we helped uh helped dub the economic survey in various languages. We also assisted NITI in building a platform that was able to do deep research on curated government data and this included structured data but also a lot of unstructured data which we in government do not always have access to. So things like PIB reports, things like ministers star questions, answers in parliament. This is government data but the government itself cannot gather it in one place. So we were able to do that and with the platform that my colleagues uh Vinat showed uh do deep research and call out insights and we were Nitia was acknowledged for this in the survey. Um I'll skip that. Now again the way we approach the public sector is that we first understand your problem statement. So before various people who are seated here some of whom we have worked with we bring in your domain knowledge and our EI expertise to refine that because the most important thing is in this changing technology what is to be done is is discovered between um us and the folks we work with rather than given by either party at once. The next thing uh this is something that uh you know my colleague showed but the important thing here is how do we quickly understand your data to do anything in your organization to roll out a program to roll out a voice use case to roll out uh something that is able to surface insights on data we need to understand it. So we have built very strong automated pipelines which can do it in a matter of hours and you and you saw an example of that over there. And then finally, as my colleague Shruthy also covered in in government, we believe in uh deploying business and technical teams in your premises, working with you shoulder-to-shoulder to actually deploy things at scale. Uh I have not covered a lot of the use cases, but we're working extensively with all of the organizations here, and we want to continue to partner with the government to be able to reach and and transform India at scale. Thank you. Right. As you can see, we are doing many things that it with the time that we have is not sufficient. Uh the last thing that we'll just talk about is the social impact that we are having. We talked about developers, talked about uh enterprise, government. Uh social impact is also very important. I'll just go directly play a video. Can you play the video please? STEP AI for Bharat and Survivom came together to build a shared AI diffusion infrastructure that brings together technology, data, policy partners, and social expertise. Through an open call, 20 high impact voice AI use cases were selected from over 100 applications, each receiving five luck free voice AI minutes built on the Sullivan platform. This diffusion model aligns technology, data, expertise and solutions so that the right voice reaches the right person at the right time in the right language and dialect. In 30 days, 20 organizations have used over 2 million voice minutes across health, governance, agriculture, and education benefiting more than 1 cr people. Given the artificial intelligence boom in the world and the capability of India in the frontier technology, we wanted to use AI to solve the real problem on the ground and therefore we designed something called Sachiv G. It is solving the real problem of the serpent. forch. Listen at scale proves that impact doesn't spread through isolated pilots, but through diffusion networks that remove cost, lean on share infrastructure, and let communities ities learn together. This is just the beginning. So with that, I'd like to thank you. We talked about models being built in India. We talked about applications that we are building and finally the impact that we are creating. It is only right that this event is has a title of Sarvaja Hitaya Sarvajana Sukaya. It really is about human flourishing at the end of it which is a core principle that drives all the work that we do. Thank you. Thank you all for coming and thank you all for your appreciation. We look forward to a long journey ahead. Thank you. >> Thank you team Servam. With this we move to the next important keynote address on service economy to innovation economy. India's AI moment. I would like to invite on stage Mr. CP Gani, Chief Executive Officer Ionos to deliver the keynote address. Guest, I'll request you to please settle down for the following address. Please give a huge round of applause for our speaker, Mr. CP Gani. >> You know, as I was just walking up, I did realize that what was common between Saram And where I stand today as a co-founder of Ionos is actually Rajan Anandan. Rajan Anandan is an investor in uh Saram and uh my own journey. It was just coincidental that many of you would remember Rajan having this interesting conversation with Sam Alman in June of 2023. The conversation was very nice because it was talking about the AI ecosystem, the role of startups in building the AI ecosystem and in a way the technology that has been developed in US can it be done frugally in India? Now as you all know Rajan on one end is a very astute investor on the other end he's also a thought leader. So when he was having this interesting Q&A with Sam Alman somewhere the word 10 million and that India or anyone else cannot be so frugal that you could develop an LLM at 10 million. Fast forward in life, I mean you have seen project industra uh 37 languages being supported and it is also that I was one of those stupid ones. you know the guys who sit in the class and say yes and I did raise my hands when Rajan and Sam Alman had this debate and I was standing up and listening to the server presentation and I was genuinely saying that all of us should actually go to this class of Rajan Anandan or Sarban. The reason being very simple, the simple part is at $300 billion of exports of services industry, the stock market doing the yo-yo on every time a new tool is launched and more importantly is that it is not about the stock market yo-yo. It is about a feeling that the services sector which fueled Indian economy. Services sector which created not only jobs but also created India's provinces with the fortune,000 world over. Now is that journey coming to an end or is that journey only the beginning? My personal feeling is that the servant story amplified or in a way that was a story that I answered to myself. The story that I answered to myself is when I hung my boots in 23 December. The story was what next? And what next was the birth of Ionos. The birth of Ionos really was that we are now looking at the next generation services company. We are now looking at using AI as a tool. We are now looking at taking advantage of the tools that are available to us and learning how to take 275 billion or a 300 billion IT industry to 750 billion industry by 2035. And clearly the answer lied in innovation. The answer lied in understanding what the customer wants. So when you design a B2B business, what do you design? You design because you are now learning to work in understanding the needs of that customer. It is you know no longer about you know number of people number of billable hours number of people hired it is all about outcome it is all about impact and that's where I think when Ionos was born it was based on building platforms it was not about adding number of people it was not about billable hours and when you do platforms S what do you learn from platforms? For example, most of us have used a Zumato or a Swiggy. Now, is Zumato or a Swiggy a logistics company? Is Zumato or a Swiggy a food company or is have they reinvented a business? Yes, they did. It is the same business that when you want to a Pizza Hut, they were promising you 20 minute delivery. I mean that business when you started amplifying it and you started using technology, what did you develop? you developed a platform and that platform whether you went to the 80th city or the 800th city the platform could multiply itself and I think that's really what we are doing at Ionos building platforms understanding the needs not only of my customer but the customer's customer so data wise All I can tell you is that this industry will grow. this industry powered by AI and I'm glad that we are all sitting here today and we are talking about AI impact because whether you apply it to a urban clap or you apply it to that what 21-year-old Stanford failure or and Stanford dropout did with Zeppto. What did he do? He applied the kirana store principle of de distribute or a egg or your oatmeal or whatever because that shopkeeper knew what the neighborhood wanted. Suddenly the language has become now dark stores. Suddenly the language has become all about logistics. The language is about you know how we understand the data. Now if you start applying it because your customer's customer wanted a convenience of the next door store and you were using technology normal company go back into your own companies try getting a gate pass for your laptop I mean it'll take you 20 minutes because if there are four people who want to either sign or check or define how to do it. So my own submission is the aha moments for Ionos were all about understanding the day you start understanding your customers customer your usage of AI your build of platforms will my friend has come this time it is a four-legged one so so anyway understanding customers customer. Actually, I have a story on customers customer. I know I'm running out of time and since Professor Junjinwala is here, I must tell the story. The story is my 2-year-old grandchild who uses AI because he talks to Alexa. He uses iPad in his own way. And uh I was traveling and I asked him, "What do I get for you?" He has been hounding me to get a puppy. I said, you know, I might as well try and find out, you know, a furry four-legged robotic dog. Furry robotic four-legged. And for that 2-year-old, the my customer customer, which is my 2-year-old son, can will only want to throw a ball so that this four-legged robo can come and collect it. And trust me, I found all kinds of dogs on the but there was nothing which looked like that means there was no hyperpersonalization. There was no design element which took into account the 2-year-old's requirement. We have dogs who sing and dance. We have dogs who do whatever, but they still look like a robo. They don't look like that four-legged stool. So the point again and again is we all know our customers demands are changing. We all know that we have the data. We all know that there is a research available. So go back into the basics of any innovation or any B2B company. The basics are understand what the requirement is or redefine what the requirement is. A typical corporate will say cost transformation. A typical corporate will say business transformation. A typical corporate will be increase my customer satisfaction. A typical corporate will say protect me. And typical corporate will also say can I grow my business. So at ionos we listen to our customers. We now have four platforms. The one first platform is uni protect which takes into account that we need to make systems which are resilient. We need to make systems which can be governed better and systems which can be brought up just in case the hacker succeeds. Similarly, I have a product called UniV which takes into account customer experience management but at half the cost because now we harmonize what the requirements of AI is, what the facilities of agentic AI is and how I can marry technology and humans to deliver results. Similarly, I have a product which is about data monetization because my customers want to grow their business. They know they have data. You are a bank, you have data. You are a telecom, you have data. You are a kirana store, you have data, you want to cross-ell, upsell, you want to do more. So, we have this product which is all about data monetization. And similarly the last but not the least which is uni stack which is about multiple agentic AIS multiple chatbots multiple AGIS all running through your system. How do you make sure that they are orchestrated? So I think we are having fun building Ionos. We have had fun listening to Sam Alman or a Rajan and all I can tell you is India is ready for scale up. India is ready for 750 billion and India is lucky that we have innovation centers like IIT Madras that professor Ashok Gunjunwala runs and I can only promise you is that we are also lucky that Ionos is rising up to the challenge because we listen to the customer we listen to the customer's customer and we use AI as a tool thank you guys thank you so Thank you sir for sharing the vision for of Ironos. We now move on to the next panel discussion. I request all the guests and audience seated on farther end of the stage please take seats towards the center of the stage. Hello. Hello. Good afternoon everyone. We're officially at the halfway mark of the AI impact summit. Um and it gives me great pleasure to introduce my panelists here on on our session on enterprise um AI. I'll start with Amit. Amit Zaviri is the COO, president and CPO at Service Now, um the workflow enterprise giant. Um followed by Victoria Espanel who is the CEO for BSA, the software alliance. They're a global industry advocacy body for enterprise software companies. And we also have Miss Ambikar Raj Gopal who is the global chief uh digital and AI ethics officer for Michelin which is the industrial and manufacturing giant. I think I want to start off with you Amit. Um I as COO and CPO you dawn two hats between building the product and and shipping it versus also running the business. There is a fine line to tread. How do you think about the business value that that AI is able to you know acrue to your enterprise customers? Um what are some of the challenges that you're seeing between say 18 months ago to now? 18 months ago we were at an experimental stage now experimentation stage. Now we're moving to much more of an adoption across the enterprise stage. >> First thanks for having me. Hello everyone. Uh I think the question you asked has been top of mind for every customer I speak to. uh last year I landed speaking to almost 900 customers and most of them start of last year were worried about what is a what where to start with AI uh what is the value it'll create and can you really manage it uh middle of last year we started seeing a lot of change in mindset specifically around the idea of if you can control and you have visibility then AI is something they want to experiment and start using and the growth started happening pretty much last end of last year when people are starting to use this agentic workflows and systems to connect different things together and get real good value and automation out of it only only time they started getting excited about it is because they have to have security around it right so what we did was we introduced something called AI control tower which provides you visibility and discovery of all the AI systems you have and for customers that made them much more comfortable that now I have ability to know what's going on who's using what how much I'm paying for it can I really have visib ility in terms of any kind of changes I'm making and uh really be able to turn things on and off and now what we're seeing is the huge amount of adoption starting to happen because of the idea that security is built in uh you have lot of scaffolding around compliance auditing uh be able to have visibility that's the value creation starting to happen because AI is a great technology it's really been very good enabler uh for automation insights be able to do things much faster but the worry always was around security compliance and visibility and control. Once you start taking that barriers out, the adoption started to go up and the value creation is really about efficiency gain. Uh be able to now connect different systems together faster. Uh remove a lot of the inefficiency you had in the in the businesses and freeing up resources to be able to invest in a lot of new areas as well. So connecting those things together has been really useful so far. Speaking of new areas, Ambika, I want to bring you in because I think the vantage point you have at Michelin is a little different from how most of the world might be using AI right now. Michelin has, you know, realized almost hundred million euros worth of business value through its enterprise uh through its AI adoption. tell us one boring, you know, so-called boring industrial use case which has actually moved the needle much more than maybe an AI chatbot would have. >> Yeah. So, uh it's a wrong person to ask the question because uh I mean I've done AI for more than 20 years and my joke is that you know I used to it used to struggle to get people to talk about AI and now I can't go anywhere without you know people only asking me questions about AI. So for me there's you know there's nothing boring but um actually for us I think the the chatbot has become let's say um uh very common we have um you know um various levels of chatbots deployed um both uh let's say very accurate ones for our finance for our folks that essentially consult our finance documentation we have ones that are that are on the SP our HR policies um you know and of course u you know more generic ones that people can make for themselves. But maybe a um a use case that is not among all of this but really creates value. Um in fact we've had a um a strong AI um focus for several years now and um you know so if you if you look so the tire it's a it's a zero safety product and the imperfections or defects that you can see on the tire are visual. Okay. So in fact one step in our qualification process is actually to visually inspect the tire. So over several years and we have multiple patents for this. We basically we have a machine um which we call iris that essentially um you know scans the entire surface of the tire and points out you know essentially flags imperfection. But this the interesting part is not this one. The interesting part is actually, you know, what was the reaction of those that were involved in inspecting the tire prior to this. Okay. And it's amazing because first of all, you know, it's it was not a really, you know, uh ergonomically friendly job to essentially, you know, closely inspect a tire, let's say, in first shift, second shift, etc. But also, what the what the operators essentially said was the the part of their job that they really enjoyed was not finding the defect. It was really understanding the defect and flagging what it really was. Basically bringing their deeper knowledge of what tire defects really look like. You know what is you know classifying them, understanding them and this is what they are now able to focus on. So that's a that's an example um of course rolled out in several um um several of our plants already and uh now we are looking at um you know because now we have all those images. So it essentially is opening up even more use cases for us. >> Got it. Victoria, as the head of an industry body, you know, which counts the the topmost enterprise giants amongst its membership. I want to start first with challenges and bottlenecks. What would you say are your top three four challenges that you're seeing when it comes to large enterprises really truly embedding the use of AI in their everyday fabric? >> Thank you. Um so you I think it depends on the on the organization but I think one of things that companies have struggle with. I found your your example really interesting because safety for Michelin is is critical, right? is trying to decide where in their organization they most use need to use AI and focus that. Where I hear uh companies saying that they're struggling is when they either have um they have sort of a organic use of it but not one that is organized around something that's really missionritical to the company. And so and I think that's starting to change as companies are using it more and more. But I think one of the things that I say because I get a lot of companies that ask me like what should we do? We want to start using AI. How should we start using it? And the advice that I give them is to focus on one or two things that are really important to the company and then build um a history of use around that and then try to expand instead of trying to do too many things at once. Um I think sort of building that expertise inside. A second challenge um is making sure your workforce understands it. So I think that is I mean it sounds obvious but obviously a company's not going to be able to use AI effectively if the people inside the company don't know how to use it. And I think making sure that those skills are being transferred um and given to the employees is critically important. You know, I think there's my job is I'm a policy expert. So, I work with governments around the world um and give them our advice from the perspective of enterprise software what their laws should look like. And I think one of the struggles is that right now we're still early in those days and there's a fair amount of regulatory uncertainty. And so I think that can be a barrier to adoption when companies are concerned whether or not they're going to be compliant with a particular law. And that is at BSA. That's one of the things that we work on is trying to make sure that governments around the world are putting laws in place that are relatively consistent so that our members like service now but even more importantly the customers of our members aren't having to deal with a lot of regulatory uncertainty. Uh Amit coming to customers, what is the number one reason that CEOs are hesitant to give right access to AI agents um you know for their core enterprise solutions? >> The number one reason is always security. Uh the there's a huge amount of concern about who has access to the data and how is going to be exposed externally. So typically if you talk to any any CIO or anybody else, they want to have ability to control that and they are worried about some of these AI agents where you have no ability to govern or secure or uh really have uh ability to manage them that can go wrong and enterprise data and your IP can be exposed. That's typically the main main reason and then after that once you can solve some of the problem then they get excited. I'm sensing there is a culture or at least a mindset that we need to overcome whether it comes to customers or whether it comes to you know the users within your enterprise who have to do that. Um Amika let's go to the shop floor the factory floor. How do you convince an army of factory workers with maybe 30 years of experience to listen to an AI agent that's telling them to change a vulcanization setting that is not intuitive to them. uh they feel like they've been on the floor they know they understand the system inside out but perhaps your AI system has detected an alternative way of doing things is that something that's even a challenge now um the mindset of the people who've had to kind of implement the AI >> yeah so um I think you know the first of all there is u you know what we are let's say you know not what is not helpful is that you know there is a lot of conversation around um loss of jobs um due to AI automation uh but honestly I would say without a lot of substantial data behind it there are layoffs but are they you know in which sector are they directly correlated this is not clear and then you know the the academic studies we don't really have any research as yet that I'm aware of that clearly points to this so in fact um what we do have is long-term research from econometrics that essentially shows that what what are being what could be automated are tasks, right? And and uh and essentially tasks in areas where a particular um you know the the person performing the task has in fact a wide range of tasks in their job. So it's not the job that's getting automated like a single job. It is in fact tasks inside a job. And this is very interesting because you know if you if you let's say take a person who has been working at a station for multiple years and one of their tasks of making a specific judgment now comes with a recommendation which gives them deeper insight into what it is also essentially shows them over time that they get better outcomes you know in their station from that particular part. And not only that, basically frees up their mental space, cognitive ability to essentially focus maybe on the root cause of some of the flags that they are seeing. Then you know we are talking about something completely different. We are basically talking now about a worker who is more engaged in in in what they are doing. They we are talking about a worker for whom you know the the the AI in fact is is helping them you know to understand their own process better. And uh we have examples where in fact this is exactly exactly how it goes. Uh not with um you know we we've basically deployed um um you know um recommendation engines in the form of bots of course but those are you know not the chat bots like LLMs. say in fact um you let's say say okay you know what this is what I see is going on with this machine you know could you suggest what it could be due to and it brings back let's say one two three root causes for it and they love it you know and it's exactly for the reasons that that I said before it brings an answer that then they have the time you know to reflect about and and that's that's a win-win >> I'm going to come to the geopolitical effects of of AI adoption in just a bit but before I do I have one question for all three of you. AI is changing rapidly um even weeks if not months months not not weeks and Indian you know businesses are at an early stage of streamlining their technology. If we talk about small and medium-sized businesses, you know, they're facing a strange conundrum between making investments in technology that might actually become obsolete very soon, but also having to lay down at least the foundational, you know, framework for having their AI processes and technology in place. They're at at odds with, you know, what kind of decisions they should be making and how quickly. What is the one piece of advice you'd have for small and medium-sized businesses and how they ought to think about their AI roadmap for say the next 12 to 18 months? >> Yeah. >> Uh so I would say two one pick one use case and focus on that. Um, second, you know, a lot of small and mediumsized businesses, companies are using software that is embedded. A AI is being embedded into it. And so I think if you're unsure where to start, one thing to start is making sure you're using the AI tools and the software products that you are already using before leaping into something new. But the first one is pick one use case, start there, make it work, learn from that. And and what I would say is you know obsolescence dealing with obsolescence is the fact of life of every CIO. You can't escape it. It's always there. But what is far more important for me than obso what I would say is far more important obsollesence is adoption. Um as long as you have adoption and as long as you're seeing values you know value then you know the obsolissence that you have become something that you can actually you know take care of. It's when it's the other way around. you have obsolissance but you have no value coming out of the software then you know you're in in a different position so so you know it is a strange time um it feels like the ground is moving underneath our feet you know every every few months so nevertheless I think the focus on adoption making sure that whatever it is that you built is in fact truly relevant for the folks that you're building it for my my advice would be to focus on that >> I'll just say I think I agree with you getting a good use case which is going to add value right something which you can say that I can measure and see something useful out of it is going to be important part of it. And I think you cannot just ignore the value of AI. So get used to it. Learn some of the tools. Uh but don't use AI for the sake of AI. Just make sure you're getting some value from it before you invest in it. >> One more question. Service Now is model agnostic. Every company is pitching their model to be the best one. How does one prevent AI sprawl? Because currently enterprises are also struggling with having 50 disconnected systems in place. How does one, you know, company choose what's best for them in this context? Why is interoperability important? Why are open platforms important? >> No, I think it's important. If you look at history of enterprise software, if you do land up getting locked in, it is very hard to get out of it. And uh that's why having a solution or buying products which give you choice and flexibility for an enterprise customer is always paramount. And I think many enterprise customers have learned over years. Don't lock yourself in. So the way we think about it is that have a solution where it's not really about the model and you shouldn't care what model is been used underneath an application as long as the solution meets your need and we can give you the choice of whatever it is underneath the covers and eventually you might not even care because the value is created by the product and the solution not by the model itself. So that way you're not locked in. If I if I change something which is better price or better performance or better capability or but more language support more more voice support whatever may be required that's the right thing to do for the product and it should not be tied based on just like you don't pick the chip you're using in a application do you care whether it's AMD or Intel or Nvidia probably not for a application user typically or a workflow user that's how we think about this idea so don't lock yourself in get a solution which gives you flexibility in terms of deployment integration as well as model choice prices and then you will get the best price as well as the best performance and the best solution over time. >> I think fragmentation is becoming a problem not just within the enterprise but also across countries across markets that you operate and across sectors. Victoria BSA, you know, advocates a risk based approach, you know, both to sectoral, you know, regulations, um, as well as how AI rules, you know, will evolve even in different countries. How do we prevent 50 different rules for 50 different sectors? You know, there are highly regulated sectors like the financial services sector, like insurance. um what kind of an approach should regulators think about when it comes to you know different um companies working in the sector so that that company doesn't owe different kinds of things to different people who govern them. >> Yeah. I mean this issue of fracturing comes up in all sorts of different ways, right? So there's sectoral versus there's different countries, there's within a country, the different frameworks they have. And again, part of what we spend a lot of time around the world doing is trying to make sure those approaches are as consistent as possible. Different sectors of the economy are going to have different obligation and compliance burdens, right? They're going to have different regulators. What we advocate for is having one general framework that applies across the economy and then four particular sectors right now because we are still in relatively early days to have regulator regulators using tools like sandboxes and general guidelines and seeing if those approaches work and being able to sort of quickly pivot to another sort of agile regulation if you will. And I think that's going to be very important as we're as we're moving forward in this world. Ambika again very very interesting vantage point because factories don't chase hype they chase uptime two myths you'd like to bust about AI when it comes to you know industrial and and manufacturing space >> um the I think the the the first one is um that um there is no interest or a strong resistance from either the factory workers or floor or in fact it's exactly the opposite Um we have examples in fact we you know there is a push that we have um you know from remote factories around the world where they have access to you know certain tools that essentially they are able to build something and they come to us and say hey we've built this it's doing great can how can we deploy it how can we work on it so I think the first myth is that there is a you know lack of a ground up enthusiasm this is not true in fact we find a um a large um you large um swell of interest that's coming to us u you know from uh from around the world. I think the the the second thing would be that um you know as to where is it that the focus is um so it's really the in fact what we have found is because manufacturing organizations uh you know have a long history uh through Kaizen through six sigma of consistently working on our processes. So it's just how manufacturing companies work. we consistently you know refine our processes. So really the organizations uh that have that mindset are able to look at AI as another opportunity to essentially re-engineer processes. So a process uh and a system focused way uh to look at um you know to look at problems that are let's say u you know where AI can make a difference. This has been huge as well. Uh Amit we were briefly having a sidebar conversation earlier where we were discussing this whole trend of sovereignty. You know a few years ago there were fears about the bulcanization of the internet. You know when the whole data localization piece was coming up. Now there is talk of a splinteret because you know different countries have concerns about what kind of sovereign capabilities the country should be focusing on where the data should reside you know where the models should be trained and where inferencing should be done. Can you talk to us a little bit about what are the challenges that you're seeing when it comes to you know implementing some of these solutions especially for customers that might be operating in different countries with different rules you know is are are the operating rules different for a company operating in Delhi versus Detroit >> no I think uh the question you asked about sovereignity is top of mind for every customer I speak to especially multinational but also a lot lot of the country based uh sovereign country uh institutions especially public sector or things like regulated industry ries and it's gone up a lot over the last few years because the worry about that do you want to run software which is not in your access control and do you give data outside without any kind of oversight uh so I think the software which we have designing and we seeing a lot more uh need for it is to ensure that we have you have ability to run that locally uh where the data resides locally is maintained and managed by somebody local in the country with the citizenship uh and then the architecture becomes very complex as you said if you're multinational you're operating in many many countries how do you guarantee that kind of regulatory profile and that software guarantees that you will get the right outcome uh so I think what we have done at least we try to make our software very flexible you can run this in private cloud you can run it in your own data center uh our data center on a hyperscaler so that any kind of new regulations come in you can adapt to it but there are a lot of other issues out there with many many of these hypers if you see what you with this large language models the frontier models don't run locally the inferencing might happen locally but some data still will go somewhere else and that is be an issue where architecturally I'm not sure how quickly they can adopt to the sovereign requirements of many many countries today everybody's getting excited about AI but that is going to be the big problem >> if the architecture were to be solved for if if the company's completely compliant do you sense that there might be a risk still that the efficiency might come down if there is more and more kind of hard data localization are the outcomes that the system is able to produce better when the system is more widely and freely connected. >> Yeah, I think having a global environment is always better but uh I can definitely see the performance and other issues are not there. The question becomes can you build so much uniqueness >> for every different regulation and requirements and it's very costly and the cost will eventually get passed to the individual customers and then that's where the do you want to adopt it? How quickly will you do it? whether you want to invest in it becomes a big question. >> Victoria, as a former US trade negotiator, I know you're no stranger to, you know, aligning global standards and knowing how difficult it is. If you had to preach and and advise governments around the world to take it a little slow when it comes to, you know, putting the brake on on you know this innovation so that a global environment like Amit said is is easier to have. What would you advise them? >> So I would say focus on adoption. I think that is the thing that is going to have the biggest econom economic impact on countries. And so if we're sitting here 10 years from now looking back, the countries that win the AI race, the ones that are going to be the winners are going to be the ones that figured out how to have their private sector adopt AI in a smart way. That is who's going to win the AI race. So I would say focus on adoption. I I would also say I'm so excited. I love being in India. So excited to be back in Delhi and I'm so excited that Prime Minister Modi decided to host the summit here because these types of convenings are what help us move towards global cooperation and global alignment. So um this is it's wonderful to be here. >> Am I'm going to move to you. India's priming itself to be the next global manufacturing hub. You know, historically we've competed on costs, but do you think AI can be India's secret weapon um where we win on precision rather than price necessarily if we're able to become AI native and AI first in a truly meaningful way? Yeah, I think um you know just being here as Victoria said um it's you know the the the you just have to be here to really I think feel the energy you know to have I think the the average age must be like mid20s and I see a certain you know enthusiasm I see uh um you know hope in everybody's eyes and it's you know and and I think um you know as whether it's manufacturing or whether it's any other sector um this is you know the the the the the divid the the dividend that we will actually reap is from the investment that is there you know from in the education of our um technical education technical bent um and deep interest entrepreneurial mindset uh of our um of our youth and that's that's sector agnostic >> I know time is up I have one quick fire question for all three of you AI function that you think will change the most by 2030 and one that you think will resist the wave of AI the most I >> think change the most will be uh will be consulting so I think it's just going to be done an entirely uh different way um and that will resist the most I think is uh um I would say the medical field because um I think it's just it's we already have plenty of evidence that it sort of you know just absorbs it becomes more complex and moves on so your relationship with your doctor is you know is not something I don't think that's going to change. >> I know we're at time, but thank you everyone for your patience and for being here. And thank you so much to all of our panelists for this uh for their wonderful remarks. Thank >> you panel members. Thank you man for your excellent moderatorship. I was surprised. Good evening, ladies and gentlemen. We now move on to the next keynote address for the day. It's my honor to invite Mr. Carl Scow, Deputy Executive Director, World Food Program to deliver the keynote address on AI in food security and nutrition. Please give a huge round of applause for Mr. >> Kh. Distinguished colleagues, ladies and gentlemen, I'm really delighted to be here today and let me start by thanking the government of India and everyone involved in organizing this impressive summit. It has already generated thoughtprovoking discussions and illuminating insights on the potential to transform economies, the future of work and daily life. The transition from strategy to impact is indeed key. But I would like to focus on another vital intelligence frontier in this I AI space, one that deserves just as much attention, and that is humanitarian action. If harnessed responsibly, AI could enable humanitarian organizations to save and improve millions of lives. We could unlock new levels of scale, speed, and efficiencies. And the need for technological innovation has never been greater because today the humanitarian and development system is overstretched and underfunded. Just take world hunger. 300 million people don't know where their next meal is going to come from. Two famines have been confirmed simultaneously for the first time in a century in Gaza and in Sudan. But drastic budget cuts have forced organizations like the World Food Program to cut food assistance almost everywhere we work. like in the Eastern Democratic Republic of the Congo where WFP is the only able is only able to feed half a million people out of 10 million classified as acutely food insecure or in Afghanistan where we can only can cannot support 15 million people in urgent need of food assistance. So it is imperative that humanitarians find new ways to multiply impact We have to do better with less. And AI innovation could fill some of that gap. With further investment and new partnerships, we could bring the benefits of AI to even more of the world's most vulnerable people. WFP is well positioned to lead. Our frontline presence give us unique data from some of the hardest to reach places on Earth. WFP is taking an organizationwide enterprise approach to AI development. Our global AI strategy has set clear standards, priorities, and governance. Our research and development teams are quickly scaling and deploying AI solutions to real problems in the field. This is allowing WFP's frontline teams to deliver faster, smarter, and more efficient programs, often at low lower cost. Four key areas of WFP operations have been transformed already. Firstly, AI enabled tools are helping WFP to predict and plan for crisis before they strike. Our hunger map live platform uses near realtime machine learning to track risks like extreme floods or droughts in over 90 countries. It can predict a crisis hotspot up to 60 days before it peaks which gives our country teams time to plan and deliver early support to families before the peak of the shock. This reduces the impact on vulnerable populations already on the brink and it is more costefficient than postcrisis aid. Second, AI is helping WFP to assess damage after disasters strike so that we know which areas are in greatest needs and to do so quickly. Our open-source AI powered satellite analysis lets us assess building damage within 48 hours before it took us three weeks. We have shared this tool with government partners so that together we can rush in humanitarian assistance to the hardest hit areas after a crisis. This allowed faster and smarter response in Myanmar earthquake in 2025. the Turkey Syria earthquakes in 2023 and the Pakistan floods in 2022. And we continue to reiterate we expect that the next version of delivery insights under will deliver insights under 24 hours. Third, AI is starting to allow WFP to leverage our extensive population data sets to make faster and smarter operational decisions. Like in our food security assessment system, which hold the information of tens of millions of people, we now use AI automation to process vast amounts of their data twice as quickly as before. This has radically sped up the food assistance journey. We are moving much faster from field data collection to targeting insights to delivering food and cash. And fourth, AI enable enabling logistics and demand forecasting systems are helping WFP to improve our approach to humanitarian delivery. This is the core of WFP's business and the cost efficiencies could be gamechanging. Like Scout, our supply chain planning tool, it allows us to plan cheaper and faster food procurement, stock prepositioning and storage and delivery routes. The tool has already saved us $6 million in savings, which can be channeled back into WFP frontline programs. And as we scale up, we project it could save $25 million a year. Those efficiencies could free up enough resources for WFP to provide 50 million more meals to people in need. Moving from our frontline operations to our internal systems, AI is also helping us to eliminate internal resource waste which WFP simply cannot afford anymore. For example, AI automation is now fixing duplication errors in our population databases. These errors are hard to detect manually. So, this automated solution is a real boost to our country operations. With more accurate registration records, they can ensure that WFP assistance is reaching the right people at the right time. In Mali, where funding shortfalls have required us to cut assistance by some 50% in the last year, this service has fa saved us more than $400,000. We're now planning to scale it up worldwide, which we project could save some $5 million already this year. Distinguished colleagues, global hunger is a shared challenge. WFP's goal is to tackle food insecurity wherever and however we can make a positive difference. We have growing expertise in developing and delivering technological change. These are robust foundations to support host governments and authorities to leverage AI for domestic food security. That support include helping countries to enhance their crisis early warning systems and grow the impact and scale of their social protection systems and climate risk preparedness. This spirit of innovation has helped WFP to forge particularly strong partnership with the government of India. Together, we are improving efficiency, access, and transparency in the world's largest food safety nets. Like our work on optimizing the public distribution system supply chain, we have cut transport costs and times across 31 states here in India so that food grains are delivered faster to people who need them most. The resulting savings can be red redirected into critical social programs. Together, we have also rolled out smart warehouses nationwide which use AI to store food more efficiently at a lower uh stock losses. And we are very proud of our joint success anupi automatic grain dispenser. They provide 247 access to monthly food entitlements so that people can collect the rations at the time that suits them best. This is making a big difference to migrant families and other vulnerable groups. And the work that we do here in India is really an inspiration and it's providing solutions also for our operations worldwide and the support that we provide to governments in other countries. WFP is ready to co-create, co-invest. The value we can bring is more than just response tech expertise. It is frontline scale. Through our operational footprint, WFP generates and responsibly maintains largecale real world data sets. This puts us in a unique position to train models, to validate them, and to put them at work. So, we want to hear from more industry and research partners. Your cutting edge innovation and tools could save and improve millions of lives when combined with WFP's operating scale. We are ready to support more government systems, too. Our teams are leading experts on integration of responsible AI international food s food security preparedness and social protection systems. Our AI systems for early warning needs assessment and logistics could catalyze your national systems to deliver far more impact and at a lower cost. Today there today together we can modernize crisis preparedness arch ar ar ar ar ar ar ar ar ar ar ar ar ar ar ar ar ar ar ar ar architectures and protect more people earlier and more costefficiently. And to the humanitarian and development community, we are committed to partnering with you through enterprisegrade platforms and scalable approaches. We are ready to share, reuse, and strengthen what works for everyone. We owe it to the people we serve to reduce fragmentation, accelerate better outcomes, and ensure that innovation truly serves the people at scale. Colleagues, we are excited at the potential for AI to supercharge the fight against hunger and many other humanitarian challenges. Besides, redefining humanitarian response through AI is now one of our top corporate priorities at WFP. With the right partners, we can take what works and make it work even better everywhere. The leadership and innovation ecosystem in this room is already shaping how the world thinks about technology for public good at scale and with inclusion. We are eager to work with more of you on responsible, high impact humanitarian action enabled by AI. Together, we can save and change millions of lives for the world's most vulnerable people. They they deserve to share in the AI dividends as much as everyone, if not more. I thank you. you Mr. Scow for sharing the vision of the world food program and India's and WFP collaboration. Ladies and gentlemen, I'll request you to stay seated for the next power conversation panel. Krishna, Secretary, Ministry of Electronics and Information Technology, Government of India as the moderator. We also have with us Shri Ajay Kumar Sud, Principal Scientific Adviser to the Government of India and Shri Setu Raman Panchchinatan, former director of the US National Science Foundation. Ladies and gentlemen, please give a huge round of applause for the leaders. Oh wow. Okay, that is for a change. I get to ask questions. >> Okay. uh very happy to have uh both uh uh Dr. Sith Raman Panchchanatan and Dr. Ajay Kumar Sud here with us and as is I mean I've got so used to answering all kinds of questions in the past few weeks that finally it feels good to be in a position to actually ask people questions. So um let me uh I I guess neither of the two speakers actually requires an introduction. Both of them are leading scientists and science administrators in their own right. Uh who unlike a pure administrator like me have done far greater good to the cause of science. So um let me start with you uh Dr. Panchathan. Um during your tenure at NSF, how did you approach funding decisions for AI research? Which what criteria determined which projects received the support and what funding models have proven most effective in translating AI research into real world applications. Thank you, Secretary Krishna. It's good to be here and it's mind-boggling what you have put together and I I can imagine how you are all spending sleepless nights. We're very grateful. So uh you asked a question about NSF. At NSF you know one of the things I keep reminding people is the AI of today that we are all celebrating is more than five to six decades of sustained investments by NSF. I often remind people that even in AI winters when people were not investing in AI because they were circumspect about what it is uh NSF continue to invest along with other investors and so what you see today is an outcome of that kind of an investment. That's the first point. More recently, we have configured the investments not only in discovery spaces but also in a very focused way. Just in the last three years, we invested in 27 AI institutes close to more than half a billion dollars. Each center being $20 million scale and co-invested by not only NSF but also other partnership entities, industry, other agencies and so on. So that's a second and you asked the third part of the question is what does it do in terms of translating and what kind of programs help with the translation institutes do some but we also have a program which we created as part of a technology innovation partnerships directorate called the regional innovation engines program. There we essentially allowed for these ideas to then form the basis of development of economic development ecosystems for economic prosperity. And then you augment that with other programs that existed at NSF which continues to advance ideas to translation like the you know innovation core program or the small business innovation research program and others which essentially take the AI ideas like other science and technology ideas incubate them into small enterprises and entrepreneurial ventures and so these are the ways in which a multiaceted approach to sustained investments from discovery to translation to impact. So in a very quick summary form, >> thank you. Thank you very much for that quick summary and uh which sort of encapsulates all that NSF has done over almost 50 60 years. Uh to you Dr. Sud, what is the current landscape of AI funding in India across government agencies and how do we ensure better coordination and avoid duplication? Also, how can India attract more private sector investment into AI research while maintaining focus on the public good? >> Thank you very much, Mr. Krishna. First of all, I'd like to take this opportunity to say that it's a privilege and a pleasure for personally for me and my office principal scientific advisor's office to be associated with this AI mission AI wave in the country. So we have been working uh with your office with you and I can see the scale at which uh mighty has worked to bring AI to this scale at right uh you had the mission approved in 2024 and it's only about one and a half years the progress is actually more than exponential. So first of all my congratulations to you and your entire team for this spectacular work which you have done and through you I am also conveying to honorable minister who is leading the ship and of course our honorable prime minister. So coming to what uh you said uh investment in AI uh as compared to other countries has been mostly from the government uh which nucleated the whole scene with your AI mission and along with AI mission we had also ministry of education which put in its resources to make four centers of excellence and of course uh DST which did some initial funding under cyber physical system. So with all this we have brought uh brought up a a critical mass of uh innovators in this game. So now the stage is all set where private sector has been energized. So it is not that the private sectors took the lead and invested. Here it has been the other way. Government nucleated this and catalyzed this and now the players will come on board. So the private sector can see a value. So when they set up the data centers with quite a bit of a announcement now uh right from Google 15 billion in wisog and in Reliance and then Amazon all those data centers will contribute to AI not only AI innovation but AI diffusion. And what is important is that with India we have to focus on innovation and today is a good day. I was just because it's so hot I thought I'll mention that this server AI which our AI mission funded and you are a partner in crime uh they have released today 105 billion parameter model with 22 Indian languages. Now this is not really com uh saying that we are also in the race. We are saying we are ahead of the race in this game. So the innovation is the key point and once the innovation comes I'm sure the private sector and academia and startups with they'll they are working in unison. In fact there is a synergy and AI mission is actually the glue which is helping this. So once again uh my congratulations to AI mission which has done a phenomenal job in nucleating this and all this ecosystem which has been created in the country uh and the enormous uh enthusiasm of the young people in this summit is a reflection of how AI is going to penetrate our lives with safety and uh trustworthy AI. >> Dr. Dr. S, I mean you're as much part of the AI mission as any of us. So the credit belongs as much to you as to anybody else. >> Thank you. >> But uh staying with you, another question for you since you've been partly associated with that. India is developing its own AI regulatory framework while others like EU have already implemented some comprehensive laws. Should India adopt a similar approach or chart its own path and how is India addressing concerns around algorithmic bias and ethical AI use across sectors? >> Actually probably the most important as question you have asked. So I'll just uh say for the people who are here uh uh India AI governance framework was released uh by mighty and I happen to chair that uh that was in November 2025 and one of the vertical or sutra as we called is the safe at AI. In that we uh have articulated what it means uh by this and in particular we took a leaf out of our experience in and we brought in a con idea of technolal framework we that is what DPI 1.0 has really permeated our society. So what it means for non-experts in the audience you embed your legal uh requirements in the tech uh right in the uh technology when you are developing deploying and using. So these are the uh uh uh requirements which are embedded. Of course you can always say will it uh affect my model uh how much will it slow down how much will it have latency all those are worth looking at it but this framework which was released a white paper uh on 10th of February I request all of you to look at it there we have advocated that technolal framework could be one of the way to have safe and trusted AI this is not only for the government even the institutions when they want to implement AI uh you know processes they have to know whether it is safe trust me if you are not careful and if you're in a rush actually the legal issues will kill you in few years because it will do some damage and then it will be question who is responsible so this technolal framework is really a oneoff framework works which we have said with appropriate technologies, appropriate uh uh uh things and through you I will put here on this platform we should see how we can incentivize the implementation of technological framework or any safety framework. It's not only voluntary because I think if we incentivize to all the companies all theions it will be a big way. So I thought uh we have a role to play here and that's why I mention it. >> Thank you very much. And uh turning to you Dr. Punch. Uh how is the US navigating the tension between fostering innovation on one side and ensuring responsible AI development on the other? uh what do you think is the best possible regulatory approach here? >> No, this is a very very good question as um as AJ has weighed into this from the Indian side. From the US side, I think the important thing that you want as a guidepost is you don't want regulations to impede innovation. That's the underlying thing that you should never let any regulation become you know uh an impediment to fostering innovation. So that's been the the guiding mantra if you may right through the process. So clearly you know entities like NIST have put together risks frameworks. So you need some frameworks that tells you where the risks are otherwise it can be in a blanket kind of policy that you build that might actually as I said curb the speed of innovation. So that is a good step in my view and so it is a work in progress is how I would say it as as AJ has been saying you need a number of other uh disciplinary folks participating in this because typically when we build technology these things become afterthought and one of the challenges that we face in AI today is that technology has advanced so fast and is advancing faster but the other frameworks are trying to keep pace with it and you can think of it as putting band-aids if you Okay. Right. Rather than how do you have policy and social behavioral economic sciences uh and other disciplinary inspirations co-creating technology so that these things don't become an afterthought but it becomes you know right from the inception of the technology itself because we're learning these lessons in AI which is going to help us in other technologies of the future. So back to your question therefore there are many approaches that is being talked about but in the US I think the fundamental concept is how do you build guardrails where guardrails need to be put in place and at the same time be mindful of the fast pace of progress and so to work closely with industry and other partners. So Congress is interested in that. There have been caucuses in Congress in the last couple of years both in the Senate side and the house side. Of course the administration is closely involved. The office of science technology policy in the white house is closely involved. Agencies like NSF and other agencies are also closely involved at NSF. What we did was we said why might not we create teams by which we can work with industry. I'll give you a concrete example. We partnered with Amazon on a trustworthy AI call. This is about three years ago now. you know um sort of foreshadowing what might come about and how might we work and bring the assets of industry and its concerns and the emerging concerns public domain but also bring scientists along so that we might solve these problems rather than only putting those kinds of policy frameworks without being informed by all the things that needs to happen with a scientific approach to this also. uh otherwise these things will be lacking in scientific rigor and approach that we might just put it because we are afraid of something as you know fear is not necessarily a good emotion and it really curbs innovation. So it's not to be coming from a foundation of fear but a foundation of responsible ethical approach to how do we build these frameworks and that's the approach that we are taking as we speak. >> Thank you very much. Now given that uh we don't have much time left I have one question which I'd like both of you to answer. Um, India has scale and diverse real world problems. The US has deep research infrastructure and funding. How can we structure partnerships that leverage these complimentary strengths so that it's good not just for these two countries but for the rest of the world as well? Dr. Uh I think no absolutely u uh good question to uh look at because uh we have our strength in innovation and now with the infrastructure provided by uh mission as well as by other agencies. Our innovators have been enabled. Now once that happens we can really interact as a partner rather than just uh accepting uh whatever is given. So this is a true partnership uh issue and India can be a very very wonderful player uh where uh uh the skills of our young people the innovative skills the innovation hunger I would call it will be very very beneficial. So what we need to see we uh we need a uh framework actually for this cooperation if we want uh government to government or government to be but businessto business is really what will take over in this uh field and business to business can only be done when there is a trust and India is a very trusted player and so US so this is our strength of years of partnership between India and US because our lot of young uh talent has one way or the other uh interacted or spent time in US. So it is a uh very good situation where trust has been built. So now we work want to work on it and we need to see how we utilize each other's strength. So one example uh which one can see uh is there a use case because India of course has huge diversity in languages and uh our heritage uh literature and so on. What we learn here what message it is has for the US. So it can't be only oneway traffic. It has to be two-way traffic where we will learn from our experience and our showcasing and we are open from the other side. So it is a uh a win-win for both sides. >> Uh thank you AJ. Picking up on what AJ said. First of all I want to say that we developed a strong partnership um NSF and uh DST, METI, DBT and others and we had forged a lot of projects between us and India over the last five years. So let's start right there. The largest democracy and the oldest democracy working together can do amazing things. picking up on what AJ said and AJ and I worked very closely in the quad context a AI and agriculture because that's an area that we both care about and that we can deliver solutions. So at the the top level you address the issue of infrastructure versus applications. I would say there are model development for example infrastructure clearly is an area where you know there a lot of progress is made in in in um in United States and India is also trying to do the same. Then there are models and then there are these large scale models and then the small scale models are becoming more contextualized and India is taking a lot of steps in that area and of course so is US. So there are some synergies that are possible there around certain applications domain data sharing which is an exceedingly important imperative if you want to really build good models is an area where we can actually work together on and clearly the applications that we both care about deeply and we can have a lot of transactions at that level. All of the layers can have potential gains and there are things as AJ said that can be learned from both sides in order to enrich the development which then to the concept of what this meeting is all about. AI becomes for global good not just only two nations and their economic and social good but it becomes for global good and this partnership therefore can has been evolving and in the last few years we have in fact with lot of intention intensity and intentionality we have scaled it there's a lot more rule room for scaling and you talked about the private sector there's a lot of private sector that transcends both India and the United States you named Google for example every large company both ways uh whether it is cognizant or Infosys on this side. Uh Cognizant is a US company but a lot of presence in India and likewise you know Google and Amazon and Microsoft and others. So the the I would say that it is not just only one sector that leads it. It's going the future is going to be determined by all sectors working together the the the agencies the private sector academia startups and uh small businesses all of them and of course the two governments enabling that is the future I see which is going to be made possible because of the collective interest and the speed at which things are moving will motivate us to want to explore avenues by which we strengthen our partnerships and uh and and work for the global good as I said and that's what I time is over. Can I add 5 seconds to this? Because I think uh it is also a high time when we go above the euphoria of AI usage alone applications. We need to see five years down the line what will happen and this is where India and US should collaborate. I'll give you two examples which are possible and not much is happening. One is with the energy demand AI is going crazy. It's going nuts. Question is is it scalable after 1 trillion 5 trillion what do you do? So we have been saying think about using quantum computers in AI and AI quantum computing. This is an area which is very nent right now. And if India and US come together in these two cutting edge technologies AI and quantum computing, I have a feeling we can make a difference. Second area where again India and US can make a difference is in the physical AI. Physical AI is not so much on the scene as it should be. But physical AI looking at uh robotics, humanoid whatever you want to call it but which is really working at where we don't want humans to be there. So this is another area which I think three year down the line we will have a huge huge explosion in these two areas if I'm allowed to really think aloud and you can always think aloud in the evening. So I guess that's the point. >> I guess you answered the last question that I had for both of you which was that if you could implement one policy change to accelerate beneficial AI development what would it be? Can I take your response as an answer to that question Dr. S? that uh that is one part but if you want to take one thing what we need to see somehow come out with a framework which is trustworthy in terms of regulations and policies so that whatever is developed across both countries has a easy path uh whatever you want to call it unless that is done and unless you have a global data governance framework work it will not happen. >> Thank you for that answer. You have the last word on that question. >> Thank you. No, I was just uh didn't want to lose sight of the fact that we have talked a lot about technology and u you know the applications and so on. At the end of the day, the success of AI is going to be determined by talent. And so if there is a policy that I would like to see is the proliferation of a policy that allows for talent to be trained at scale, at speed and across not only technology realm but across all disciplines. So this is an important thing that we should keep in mind and there I don't think it is determined only by what academic progress will do. It is really a convergence of academia, industry, technology and other folks coming together. It is a new way of looking at what learning is all of all going to be. It is not what it is going to be today extrapolated. It's going to be a completely new model of how you build that. And so I really feel that we need to spend a lot of energy in that thinking because that's what is going to sustain the progress and speed the progress into the future. >> Thank you very much both Dr. Panchatan and Dr. Sud. We could have kept this conversation going for hours I know but times up is what they are telling us and these premises have to be vacated at 4:30 for uh uh the later events of the evening. Thank you. It was wonderful having this conversation and for me personally a real relief to be asking questions instead of answering them. I've been answering too many of them but wonderful insights. Thank you very much. >> Thank you leaders. Thank you Secretary S for your moderatorship and professor Sud and Mr. Panchatan for their time. Hello. >> Yeah. Hey, uh good evening everyone. I know this is the last session, so we'll uh keep it brief. I don't think I won't take more than 10 15 minutes. I want to talk about something very interesting agentic commerce and something that I am personally very excited about on how it can change the way India consumes commerce today. But before I start there, let's talk about digital India. We all know India has a massive digital ecosystem. We have 1.5 billion Aadhaar users. We have 950 million internet users. We have 650 million plus smartphone users. We have 450 million plus users of digital payments. India. No other country has been able to build a massive digital infrastructure like India has. And while this is very exciting, let's look at commerce. When we look at commerce, out of 650 million people, less than 200 million people actually do shopping online. If you peel it even further, less than 10 million of those people do 70% of all e-commerce purchases. So, out of 1.5 billion people, we're down to just 10 million doing 70% of all purchases. Why is it that tiny? It's not like these people aren't consuming, but they're consuming through offline channels. They're consuming through retailers. They're consuming through offline agents. They're consuming through brokers because they still don't trust or use online commerce the way we all are used to. And why does that happen? I think the fundamental reason is India is conversational. We like to talk. We like to interact. We like to take time to come to our decision- making. some some examples I'll give here. When you look at WhatsApp, we all use WhatsApp. India runs on WhatsApp. But almost 50% of all WhatsApp voice notes originate from India. We all have people in our families who still send that WhatsApp voice note because that's what they're comfortable with. They want to speak in their own language. They want to speak in their own voice when they communicate with someone rather than using text or reading text. My friends in US are always surprised that in tier 2 and tier three cities of India, YouTube is the most popular search engine and not Google. And that's because people want to hear the answers to their questions. People want to listen to somebody talk in their language, not just read a wall of text and that has been hard to replace in the commerce world. So when you look at commerce in India, the conversational part of commerce is far bigger than transactional. And most apps that we are all used to are still transactional. They tell you what's available and to figure out yourself. Given an example of travel like we I I have people in a family who still go to a travel agent because because when you go to an OTAA platform, you have to pick and choose the interface intimidates them. You to figure out what to do while all options are available. They're intimidated by the lack by by the amount of choice that's available. So less than 70 million Indians use online travel portals and $50 billion plus of purchases on travel happens through offline travel agents. Insurance is similar. Less than 10% of insurance is purchased online. 90% of it is purchased through a broker, somebody they know, somebody they can interact with, somebody can who can answer their questions, somebody who they can go to and ask when they have a problem. And that is something online commerce hasn't solved for people today. AI essentially enables these conversations. AI allows us to build interfaces that are voice first, that are multilingual, that are assisted, where you can ask any question in your local language and get it answered. And that's why AI can change this. The fundamental bottom line is the apps sold for access. AI solves for accessibility. And I'll give an example of what I mean by that. Like when I speak to my friends in US, they typically buy their day-to-day stuff in a supermarket. When you if you've seen US supermarkets, they're full of choices. You have all you have aisles and aisles full of produce. You have aisles and aisles fulls of products. You'll have 20 types of cereals. You'll have 10 types of milk. And the US ecosystem loves that. You have all the choices. You pick pick and choose what you want. You make your cart. You go to a checkout point. Sometimes even the checkout is uh selfch checkckout. And you do it and you walk out. That's how Americans shop. But that's not how Indians shop. When Indians want to shop, they go to a retailer next to next door. They ask him that, "Hey, I want to buy this." And he tells you the price. You negotiate with him that, "Hey, I want to pay this price." He sometimes upsells you that, "Hey, have you tried this new product?" And that's how you make purchases. The commerce apps that we have in this country are built like the US supermarkets. But an average Indian doesn't shop like the US supermarkets. The average Indian shops through voice. He shops through conversations. And that is what AI can solve. So while apps solve for access to all the capabilities, AI solves for access accessibility where you can answer your it can answer your questions before you make a purchase. So the old journey involves discovery, decision- making, negotiation, assistance. That's what people are used to. And AI can allow you to build that agentic commerce journey exactly how people are used to. It's natural for Indians. So think of somebody wanting to plan a solo travel trip. He goes to an AI agent. He says, "Hey, I want to plan a trip to this place. What are the options?" And he says, "Hey, who wants to go? Do you want to go solo? Where do you want to go?" It gives you the options. You pick and choose. You make a decision. Then it gives you a price. You say, "Hey, can you find me a better price?" It goes online, searches for all the options, it tells you the right price. You say, "Hey, lock it. But can you answer me some other questions? Do I need a visa? Do I need currency?" Almost like an offline travel agent. And that's the interface that most Indians are comfortable with and AI allows us to build that real e-commerce journey that India needs. The other problem is trust. Now the way India operates on trust is that trust is localized. We trust a particular person. We trust a particular agent because we know this guy doesn't do wrong by me. AI allows us to make that trust scalable. Let me give an example there. Uh my dad is about 70 years old and I'm always worried that he'll buy something fraudulent. he'll buy something that is missold to him, he'll get into something that he doesn't need at all. So I tell him whenever he make an expensive purchase, just give me a call. Now AI allows me to put something that is smarter than me right in his own pocket. So when he's making a purchase, he can ask an AI agent, hey, is this the right purchase for me? Is this the right insurance policy for me? Is this the right financial investment for me? And he can tell my dad, hey, don't buy this or buy this. Right? And that allows us to make trust scalable. I can imagine in next one or two years, every one of us will have an AI agent who can shop for us, who can compare prices for us, who can choose the right interfaces for us, and who can tell us that, hey, don't buy from here. This looks like a fraudulent platform or this looks like somebody's missing an insurance scheme that you don't really need. And India has already shown the world that we are adopting these things faster than anyone else. We had Sam speak a couple of days back that India is their second largest market with 100 million plus users. We had Dario speak about how India is their second largest market for claude. We have 3x faster voice AI adoption because as I said earlier we are voice first. Even a lot of local companies are doing this like we have seen Bajins talk about in their earnings call how they are using AI agents to make sales. We had SECO doing using AI to create videos for people to solve their day-to-day problems. We have Jar using AI to deliver financial advice to people at the bottom of the pyramid. We have Vodafone idea which is now has an AI agent inside their app which can answer questions about the right kind of package to use, the right kind of recharge to use and then buy it for them almost like an offline retail agent. Let's look at the Vodafone example closely. Something we have recently launched with them. Heat. Heat. And by the way, this is already live. This is live on the Vodafone app today. And and this is just an example of something simple. You can ask it all sort of complex questions that hey can I can you I use data more I use voice more I do a lot more international calls and you can find the right package and then you can purchase it right there. I want to show you show you something else. Something we launched just today afternoon with Swiggy, Zomato, and Zeppto. And this is again live with NPCI on cloud today. So now when you want to buy grocery, you can ask it questions that hey I don't want this. I don't want this brand. I don't want this brand. I want your healthier brand. It can choose all the options that you want and then you can make a purchase right then and there. And this is just a starting point. India is India has shown the world that we can be the playbook for the entire global south. When we looked at UPI because of the success of UPI now real-time payments are taking up in entirety of global south. I believe we have the similar opportunity with agentic commerce because entirety of global south has the same problems that I spoke about that agentic commerce solves. We are all voice first. We are all multilingual. We all need assisted interfaces. So if we can build something in India and pilot it here, we can take it to the rest of the global south and we have an opportunity to build an ecosystem here. So in the last one year, we have built with multiple partners to to get where we are today. But it's going to be a long journey. AJ commerce is going to be the next fundamental disruptive change in the way commerce happens in this country and we all will work together to build it in the right way. So let's build it together. Thank you everyone. Thank you Mr. Matur for sharing the work and the vision of Razer Pay with Agent AI. AI summit in 2025 to the AI impact summit in 2026. I would like to invite on stage our host Miss Nava, data exchange and government specialist at UNDP, who will be leading a fireside chat with Mr. Lionel Regard, CEO of Cubit Soft. >> Okay. Also in conversation with us is Mr. Gautier Glock, CEO of Edge Company. Please give a huge round of applause for our next speakers. Designed to integrate directly into operational workflows across sectors such as healthcare, infrastructure, public services, and industry. Hi everyone. So great to be here. Um this is the last fireside chat for real this time around. Uh so we'll keep this relatively relaxed. Just a quick fireside chat to get a sense of what's really going on in the AI space beyond the hype. Uh for some context, my name is Navia. I work as a data exchange and governance specialist with the digital AI and innovation hub um at UNDP. And I'll um hand over to Gautier for an introduction of himself and the wonderful work that he does. >> Yeah, for sure. So really nice to meet you all. Um I'm a bit exhausted. I've been running for 10 minutes to uh to get on time to this panel and I was a bit late. So I'll try to um I'll try to wind down. But yeah, I'm Gotier. Um I spent the past 15 years of of my life deploying AI in large corporations in Europe in the US. Um I spent 10 years at Parenter Technologies um in the US and then I started the offices in France and Europe. Um and um and I was a bit frustrated at the end by not being able to deploy as quickly and as efficiently as I wanted AI and companies. So we started H company a year ago in France. Um we did the biggest fundraising ever of the history of Europe, 220 million in in seeds, $220 million with a team of people from Palanteer, from Meta, from Google, from uh our colleagues at Mistral, from And so what um what was frustrating? Do you know what was the the issue of the deployment of the first waves of AI in in enterprise? Um the the main issue was a lot of money was spent by big corporations over the past two years with not a lot of measurable ROI. So like a lot of projects taking a long time um technical projects that are hard to uh to build. And so the first wave that I saw um was a wave of LLM plus rags. So like chatbots that connect to enterprise data so you can ask question about your company. So it's useful um but it's not really bringing a lot of value that you can measure to the company. It's a bit of productivity maybe. Um the second wave were agents. So agents you plug the LLMs to APIs so to interfaces of the existing environment of the company. So it can be a government can be a company. Uh so that was what I was doing in my previous job. The the main issue with that is that a lot of legacy companies have legacy IT. So it from the 80s, from the 90s with little APIs. Um, and it takes a long time to connect one by one to dirty data, to old software. So it's very hard to do it and it takes like years. Um, and what we've built is what we call the third generation of AI. Um, so it's basically what we call virtual humanoids. They can do anything that a human can do in a couple of seconds. You don't have to connect them to Excel and SAP and Salesforce and all the tool that you are using because they are using the front end. So meaning the user interface that everybody is using. Um and we've built AI models that are so far the best in the world right now if you look at the rankings. So it's very specialized, very niche, but they are the best at interacting with software. So clicking, scrolling, even if they've never seen the software before. So the the big change of paradigma is that now it's very quick um to uh to deploy. It takes a couple of uh hours to deploy these models. There is no need for clean data, no need for clear clean APIs and um and I realize I'm very long and you're smiling at me. So maybe I should uh go to the next question. Um I've introduced you to to edge company, what we are doing and also where I come from. >> Thanks so much uh Katier. We also have here Lionel who uh runs a business where he deploys quantum as a service. Uh Lionel, do you want to tell us a little bit about your company, how it came about, the idea behind it? >> Yeah, of course. Thank you very much for having me here. So, I'm Lionel Rigo and CEO and co-founder of Cubitoft, a quantum as a service company. So, usually when we talk about quantum, people just want to jump by their window because they think it's complicated. Our purpose is to be able to take this seemingly complicated stuff and make it useful for the companies now not in five years but now and today. So I have a past I worked about 25 to 30 years in AI and uh four years ago I decided to go to the next level uh which is uh quantum computing. So what we're doing is we're creating uh quantum as a service platform which uh hosts uh quantum applications which are business use cases applications like this companies who don't know anything about quantum who don't who don't want to buy uh complicated infrastructure who just wants to use it and to have uh to leverage the quantum uh computing power today to increase their business value their overall efficiency can do just in a nutshell if you want more explanation if it's okay. >> Thank you so much Lel. So the question to both of you is we're at an AI summit and everyone is talking about AI. So what do you think is genuinely the promise of AI in the businesses that you both run and what do you think is overhyped or is that a is that a tough question? I know we said this will be relaxed. I think it's a very good question. No, I think there is a lot of hype, right? Like if you look at how many companies are doing AI for for companies, the the enterprise AI that I I work it. Um, so it's interesting because I start to see a shift from like I talked to a lot of CEOs of big companies. And before they were like, okay, you should speak to my AI specialist or you should speak to the technical team. Now I see a shift where they want to have this discussion CEOs CFOs because hype is just like putting new tools. Oh there is a new tool there is a 20% adoption there is a new tool there then 80% adoption adoption is not really a a mean of doing anything. It's results that you are looking for. So so what I'm telling these CEOs is you need to ask for real ROI that you can measure. If you put 10 million in AI you need to ask the company that is taking this 10 million do I get 100 million? how can I measure it? What do I do if I don't get these 100 million? Um or if we talk about non-financial ROI, we started to um to deploy our technology in a couple of hospitals in India. Um and the the ROI here is saving lives, is decreasing the uh waiting time in the emergency room is these are the things that you can also create with AI. But you you need to always measure and be very clear about what you are trying to do. Otherwise, you're going to end up with like 500 different AI tools that are going to be hype, that going to be fun to use, um, but that are not going to create AO. And I think companies that are focusing on hype might not be there, you know, in in two years. Um, but companies that are focusing on real results in real life that you can measure, I think so. >> Thank you, L. >> Um, yeah, I'm I totally agree with what Goautier said because today uh but in quantum it's a bit the opposite. today thank all the companies in a uh want to have a AI some for good reasons other for the hype the one who want to have AI for the hype won't be there won't last long uh in quantum it's the opposite because people are afraid of quantum computing like I said because they think it's complicated uh so uh we have to tell them it's not hype it's not complicated you can do it now and you You have use cases where you can win money where you can have a small ARI even on the existing quantum computers. There are a lot of existing quantum computers in every country. I saw someone a vendor yesterday in India uh where you could use this power to leverage and to win money. And so this is the real uh purpose and the real common point uh is to find the use case where you can win money either on AI uh just on a it will be to find the good use case and not do any uh everything and on quantum to find the good use case so that you can win this money and I think the second question was why the we were on the Indian AI summit uh for us it's important to tell people that use cases exist in quantum, use cases exist in AI and the most important thing is that people adopt them, use them and know them to uh increase their overall value and this is this is the real message we want to to pass on uh in this summit. >> Thank you Lionel. One quick follow-up question. There is a lot of conversation around use cases at the summit like you pointed out as well and you mentioned something about a good use case. So in in your uh when you work how do you identify what a good use case is which sector might be worth investing in and how it will scale and adopt. >> Um the first thing to uh to find a good use case is not to talk technic to find we don't if you talk technic at the beginning uh it's a bad use case. You have to talk take five minutes so people in front of you know what can be done have an idea of all the scope of what you you can solve but then you have to talk business what are the pain points what uh what can we expect to win what do we have inhouse because if you have bad data you'll have bad AI or bad quantum at the same thing so the main point is to have a a business review a company review to find the pain points where you can have the first the good ROI. So not technical people but more business people who know technical stuff >> and Gautia do you have any thoughts how did you decide to work in the sector that you do? Yeah. So um to us we are here to help competitivity of companies. So making them more efficient, making sure they don't disappear uh because they are replaced by someone that is using area. So that's all the financial ROI. So we focus on what humans are doing today, but that they don't really want to do. So like if you take the example of a nurse in an emergency room, usually between countries, it's 60 or 70% of the time that she's going to spend or he's going to spend in front of a computer clicking, scrolling, going from one software to another. Um and and if you ask them, they want to spend time with patients. So removing humans where they don't have a real big value and putting them back to where they have a big value, I think is like what's what drives our uh use case generation. So and and the other thing is can we measure the ROI if we can't it's really difficult to uh to know if you're going to be useful. So I talked to you about a healthcare example um but we obviously have other examples like a salesperson uh you can it's almost the same thing. It's like 50 to 60% in front of their computer. So you remove that the agents are doing that and they can spend more time in front of customers launching new markets helping the company to be more profitable and more sustainable. Um and and the last um the last element that I would add to that is we are making AI that is 100 times cheaper to run. So also 100 times most energy energy and environmentally friendly. And we think it's very important because if you build bigger and bigger and bigger models, maybe they're going to be able to tell you about the history of the king of France in 1000 in in in Hindi. But um what we need here in companies is just a tool that can do anything that a human can do in a company. So that's also what we focus on. >> Thank you so much Kia. Um I want to double click on something that you said and just take it from there. How do you then move from research to real world deployment? And you run a business. So what kinds of challenges are you seeing when you can see the potential from the research and then you're thinking about um how this is going to be deployed in the in the real world? >> Yeah, it's a very tough question and the question you're asking me is a question I'm asking myself almost every day, maybe every week. Um we have a big research team as I was mentioning. So I think it's like the second or third biggest research team in France for AI. uh of a private company. And so researchers have a lot of ideas, but you need to run a business. If you just run a business and tell your researchers, okay, you need to do that and focus on that and do nothing else. A, you're not going to have the best researchers in the world. They're going to go to like other places and B, you're going to miss some opportunities. Someone who stayed, you know, late in a weekend and had a good idea and just like went on it. So, um, it's really a balance. What I'm what I'm saying to teams is you know roughly like do 60 40 do 60% of the things that you are sure are useful for the company and 40% that's not sure but at least you know there is a possibility that it's useful for the company. Um so we do that through a lot of different ways for instance like you do a hack day or hack week where everybody can do whatever they want and then you come back to to real business. Um and then it's important to really um look at what's happening out of research. For instance, um once a researcher invented the no prompt AI, so you don't have to tell anything to the AI and I was like, "Oh, wow. I've never heard that before." So the, you know, the agent is just looking at the screen and you navigate on a website, you arrive at a on a form. It's like, "Oh, my user uh is on a form. Um I'll fill it because I have the necessary information." So you don't have to say, "Can you please fill this form?" So So that was like a good idea, right? and um and that came out of like not a out of meeting or strategy but just out of the brain of someone. So I think it not only applies to researchers the question you're asking me but more and more to humans in general because AI are going to be doing things that are you know sort of like that that we were doing before so we should focus on on these sort of skills I think. >> Thank you. Gotia Lionel do you have any thoughts about that? How do you move from research to deployment? >> Um, yeah, it's a big deal in quantum computing because it's really just new new computers come out every day. New technologies come every day and it is uh really what set goi uh earlier because we have a team almost uh exclusively of PhDs used to search used to have uh to be before going somewhere an extensive view of everything that was done and they want to be sure that they saw every possibilities. We have a business run. So this is not the question. And we I have often to tell them wait I just want today our customer wants this use case. He wants it solved. He wants it solved on an on use case apps that can be deployed that can be reused. I just need one path to solve the problem. If you have one path and this path is good and this path is efficient. I don't want you to look at all the other possibilities. Once you have it, it works. You're sure it's the most efficient. Don't waste your time and go on to the next one. And this is really the most important thing. But on the other side, we created a specific lab where people have several days a month to look at what they want to be sure they stay at the top of the science, at the top of what is made. >> Thank you so much, Lionel. Um, we'll switch gears a little bit now. We have members in the audience and at the summit who are budding entrepreneurs or who are students. Um what kinds of skills and capacity building exercises do you recommend that they invest in or even the governments invest in to be able to keep up with whatever is happening now both from a education standpoint as well as any advice for budding entrepreneurs that are really looking to take ideas and then make that into an AI startup? Once again, I know we said we'll keep this relaxed, >> but I feel like all of my questions are >> No, they are very relaxing. I confirm that. >> I'm happy to to what? Okay. Um, so I think in terms of what's what what I see, I think, you know, AI is going to take a lot of hard skills that were done by, you know, junior people. So like jobs that used to be safe accounting legal if you start now in in a junior position um a lot of things that juniors are doing are going to be done by by so so I think that the the shift is moving towards soft skills are becoming more and more important uh empathy so like we'll always like to have humans in front of us for a lot of things um creativity AI can be creative um but the agency the intention that you give AI um is very often coming from humans. We have roughly five billion years of evolution that brought us to where we are. Uh so we have a lot um uh in advance from from AIS who have like a couple of uh a couple of years. Um also you know the sense of agency it's something that it's when I hire people in my company uh and we get a lot of people applying so it's very competitive. One thing that I'm looking at is not like are they the best in AI skills or but it's more do they have agency. So they face a problem. Um will they try many ways to solve it? Will they um you know go through the window if the door is closed? Like um one thing that I say maybe it's not politically correct but I'll say it is um you know people that don't really follow the rules. Um AI are going to follow the rules. Like the rules can be very different but they're going to follow that. and not following the rule. I'm not saying to do things illegal every day, but if you want to create new things, sometimes you have to break the rules and and create a new parading. So, I think that's also very important. Um, jobs that are just following rules and executing, I think are not going to be um there very long with with AI. Um, so I'd say that and and also I think it's um I remember um at Christmas I was with my grandfather who is 95 years old. He's in very good shape. He's drinking a lot of wine. He was making wine in in France. Uh so I encourage you to drink a little bit of wine if you want to be. And he um he was like witnessing me uh doing rock from his house for two days. I was you know on my computer and I was talking to people. He's like but you haven't worked. You've been talking to people. You've been laughing. You've been like it's not work. Like for him work was going in the fields and cutting things and like doing real things. Not not being in a nice heated environment and speaking to nice people. Um, and so I think if you know in 50 years we'll probably be have the same situation uh as of today. Uh, we'll be looking at our grandkids and being like, "Oh, but you don't really work. You're never in front of a computer. I'm not sure we'll use a mouse or keyboard in 10 years. I'm actually pretty sure that that won't exist anymore because that was the old way to interact with with computers." Um, so we'll be doing all these other things that I think are going to be uh alone or together like very human. Um so do focus on that. Um I think yeah >> thank you so much Kier over to you Lionel. >> Yeah uh I say the first thing is not to be scared of AI. People often say jobs will be replaced by AI. Uh it's not true. Jobs will be people who don't use AI will be replaced by people who use AI. Yes. And this is really important. So first point is to know how to use AI. per thing. Second thing is not to forget a artificial. So it's not real intelligence. Uh AI just uh gives back what it learned. It usually what it learned was given by a human person. So you have to keep keep this in mind. Uh AI won't think the same way as you do today. uh but if you only follow specific rules which are the same rules which were made 10 years, 30 years, 50 years ago. Yes, in this case you may be replaced by AI. So you just have to have a new type of skill set which is I'm going to dream. I'm going to propose new solution. I'm going to have new ideas and this is something AI won't be able to do. uh when I uh teach some of my students at the end of the class or the end of the course I say dream dream big because this is what is going to change the thing. Last of all and this is even more true in uh in quantum computing uh focus on fundamental skills math, physics uh science because those are the the skills on which we can build anything. the skills on which you can learn how to use any AI tool and this is the skills where AI can't replace you because those are the fundamental skills and with this you'll be able to do everything if you focus on using one tool this tool will be obsolete in five years and if you don't if you know only to use this tool you'll be obser learn how to use it but the big base is fundamental tool and the human soft skills. >> Thank you so much Lionel. That's that's great advice. U both Lionel and Gautier. We have one last question and I think the burning question across various panels at different summits is what does meaningful ROI look like from AI in and I know it means different things to different stakeholders but as business people and people running great AI companies what does meaningful ROI look like? I promise this is the last question. uh it depends uh meaningful ROI for AI uh will depend on what you want to do it look so first of all it's to find the use case and a human has to decide what will be the ROI if you say I'm going to put an AI and see what it does does it won't work uh if an RAI in a hospital is to have a nurses uh focus on their nurse job and not do administrative stuff this is a good ROI if uh an AI helps uh cure certain illness because he will saves time for a doctor and the doctor will focus on his skills not on computer skills but on his skill which is his mind analyzing this is a good uh this is a good ROI. So all this uh it's not only money just to say I'm going to win uh money is important because this is what makes corporation grow and live. uh but money is made because you give a service and this is really the basis. So AI has to give this service but so help people give this service and it won't replace people in a notch like this. >> Thank you so much Lana over to you got you have the last word on this. Okay. So yeah, ROI um oh I see a couple of hands. ROI is um obviously depending on depending on industry but what we see so I took the example of like decreasing by two the waiting time in the emergency room. It's very easy to measure if it's there it's there. If it's not there it's not there. Um if we look at businesses so procurement um decreasing by three four five% uh the current the bill of like everything that a company purchases because you have agents looking for the best prices looking for a lot of things that make make cheaper that's very easy to measure as well um if you look at customer service um obviously the enda is like is the customer happy but you can think of not just like one thing that we are seeing is our Customers always want to automate or create more efficient processes for what they are doing which is great is usually what we start to uh work on when we work with them. But the next phase is doing things that they couldn't do before just because AI is there and you can do new things. So if you take customer service for instance, do you want to uh realize in the morning that your Wi-Fi is not working and start to uh mess with the box and then call the customer service and be transferred to like five different places or do you want an agent that you know every five minutes looks at your internet connection and say, "Okay, it's up and realizes that 3:00 a.m. it's down. does all the diagnostics at 4:00 am realizes that you need to change your device and at 5 am there is a new device that is being sent to your home. Um that these are the sort of things that customer service are moving towards. Um if you have you know you bought a lot of companies in a lot of different places. Usually we see that it's very difficult to integrate these systems together. So you run multiple companies. We have an example of a big you know publicity company. they had to um um create a campaign for like every country that they were working on. Um now they are doing real uh time marketing. So maybe they they see you at UNDP saying something and the next uh minutes there will be an ad linked to that uh probably more like you know a football player score goals or cricket player. These sort of things are things that you couldn't do before because AI wasn't there. Um so so it's very um dependent on the businesses but the common point is it's really focused on expansing the strategy of the company and creating a strategic asset not just a new tool that you you know you put on on your desk and you know maybe you clean your desk and you put it in in the you know in the cupboard and you lose it but um a strategic asset that is part of the core of the company. Maybe one last example for airplanes. Um um I worked on a tool that um is now being sold in a lot of airlines to um um not just buy airplanes but also buy um predictive maintenance fruing a lot of things that AI can help. So if you buy if you manufacture aircraft tomorrow maybe you manufacture AI that helps you operate these aircrafts. So these are the trends of partying that we are seeing. >> That's pretty fascinating. Gotier, thank you so much Gautier and Lionel for uh your great insights on the panel. We're almost at time. Thank you everyone for coming by and um staying around. I hope you are having a good time at the summit and we'll conclude and not keep you hostage here anymore. Thank you. >> Thank you. Thank you very much. Thank you very much. Thank you Lionel and Gautio for sharing your perspective on the potential of AI across businesses. Thank you Mana for the most efficient moderatorship. And then you can stand for the picture. back summit. I thank you all for your attention and your patience with us. We have much more in planned for you for the upcoming days and I encourage you all to stay engaged and stay innovative. Thank you.