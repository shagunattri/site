G and human rights related to AI. Today we had a different scenario. We had our assistant director general opening the session and then launching one of the most important briefs that we have so far. He's on his way stuck at another meeting as as as all of us are. So we're going to start with a panel discussion uh to um to start and and then we will um switch and then go to the launch afterwards. So we're going to start with our esteemed panelists. Today we have um we have three distinguished panelists that are joining us and we're going to start with Miss Jalak and I'll introduce each of our speakers as we go ahead to also to save time. So Miss Jalakar, executive director, center for communication governance at NLU Delhi. Jalak, India's judiciary faces both first huge overload in ter in terms of case loads and at the same time immense technological opportunities and potential. What are the key ethical um or procedural let's say safeguards that you think India's courts should prioritize when engaging with AI systems especially given the diversity and scale of the justice ecosystem. >> Um thanks for that question and thanks for organizing this and having me here today. Um you know if you look at AI integration into the judiciary you can broadly say there are two areas it can be integrated. one is in sort of helping streamline administrative load of courts. So whether that'suling of cases um um or it can be used in more substantive matters like research, translation of documents um or then you know even decision making and we've seen a spectrum of applications being developed that that help across uh the cross-section of these tasks. Um some have higher risk uh such as decision making. Um some have sort of uh downstream impacts on significant decision- making like if you're translating documents and if there errors over there. Um and then of course um it may seem that administrative decision-m being taken over by AI um may not impact justice but actually even use of AI anduling can impact justice because AI deciding which case gets listed first which case is extraneous um can sort of uh really impact someone's timelines for justice delivery. So I think you know we need to of course categorize AI use in judiciary across various risk categories and then for each category we need to think about what is the level of assessment that needs to be undertaken. Um you know there are various risk assessment auditing mechanisms that are being established in the AI domain. uh and you know there needs to be thought about how those can be translated and used in the judicial context. So I think that's sort of one piece is auditing and assessments for questions of bias for questions of transparency for questions of explanability. Um the second piece that I think we need to be thinking about is judiciary sits typically in any country on on a large trove of data. I know within the Indian judicial ecosystem uh as part of the e-comittee process the Supreme Court was really thinking about how do you unlock the value of that data and use it to streamline court processes. How can you give it to stakeholders in the ecosystem whether it's startups, other public interest stakeholders, researchers to sort of go through that data and figure out okay you know this these are the lessons and this is how we can streamline processes to move through case load quickly. But that also means that you need to have very robust data management practices uh you know data protection principles being applied because this can in many instances be sensitive and personal data that is getting shared mixed in with non-personal data. So I think that's the second piece that judiciary needs to think about. I think the third piece and of course there's so many things but these are my three is uh judiciary doesn't have the expertise to build these things in house right. So they're going to rely on third party vendors. So to engender public trust, I think public procurement has to happen in an open and transparent way. And there needs to be clear guidelines that are set up for what is uh sort of the assessment of these systems on a regular basis by judiciary external auditors to engender public trust in the use of AI in courts because the last thing you want to do is erode public trust in the court system uh through the integration of AI. So you have to carry the public along with you. Thank you. just just a quick followup if you can briefly tell us how can India balance between this AI efficiency um AIdriven efficiency and constitutional protections especially in light of this multi- uh lingual multiconstitutional um context um I think that's a great question and something we really need to think deeply about because I think there's immense pressure to adopt technology because there's so much case load uh and it's it's burgeoning Um but I think we have to do it in a cautious way where efficiency doesn't trump due process, rule of law, rights of individuals. Um you know when you think about multilingual systems, the the the the thing to think about is that you know how do the a lot of these systems are based on things that are built for English context. So how are you going to translate it into use in uh context where you you have low resource languages? Um and then you know uh there aren't necessarily enough data sets for low resource languages and especially data sets that are primed uh for use in more legal contexts. So I think that is definitely going to be a journey because if we want to ensure as you're saying the protection of constitutional rights of people and the true delivery of justice you will need to balance that. I think one piece that uh we need to really think about is capacity building of judges and I know that's something UNESCO has focused on heavily uh over the last you know several years in fact the last close to a decade um under its AI and rule of law program at NLU Delhi uh at CCG we we were part of the first MOO that was designed for judges and I think you train thousands of judges around the world we are on the technical committee for the second MOO that you all are designing um for judges with Oxford University uh and you know we've also done trainings for uh South Asian judges at NLU Delhi uh on AI and rule of law. I think bringing awareness to judges on what that uh AI is not a neutral technology that it's a sociotechnical technology and that it's not going to make neutral decisions if it's trained on biased data sets it's going to give you biased output and building that awareness of where AI is useful and but what its limitations and challenges can be is is extremely important. I was at this uh conference organized by the Supreme Court of India with the Supreme Court of Singapore and they brought together a lot of Supreme Court judges, a lot of senior high court judges. This was a few years back. And what was very telling to me during that conference is uh you know these are extremely distinguished jurists, the top legal minds of our country, right? people who've been in this space for 30 40 50 sort of years and um uh they had very very fundamental questions on AI and they were really grappling with okay where is it appropriate to use these systems and where is it not and I think we need to bridge that divide where people working on AI and technology need to sort of sit in the room with a public interest lens people working on it with a public interest lens need to sit in the room and really break down what are the risks we're seeing what's appropriate because so that they don't need to reinvent the wheel and I think UNESCO is playing a great role in in bridging that divide thank you very interesting points here um I would like to go now because you mentioned a very important component which is a capacity building but before we go uh to our next speaker I'd like to introduce professor Sri Krishna Divva Rao vice chancellor for Nsar University of law and my question to you is exactly uh what Jalak was saying um from an academic perspective um how should legal education for lawyers and for judges um find some sort of adaptation to prepare judges for um for this AIdriven um justice environment? What skills, what ethical perhaps reflections should be also included? >> Yeah. uh just now Jelak mentioned about I'll start with the multilingualism what she said and then I'll come back to how the legal academia has to respond to is a major uh new age thinking as a relearning the law but multilingual is an important which is India is is a land of several languages and several dialects and uh uh of course the Anglo-Saxon legal system was able to uh reach out only to the uh communities those who are privileged and uh this is a challenge before the legal education. I think that may take another 10 or 20 years. How do we really the s massive justice gap can be at least uh temporarily answered uh once the legal education moves into more and more into the language teaching in the mother tongues and other that's where the AI can really help but that requires not just use of the AI translation into the several languages but we require a several experts in the legal academia those who can understand journalist and the several things but the uh legal academia I would look at uh when national law universities were started in India in 1980s we used to say what we need is a professionally competent socially relevant and technically sound that's what the slogan which started is aim and objective now we will say in addition to this We need technologically literate, technologically equipped lawyers, entire legal fraternity. So as a law teacher, always we look at how the new curriculum has to be developed. But when the curriculum is developed, we need to have the entire participation of the legal fraternity, the law firms, IT companies all have to come together and to see how they can create uh a more challenging, more engaging uh uh curriculum and the pedagogy. Uh for instance uh we teach no the what we call is in the legal academia bread and bud courses constitutional law, corporate law, criminal law and several other various areas property and several other but now we need to think about introducing maybe second year onwards a specialized honors in the law technology with focus on the artificial intelligence. As someone uh who has been associated with the legal aid movement in India over three decades and the parallegal movement in India, I would say that it requires several levels of first legal literacy. How do we how the AI can help in the massive legal literacy which required in a several of the languages and using a new pedagogical method. Second is community dispute resolution. how the online dispute resolution with the participation of both lawyers, judges and the legal academia must help. In fact, generally in the legal education sometimes we drew parallels to the medical education because like a medical education a medical college in India will not be given a permission unless you have a teaching hospital. Why don't we have a teaching course? AI learn technology provides that an opportunity for a consumer dispute. I wanted to settle because the public have a confidence in legal academia rather than any of the legal fraternity. Simple family disputes I wanted to resolve land disputes because that's a major challenge of massive backlogs. We can start where legal academia takes the major responsibility and duty not only creating a new curriculas and pedagogical tools and method where 40% in the classroom 60% in the technological companies that a clinical legal education clinical pedagogy can be used. Second, we need to train orient the legal fraternity starting from the law students first and then the lawyers and judges and other. So I'll stop here and I think I have taken sufficient time. >> Not at all. Thank you very much for your very um very relevant um uh contribution because you're right everything that we do has to have this multistakeholder approach. it cannot be done by only one side only not only judicial uh institutes but also across the board and my and and allow me to to welcome our assistant director general Dr. Tafi Jalassi for joining us um we're going to come to you we have pushed the launch actually to the end of the session instead of the beginning um we have one more speaker here um Mr. Argia Barachara and I'm really sorry about my pronunciation if I mispronounce any of the names. Uh co-founder and CTO of Adalat AI. So Argia as CTO of Adalat AI uh you are powering courtrooms uh across India with tools like real-time transcription and case management. What real world applications are you seeing that reduce barriers especially for marginalized or rural communities while aligning with principles of fairness, transparency and non-discrimination? >> Yeah. Uh firstly, thank you so much for having me here. Um I think there's two tracks to how AI is being used um to sort of uh improve access to justice. The first track is more direct which is um you know directly with the communities and I think over there a big part of the problem in the global south is you know people have no idea of getting information about their cases. They have no idea what's going on with their cases. It's extremely difficult to navigate archaic government websites to find out where is my case, what's the judgment, what do I have to do next. um you know there are complex jargon that lawyers love to use like interlocutory order and rest judicata which common citizens just don't understand right and so I think one big use case of AI is uh to be able to make sure that communities are able to access this information easily right and to that extent at Adalat AI we recently launched a WhatsApp chatbot where you can have a conversation in any language um that you speak not just English and you can give your name, maybe your pin code and find out if you have a case, what's the next action item to take. Um, and so that's more of the direct um sort of access to justice uh solution. The second track is more around uh the indirect access to justice um sort of solution which is to improve capacity of courts. Now when we talk about improving capacity of courts um just to paint a picture because now uh along with my co-founder who's a lawyer I've been down deep in the trenches. Um you know courts in India are severely broken. There's paper everywhere. Um one of the use cases is that you know judges write by hand. So if we were all in a courtroom and you know I asked as a lawyer I asked a witness where were you on the night of 21st April um the judge would stop us there write this by hand and then the next thing would be dictated now as you can imagine this becomes a serious bottleneck uh to court proceedings moving fast um and to that extent we've built AI transcription solutions so that you don't have to write things by hand you can just um you know go about your witness deposition and then you get a transcript of the same um by virtue of the process itself everything is verified on spot. uh what we are seeing is that solutions like this which are simple that don't go into um you know sort of being an AI judge or suggesting how to make a judgment are able to improve productivity at a daily and weekly level by 2 to 3x which at scale could reduce case resolution timelines by 30 to 50% depending on case stage and type right and so I think the big point uh that I'm trying to drive home is that even apart from the frontier of technology even apart from just being able ble to predict cases or being able to um you know sort of summarize or translate cases. There are so many other very basic tasks that AI could help with. Transcription is something that has been there for about 20 years now. Speech to text that is right and so um there there are a lot of uh technologies that are safe to use today and I think we should really work towards making sure that our judiciary has access to those and that's kind of what Adalati works on. um we're in 20% of India's codes today and that's kind of where we've observed this statistic. Now coming to this last part of your question which is how do you make this fair, trustworthy and um um you know make sure that this doesn't discriminate. I think that's the hard part about AI when it comes to being fair. I think given the current state of technology, fairness means making sure that you're only grounded to information that's available and not being suggestive, not giving uh any sort of judicial advice. Let's say if you're building a WhatsApp chatbot for communities to find out about, you know, information about their cases, AI systems cannot give advice today. That's not safe at all. That those things have not been audited yet. We have no benchmarks for doing that. And so I think that's more around the faithfulness angle. In terms of trust, I think what needs to happen is AI systems need to acknowledge when they don't know something. Uh that's something that you know the entire AI space is working towards making sure that we can get our models to say no more often. And I think that's what it means to be uh trustworthy right now. And in terms of uh making sure that they don't discriminate, I think the biggest thing that AI models need to do is make sure they account for the linguistic diversity and that's the largest problem that we have in the country and Adalat AI and and and a lot of other players in the ecosystem are working to make sure that every language and every dialect is covered because um you know just giving information is English is not good enough. So I think these are some of the challenges towards fairness, trust and uh making sure AI systems don't discriminate and possible solutions as well. >> Thank you. Thank you very much. Um it's interesting to hear the different perspectives but it's also interesting to know that while AI is global, we always have to look at the context implementation in all countries and regions should not be the same. India has this diversity and multilingualism that perhaps is not there in many countries. So I my next question is for you Dr. Jalassie. Um we've heard from different perspectives. From UNESCO's perspective, what would you say would be the urgent next steps for member states to actually um um more um how do you say um institutionalize this AI training for justice across the the board, but also more importantly, how this could translate into real judicial independence and accountability in practice. >> Thank you, Mali. Good afternoon everybody and sorry for arriving late. I was speaking at another session. So obviously I'm trying to uh to to gather what was said from the previous speakers. Well uh as you know UNESCO which this year celebrated its 80th anniversary had as a constitutional mission to build peace in the minds of men and women. Justice is a foundation for peace as is education, culture, science, communication and information. So for us today when we look at the result of a survey we conducted in 2023, it revealed that 90% of judiciary professionals use AI without any prior training nor guidelines. This is frightening. 90% of them use AI but they never had any guidelines nor any training and we know that some of these AI systems unfortunately use data sets that uh carries some biases whether it is about gender, ethnicity, language, geography. So what I'm saying is that these AI system could and in some cases that we have documented did misguide misinform the judiciary. So needless to say that the outcome would be rather negative and in this case AI will not be a force for good but a force for risk and even for harm. So UNESCO developed uh training including massive open online courses on AI and the rule of law and we have trained to date more than 10,000 judges prosecutors in number of countries around the world for the proper use of AI. So yes of course AI can help on number of dimensions. It can reduce uh the the time to process judicial cases. It can reduce the cost of it. It could help with maybe past cases. As you know in AI there is one field called case based reasoning. It could bring bring to the four some past cases and how they were were were dealt with. However, the integrity of justice cannot be automated and that we should keep in mind. So AI and AI systems in courts and tribunals as a help as a support system to the judiciary professionals but not as a replacement for them and this has been a guiding line in the work of UNESCO which has been anchored as you know Mali in the respect of human rights in uh respect of human dignity in ethics in equity. So we have to keep these values and these principles as guiding our work as far as artificial intelligence and the judiciary. And when finally I would say when I mention this human rights, human dignity and the like uh you may know that for now 13 years UNESCO has trained more than 36,000 judges and prosecutors in 160 countries on freedom of expression, safety of journalist because quite often when there is a legal case against a media professional, the judge and the prosecutor have to process that. So we want to bring the the awareness or the knowledge up to date of the judiciary regarding international standards on freedom of expression and on safety of journalist and on media because you believe that freedom of expression is a human right that enables other human rights and should be taken as a foundation for what follows as far as our work on AI and the judiciary. Thank you Adg. I have a follow-up question. So as we said international standards are non-negotiable, human rights are non-negotiable but there are sometimes there there are certain context as we said the multilingualism, the diversity in India and others that requires some adaptation of the tools that UNESCO and other organizations offer. So how do you see what would UNESCO be able to do with India's leadership in this AI adoption? How can we support these regional adaptations? You are absolutely right. It's not one sizefits all. UNESCO has to work on a global scale because UNESCO has 194 member states. It's the world. So of course we what we provide in terms of guidelines, in terms of framework, in terms of the UNESCO recommendation on the ethics of AI which which was adopted in 2021. That's uh two solid years before the advent of uh generative AI and the advent of uh CH GPT. We had the work on this recommendation started in 2018 and it was approved in 2021 by all 194 member states calling for an ethical responsible use of AI. So what I'm saying is our work is global like the guidelines for the use of AI systems in tribunals and courts. These are global guidelines but of course they need to be contextualized. So of course taken into account by the judiciary in in in different countries regions around the world contextualize them taking into account the specificities of that country cultural legal socioeconomic specificities. And that's why I'm saying it's not one size fits all but at least national judiciary systems and courts and tribunals have a good blueprint on which to build take the UNESCO work uh instead of starting from scratch and then of course adapted not adopted as is but adapted to the local or the national context. Well, since we're talking about guidelines and tools, I think this is a moment for us to launch here in your presence um the the our new policy brief uh related exactly to the same topic. So, Mr. Jalassi, I invite you to the podium perhaps and you can maybe launch share with us the the latest policy brief and then we can take some questions from the audience. >> Sure. >> Or if you can speak here as well. >> Do we have the document? >> We don't have a copy. I don't I don't have a copy of the document but since you know what AI it's a virtual document it exists but uh for now it is in a digital form not in a paper forum so we are delighted having um author developed this policy brief we believe again that it is useful resource and I say it's a resource that of course member states and the judiciary may want to use or not uh this is the work of UNESCO I Part of our work is advocacy, but advocacy based on evidence-based work. Uh, and we believe that advocacy could lead to national policies or to regulation or to implementation. And we do help as well with that. It's not only we do research, we publish, we do advocacy, but we help member states at their request develop national policies and implement them. uh in addition to our normative work when I mention uh the UNESCO recommendation on the ethics of AI it's not a convention because otherwise a convention would be legally binding we don't make it legally binding but a recommendation to say these are this is a set of principles that was developed by more than 100 international experts then it was endorsed or approved by all our 194 member states we believe it has a value for each country around the world. But it's up to the national authorities, the professional uh communities to decide to what extent they want to adapt and use these guidelines or this policy brief which Mali mentioned. You are looking for it. >> Thank you. I actually have it in a QR code for people to scan. And in the meantime, I can coordinate the Q&As's perhaps from where I stand while I do that. Um we do have some time for Q&As's and I think it is as important for you to be able to approach the speakers and have questions than the speakers just uh having a one-sided discussion. So yes let we can start taking questions. I don't know if we have a microphone if someone can help us give to the speakers. We have the first uh the audience. We have one question there. Ashita, can you help us with the please the questions the microphone? I will Hello. Yeah. Yeah. So my question is generally uh to the panel here. What is the So basically we were hearing I heard all the panelists and everybody gave their views on the reliance of AI uh in making decisions and judgments. Do you think going forward and in future what will be the liability of AI? uh how can we make AI liable uh you know in uh making judgments as well because as sir said rightly lot of judges are relying on AI and making decisions and uh so just wanted to ask you what there'll be a code set up for making AI liable or not um I think um uh sir just referred to the fact that you know a very high number of judges are using AI without any kind of guidance being given to them in a national context. So I think before we get to liability, we perhaps need to ensure that guidelines are developed domestically around AI use by judges. What it's appropriate to use it for, what it's not appropriate to use it for, where you are using it, what kind of safeguards, process checks need to be in place around its use. when courts are acquiring AI technology whether it's for translation transcription administrative management research purposes what kind of vetting auditing assessments of the system is being done at the point of um you know um acquisition of this technology but also um you know post-deployment uh assessments and audits that are being conducted um you know uh how open and transparent is public procurement. Um and then what is the kind of transparency that is remaining? So first you have to put into place these safeguards. Right? I think liability then becomes the next layer. I think uh at this point adoption of AI and courts is being used as a tool for judges rather than direct impact where uh you know it's directly impacting citizen rights. I mean there have been instances of compass and heart and victor other technologies which were deployed in jurisdictions like the US, Brazil, the UK which didn't you know had their own sort of challenges. I think people are more cognizant of it now. Um so I think li decision making I would say is largely still um vested in judges. So I'm not sure where that liability comes in but I think overarchingly governments are increasingly thinking about liability of AI systems more generally right not specific to AI use in judiciary but I think more generally um and I think that is still an evolving conversation um many thought there's a lot of thinking going into okay um from strict liability frameworks that have been developed taught liability frameworks that have been developed um across uh you know uh the last you know hundreds of years what learnings can be drawn in the context of AI liability um you know there's been a lot of conversation around okay is there something to learn from intermediary liability principles that have been imposed on internet platforms social media platforms uh the due diligence obligations that are imposed on them so what learnings can we take from all these spaces and then translate them appropriately into the context of AI. So I think there's still uh I don't think there's quite consensus on what liability looks like but there's definitely ongoing conversations on this issue. >> Yeah. Just to supplement jalak. uh yesterday I think some of you have read Supreme Court Chief Justice India mentioned about some of these and what we could see is that it is the lawyers those who use and through their arguments they mention with the use of the artificial intelligence and the some of the even in Kerala we can see Bangalore there's income tax tribunal entire when the judgment came they realize that the lawyer who mentioned about this case in the income tax tribunal the case does not exist the principle does not exist so it's depends more on what we are mentioning about UNISCO the uh toolkit will help and also individual even the Supreme Court and other high court the department of justice has to come out with a comprehensive guidelines but till that time it's a individual ual judge he has to use. Of course, we can see that some instances are coming up where the judges are using the AI for the research and the judgment. But all of us what we have seen in the panel discussion, we must remember that the legal representation will remain. Lawyer cannot be replaced by AI, teacher cannot be replaced by AI and judges cannot be replaced by AI. Thank you very much. Well, I see we have a number of questions and I'm glad we have the time. Okay, let's take let's see if if there's a lady. Let's do No, not interested. Okay, we'll take what second question and third question here. Okay, we'll take we'll take her first and then we'll come to you. Sorry. Thank you. Yes. Uh, so we are talking a lot about AI for law. But what about law for AI? So when we are talking about we are having a lot of frameworks uh and u in education in communication in jurisdiction and everything but what about a common framework or guideline or a policy to use AI or to use the data of AI that has been produced or developed or uh a common understanding to the audience that what is law for AI can be what is the uh [clears throat] bench benchmark uh for using the AI or any any kind of AI tool uh what is right or what is wrong that is what I wanted to know from um any of you if you would like to thank you maybe we can take two more questions and if there are similarities and if you also want to address it to a particular speaker please do so unless you want to address it to the entire panel. Uh um my question is uh for Argya. Uh you mentioned two specific streams where AI is sort of broadly being uh looked at as as a potential more use case. Um do you also see uh a potential need or or uh opportunity for point solutions for example QC of critical documents etc which have a significant bearing on on how an individual case sort of moves forward the delay the outcome as well. uh could be a poxo related uh chart sheet, could be uh a domestic abuse related chart sheet coming from a very narrow perspective but QC related uh sort of opportunities as well. Thank you. >> Yeah. No, that that's a great question. I think that's the territory where I I advise uh AI practitioners and companies building to stay away from. And just to uh tie that up with the previous point of training judges um in the context of India, you know, we have a thing called the Adalutath AI Academy which in fact the curriculum of which we've been building in partnership with UNESCO. As part of that, we've done a lot of trainings with judges in India. Um a lot of them don't know how to update their browsers. Um right, they don't know how to update their Chrome browsers yet. And so the first thing is for them to understand that if they use AI outputs they're liable today, right? And to that extent giving these tools in these settings to people who don't have the knowledge yet can be extremely dangerous. So I can tell you a few examples where um you know AI could help even with sensitive matters. One is perhaps transcription because again it's it's very u you know sort of embedded technology right now. You're just saying and it's writing what it is. The second is you have these long documents that you have to always go through and this is a common problem for lawyers and judges. AI can be used to ask questions and not get answers. But the AI then scrolling and taking you to the right part of the docu document, right? And often the problem becomes that you just have to scroll through thousands and thousands of pages. So if you think about it, a small trick makes AI a lot more auditable in this case as opposed to you asking a question and then it generating a huge answer where you could have fake cases being generated as well, right? And so it's really AI plus how you design the user interface that that's going to do it. Um but generally I I would avoid uh using generative AI in sensitive cases. So my question is from team representative of NLU Delhi and Adalat AI. Considering the UNESCO mandate on linguistic rights, what are the challenges that the AI can uh cater in aspect of English only mandate through article 348 of high court and supreme court and how multilinguistic criteria and can be integrated in a judicial system of India. >> Yeah. Um >> can you take another second question and then we can answer >> my question my question is actually two >> my question is actually two or two twofold the first part would be a lot was said on uh guidelines on use of AI but how do we a certain uh guidelines which are indicative in any way in all all ways actually are being used or are being applied to in the right way in all the existing thing ma matters because they they are uh indicative for for us. So for us how do we ensure that the steps that are being uh taught or that are being told is being either to or not because there is no way to reverse engineer this and know if a particular case is affected by those uh guidelines not being in place or not being or or there in place or not. The second part to that would be how would I know if my case because because for example as sir uh rightly gave uh gave gave that example as a case which which didn't exist was uh cited and an order order was passed on that so how would I know that my case is not being affected by a bias or by some case which was not in existing uh which uh which is not in existence but the opposite side has argued that case. >> So >> thank you. So we have two questions one also twofold. Would you like to start first? You were already starting to respond to this. >> I can I can start with the question on the multilingual aspect. So uh it's it's a very hard problem. It's important that we acknowledge that we have many dialects. The way that people speak um let's say um English in Kerala is very different from the way that people speak uh English in Delhi. Uh let alone the fact that we have thousands of dialects. Um so there is a certain way in which you can build translation systems that can actually address this. I can maybe give you an example of some of the efforts that are going on by the government by Supreme Court and also by Adalat AI which is to uh build these systems using expert preferences. What I mean by that is you know let's say there is a legal document that needs to be translated to let's say a local language to make sure that it's accessible. uh what we are doing is we actually give copies from humans and a lot of different AIs to lawyers and then we ask them to choose which one they like the most right and an AI solution is only allowed once it reach re reaches a point where 80% of the responses um are from AI and they're being preferred by humans. So that's one of the things that we've done in Karnataka and some of the translation systems in Karnataka run by uh Adalat AI and we've seen that um you know humans actually prefer AI output 80 to 90% of the times and these are legal professionals these are not just any annotator so that's one very important thing which is to make sure that the expert human is in the loop um right and I think the uh second challenge overall is it's going to take time. It's important to understand that you know AI systems are not just going to do it uh day you know overnight. Um and so we still have to build capacity for translators uh in the state and which is quite lagging right now. Um yeah >> and we have the second question that we hear >> would like anyone would like to respond to the other question that we had. I think the question was >> can you maybe quickly sum it up in couple of seconds? >> Guidelines being uh indicative. So how do we how do we uh establish the fact that these are being uh other and the steps that are that are taught or that are told are being uh like you know applied in that uh order. For example, if you skip one step, you may not go in the right order to the steps to the next next step. And the other other part was that how do I how do I know that my case is not being affected by AI or the bias bias involved in that because any way to reverse engineer >> um thanks for summing that up. Um I think uh within the judicial system there will have to be you know like you have office for data protection officers right the office of data protection is being set up in many courts. Similarly, you know, either within that office or a separate office depending on different contexts, different judiciaries may choose to do it differently. You will have to have a sort of an arm that is set up within the court system whose function is to oversee, enforce um and sort of look out for patterns and challenges that uh sort of may be emerging at any given point in time. Um in terms of how do you know that your case is not being affected? I mean I think lawyers and um you know participants in the judicial system have to be vigilant and point to challenges that emerge surface challenges that emerge and so that patterns of harm get visibilized within the judicial system uh and they can be flagged. Right? So where there are harmful instances or challenges arising there needs to be a feedback loop into the judiciary a grievance redressal mechanism uh sort of where it's flagged that you know this AI use is is is being problematic but a lot of AIUS and its harmful impact may be invisibleized where you do not realize that this decision is being based made is being made based on AI system which is why you need third party audits assessments and other practices which may not pick it up at an individual level but at a at a more sort of meta level it will be able to identify that these are the challenges in the deployment of this system and these changes and tweaks need to be made to the system to ensure that it is non-discriminatory that you know uh it is maintaining privacy that it's not implicating freedom of speech and expression norms but I'll I'll defer to uh Dr. Krishna Deva over here since you know he has decades of experience in in in these kind of questions. >> Yeah. Just '90s we were looking at in the legal AC particularly in India court managers and case management and the Supreme Court has come out with each district they have appointed a court manager who is a management graduate. They did not work. But now we need with the AI we need a technologist at the each not one person a group of persons at the district court data protection data analysis helping the judge in the research summary translation so many things but as we all have agreed that AI will not substitute for a judge or a teacher or a lawyer. So but some of these safeguards it has to be built up. I think that's where it's a concerted effort has to be made everybody and technology particularly the IT companies. In fact when we say that I I was just my I am passionate that even the law students must be trained to develop a software development. engineer is developing maybe the engineer may not understand the technicalities of a law or a court and other. So we need to think about now how software development of whether this online dispute resolution, judicial research, preventing the bias, discrimination, preservation of constitutional values, equality all these only a lot but that requires a major challenge of rethinking. Thank you. Okay. Uh, Mr. ADG, would you like to add something? >> Just some final words. >> Maybe before the final words, I want I see some people here wanting to ask questions. Look, if you promise your question will be straight to the point, fast. We'll take one lady, one here, and one here. He asked first, but you're welcome to ask later. Two questions. Okay. So, can we take one here and one from there, and then you can talk to the speakers. Hi uh my name is Abhishek and uh I am a podcast host doing podcasts uh with judges of Supreme Court and high courts mostly. So uh I have met so many judges uh in in uh you know in my time and uh 99% are reluctant to do work with AI and I do not blame them at all uh because of the facts which you have just mentioned that AI is uh still uh you know hallucinating and all. So how do we uh make them comfortable? How do we make sure that uh their judgments in case you know they are relying on AI or some lawyer is relying on AI then uh they are not uh misleading. >> Okay, we'll take the second question and then we'll go for the last question. >> Hi panelists, thank you for such an insightful talk. Uh my question to you is how do you protect the creativity? So we see in India a lot of judgments and you know everything is based on emotions. How do you protect creativity? That is one question. Secondly, uh the older generation is still on uh you know they are more towards documents and commentaries that are available. However, the new generation that is coming, they are more tech- based and for them I will uh for me experience matters over tech and how do you create a distinction because it will also affect the employment in the job uh employment in the legal fraternity. How do you protect that? >> Thank you. >> We go there. >> Yeah. Thank you. My name is >> Can you Can you turn it on? >> Is it? >> There we go. Okay. Last question. I'm Hoffmeister with the German Ministry for Digitalization. And towards the end, one provocative question. Don't you think that maybe the use of AI for judges by judges should become mandatory in the future? The legal system is based on trust and on acceptance. And if we see AI being more accurate in the future, the judgments being more precise in the future and comparing one judgment which is extremely precise with the help of AI and one court deciding not so precise, the trust of society goes down. So I just provocatively ask um should we not make use of AI by judges mandatory in the near future? >> Thank you. So we have three questions less than 5 minutes and Mr. Jalassi would like to close and I would like to tell you something. So I don't know if each of you would like to answer very briefly straight to the point what each of these three questions >> I think it requires a judicial education where I think some of the uh questions were raised I think very challenging uh how to simple English writing and then how AI can supplement and maybe a judge may mention that he used the AI so that safety skeptic stability and using that preserving the uh essence of the judgment how it is to be right. I know it's difficult to write in a simple language within a small paragraphs maybe a five pages a judgment it's a difficult some of them they used to say they refer to the preview council some of the outstanding judgments yeah to answer your question more directly AI is actually mandated in a lot of courts in India so for example there's a state called Kerala and Adalat AI is actually mandatory in every courtroom in Kerala you cannot record witness depositions by hand you need to do it using Adalat AI transcription right and to that extent before any such mandate kicks in for other use cases like judgment writing I think what's important is to do a serious economic impact evaluation it's it's important to see that the impact is measurable and it's also important to see that across the board generally you see better and fairer justice and only then can AI be mandated as long as that infrastructure can be developed I don't see a harm in mandating AI Okay, thank you. Have we answered all the questions? We had the old generation versus younger generation. Anyone has a message to say? >> I guess calculators came in. We didn't get bad at math. Um, and so we'll have to figure out very similar >> arithmetic. Maybe maybe we did, but we still moving on in terms of doing more innovation. We are still building more, right? And so we'll have to figure out something similar. I think the educational curriculum will have to change to account for AI as the new calculator as well. But all generations must learn. >> Thank you. I will will Dr. Jalassi would would like to say a few words just to thank you for coming. But I just want to say if you can scan this for the publication if you haven't already. Okay. Done. One second. And then there's the other one where you have all the resources about all the guidelines that UNESCO has and and can offer. So one, two here. And Dr. Jalassi, I give you the floor. You can scan this code for all the different material. >> Thank you, Mali. uh the mission of UNESCO has five C's in it. I think our meeting here first is to convene, to converse, to comprehend, to commit, to collaborate and there is a six C which is capacity building and I think what you mentioned here our work on AI and the rule of law, our guidelines for the use of AI systems in courts and tribunals, the AI essentials for judges which we officially launched here. These are just examples. These are three key uh capacity building means. uh we have to ensure that together AI remains aligned with the human rights with the rule of law because as I said behav the integrity of justice must not be automated and we have to ensure that AI strengthens not sidelines judicial independence fairness due diligence and the judicial the integrity of the judicial process on the last exchange with the between some questions and the panel panelists when we said you know what can we do with AI I think generally speaking we cannot stop technological advances we cannot but we need to provide the framework we need to provide some sort of an overarching regulation it's not in regulation that hinders creativity and innovation because the lady had a question about that it's not either or we need to have some overarching guidelines principles for using AI responsibly, ethically, and make it a force for good. >> Thank you very much. Thank you all for joining. The message was clear. AI can change maybe the way justice operates, but not what it stands for. Thank you very much. Have a a wonderful summit.